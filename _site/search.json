[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "title": "Hands-on Exercise 5: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, wewill learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package.\nWe will:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#overview",
    "title": "Hands-on Exercise 5: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, wewill learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package.\nWe will:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#getting-started",
    "title": "Hands-on Exercise 5: Global Measures of Spatial Autocorrelation",
    "section": "5.2 Getting Started",
    "text": "5.2 Getting Started\n\n5.2.1 Analytical Question\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\nThe anaytical questions are:\n\nAre the development distributed geographically?\nIf no, are there sign of spatial clustering?\nIf yes, where are these clusters?\n\n\n\n5.2.2 Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n5.2.3 Load Relevant R Packages\nThe packages are\n\nsf for importing and handling geospatial data in R\ntidyverse for wrangling attribute data in R\nspdep to compute spatial weights, global and local spatial autocorrelation statistics\ntmap to prepare cartographic quality chropleth map\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#load-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#load-data",
    "title": "Hands-on Exercise 5: Global Measures of Spatial Autocorrelation",
    "section": "5.3 Load Data",
    "text": "5.3 Load Data\n\n5.3.1 Import Shapefiles into R\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\fathimak2020\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n5.3.2 Import csv File into R\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n5.3.3 Relational Join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\n5.3.4 Visualising Regional Development Indicator\nLets prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#global-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#global-measures-of-spatial-autocorrelation",
    "title": "Hands-on Exercise 5: Global Measures of Spatial Autocorrelation",
    "section": "5.4 Global Measures of Spatial Autocorrelation",
    "text": "5.4 Global Measures of Spatial Autocorrelation\nHere we will compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\n5.4.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. In the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. \n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n5.4.2 Row-standardised Weights Matrix\nWe need to assign weights to each neighboring polygon. This is done by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#global-measures-of-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#global-measures-of-spatial-autocorrelation-morans-i",
    "title": "Hands-on Exercise 5: Global Measures of Spatial Autocorrelation",
    "section": "5.5 Global Measures of Spatial Autocorrelation: Moran’s I",
    "text": "5.5 Global Measures of Spatial Autocorrelation: Moran’s I\nHere we will perform Moran’s I statistics testing by using moran.test() of spdep.\n\n5.5.1 Maron’s I Test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nNote\n\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\nAnswer:\n\n\n\n\n\n5.5.2 Computing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n5.5.3 Visualising Monte Carlo Moran’s I\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nQuestion: What statistical observation can you draw fro mthe output above?\n\n\nChallenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "title": "Hands-on Exercise 5: Global Measures of Spatial Autocorrelation",
    "section": "5.6 Global Measures of Spatial Autocorrelation: Geary’s C",
    "text": "5.6 Global Measures of Spatial Autocorrelation: Geary’s C\nHere we will perform Geary’s C statistics testing by using appropriate functions of spdep package.\n\n5.6.1 Geary’s C Test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\n\n\n\nNote\n\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\nAnswer:\n\n\n\n\n\n5.6.2 Computing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\nAnswer:\n\n\n\n\n\n5.6.3 Visualising the Monte Carlo Geary’s C\nWe will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nQuestion: What statistical observation can you draw from the output?\nAnswer:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#spatial-correlogram",
    "title": "Hands-on Exercise 5: Global Measures of Spatial Autocorrelation",
    "section": "5.7 Spatial Correlogram",
    "text": "5.7 Spatial Correlogram\nSpatial correlograms show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.\n\n5.7.1 Compute Moran’s I Correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. \n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nQuestion: What statistical observation can you draw from the plot above?\nAnswer:\n\n\n\n\n\n5.7.2 Compute Geary’s C Correlogram and Plot\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "1.1 Setting the scene",
    "text": "1.1 Setting the scene\nUnderstanding how people move around in a city is like figuring out its heartbeat—it shows us the rhythms that shape our urban lives. Thanks to smartphones and technology, we now have a bunch of data about how people move. When we use smart analysis tools like GIS, we can unlock valuable insights that help us plan cities better.\nIn 2020, GRAB shared a set of data called Grab Posisi, all about how people move around in Singapore. This kind of information isn’t just interesting; it’s super helpful for businesses, people who make decisions about the city, and those who plan how cities work. It’s like having a dynamic picture of how people move, helping us create cities that work well for everyone."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "1.2 Objectives",
    "text": "1.2 Objectives\nThe objectives of this take-home exercise are to:\n\nApply geospatial analytics to address societal challenges\nUse spatial point patterns analysis methods to explore Grab hailing services distribution in Singapore\nOrganise geospatial data into sf tibble data.frames using sf and tidyverse functions\nFocus on Grab taxi location points, road layer within Singapore, and Singapore coastal boundary layer\nGenerate traditional Kernel Density Estimation layers\nCreate Network Kernel Density Estimation (NKDE)\nUtilise tmap functions to display kernel density layers on OSM\nDescribe spatial patterns revealed by the kernel density maps\n\nBy this exercise, I will:\n\nEnhance my understanding of geospatial analytics applications\nDevelop proficiency in spatial point patterns analysis\nGain hands-on experience in dealing with geospatial data\nExplore Grab hailing services distribution patterns in Singapore\nGenerate and interpret Kernel Density Estimation layers\nUnderstand the nuances of Network Kernel Density Estimation (NKDE)\nLearn about the visualisation of spatial patterns using tmap functions on OSM"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#getting-started",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "2 Getting Started",
    "text": "2 Getting Started"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-acquisition",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-acquisition",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "2.1 Data Acquisition",
    "text": "2.1 Data Acquisition\nThe study will utilise the following datasets to explore spatial point patterns analysis methods and reveal the geographical and spatio-temporal distribution of Grab hailing services locations in Singapore.\n\n\n\nDataset Name\nType\nSource\nPath\n\n\n\n\nGrab-Posisi\nAspatial (.parquet)\nhttps://engineering.grab.com/grab-posisi\ndata/aspatial/grabPosisi\n\n\nMaster Plan 2019 Subzone Boundary (No Sea)\nGeospatial (.shp)\nhttps://beta.data.gov.sg/collections/2104/view\ndata/geospatial/MPSZ-2019\n\n\nOpen Street Map Road Data\nGeospatial (.shp)\nhttps://download.geofabrik.de/asia/malaysia-singapore-brunei.html\ndata/geospatial/OSM/gis_osm_roads_free_1"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-relevant-r-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-relevant-r-packages",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "2.2 Importing Relevant R Packages",
    "text": "2.2 Importing Relevant R Packages\nThe R packages used in this project are:\n\narrow: for reading and writing Parquet files\ndplyr: for data manipulation\nlubridate: for working with date-time data\nmaptools: set of tools for reading and manipulating spatial data formats, such as shapefiles\nraster: reads, writes, manipulates, analyses, and models gridded spatial data\nrgdal: from CRAN, enables users to import, export, and manipulate spatial data within the R environment\nRcolorBrewer: package providing color schemes for maps and other visualizations\nrmapshaper: a package for simplifying and modifying geographic shapes in R\nsf: for importing, managing, and processing geospatial data\nspNetwork: to perform spatial analysis for NKDE\nspatstat: for performing spatial point patterns analysis\ntidyverse: a family of other R packages for performing data science tasks such as importing, wrangling, and visualizing data\ntmap: creating static and interactive maps\nggplot2: used for data visualization\nplotly: interactive graphing library for R\n\nPacman assists us by helping us load R packages that we require.\n\n pacman::p_load(arrow, dplyr, lubridate, maptools, raster, rgdal, RColorBrewer, rmapshaper, sf, sp, spNetwork, spatstat, tidyverse, tmap, ggplot2, plotly)\n\n#update.packages(ask = FALSE, dependencies = TRUE)\n## install.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-geospatial-datasets",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-geospatial-datasets",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "2.3 Importing Geospatial Datasets",
    "text": "2.3 Importing Geospatial Datasets\n\n2.3.1 Master Plan 2019 Subzone Boundary (No Sea)\nFor shapefile format, two arguments are required: dsn to define the data path, and layer to provide the shapefile name. \n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MPSZ-2019\") %&gt;%\n    st_transform(crs = 3414)\n\n\n\n\n\n\n\nImportant\n\n\n\nProject Transformation\nGiven that our dataset corresponds to the geographical boundaries of Singapore, it is necessary to specify the appropriate CRS for accurate spatial analysis. To achieve this, the st_transform() function is used to convert the CRS of mpsz_sf to SVY21 (EPSG: 3414)\n\n\n\n\n2.3.2 Coastal Outline\nIn order to create a costal outline of singapore, we will use the st_union function to consolidate all subzone boundaries from mpsz_sf into a single polygon.\n\noutline = mpsz_sf %&gt;% st_union()\nplot(outline)\n\n\n\n2.3.2.1 Extracting Outer Islands\nAs seen in the figure above, the coastal outline includes outer islands where Grab service is unavailable. Through the code chunk below, we use the subset function to select subzones from the mpsz_sf dataset to exclude. These excluded rows of data are stored in new dataframes.\n\nsemakau &lt;- subset(mpsz_sf,mpsz_sf$SUBZONE_N == \"SEMAKAU\") #western island\nsudong &lt;- subset(mpsz_sf, mpsz_sf$SUBZONE_N == \"SUDONG\") #western island\nbukom &lt;- subset(mpsz_sf, mpsz_sf$SUBZONE_N ==  \"JURONG ISLAND AND BUKOM\")\nnorth &lt;- subset(mpsz_sf, mpsz_sf$SUBZONE_N == \"NORTH-EASTERN ISLANDS\")\nsouth &lt;- subset(mpsz_sf, mpsz_sf$SUBZONE_N == \"SOUTHERN GROUP\")\n\nWe combine the newly created dataframes using the bind_rows function and store the data in another dataframe called outer.\n\nouter &lt;- dplyr::bind_rows(list(semakau,sudong,bukom,north,south))\n\n\n\n2.3.2.2 Rendering a Coastal Boundary Excluding Outer Islands\nWe use the st_union function again to merge the geometries of mpsz_sf and outer, and the st_difference function to eliminate the overlap between the two layers. This results in a coastal boundary, sg_sf, which excludes the outer islands.\n\nsg_sf &lt;- st_difference(st_union(mpsz_sf), st_union(outer))\nplot(sg_sf)\n\n\n\n\n\n\n\nTip\n\n\n\n✅ Task Complete! We have obtained the coastal boundary layer of Singapore, excluding the outer islands.\n\n\n\n\n2.3.3 Open Street Map Road Data\nLet’s import the road data obtained from OSM.\n\nallroads = st_read(dsn = \"data/geospatial/OSM\", \n                         layer = \"gis_osm_roads_free_1\")  %&gt;% st_transform(crs = 3414)\n\n\n\n\n\n\n\nImportant\n\n\n\nProject Transformation\nGiven that our dataset corresponds to the geographical boundaries of Singapore, it’s necessary to specify the appropriate CRS for accurate spatial analysis. To achieve this, the st_transform() function is used to convert the CRS of allroads to SVY21 (EPSG: 3414)\n\n\nThis dataset encompasses road networks spanning Singapore, Malaysia, and Brunei. To narrow our focus, we will extract roads exclusively within the Singapore boundary using the st_intersection function to check the intersection between sg_sf and allroads.\n\nsg_roads_all &lt;- st_intersection(allroads,sg_sf)\n\nThe next step involves examining the various road types within the road network.\n\nunique(sg_roads_all$fclass)\n\nGiven our focus on Grab services, which primarily operate on roads excluding expressways (it is not possible for Grab to pick-up or drop off passengers along expressways), we will extract the relevant road types from the road network. To determine which roads are applicable, we can look at the OSM fclass. The image below provides descriptions for each road type, and for our analysis, we will focus on the most relevant types: primary, residential, tertiary, service, secondary, primary_link, secondary_link, and tertiary_link\n\nWe store the selected road types in a dataframe called sg_roads_filtered.\n\nsg_roads_filtered &lt;- c(\"primary\", \"residential\", \"tertiary\", \"service\", \"secondary\", \"primary_link\", \"secondary_link\", \"tertiary_link\")\n\n\nsg_roads &lt;- sg_roads_all[sg_roads_all$fclass %in% sg_roads_filtered, ]\n\nunique(sg_roads$fclass)\n\nWe will now visualise the selected road types within the boundaries of Singapore using tmap.\n\nroad_type_palette &lt;- brewer.pal(12, \"Set3\")\ntmap_mode('view')\ntm_shape(sg_sf) + \n  tm_borders(lwd = 2, col = 'grey') +\n  tm_shape(sg_roads) + \n  tm_lines(col = \"fclass\", palette = road_type_palette)\n  tm_layout(frame = FALSE, main.title = \"Types of Road Networks in Singapore\")\n\n\n\n\n\n\n\nTip\n\n\n\n✅ Task Complete! We have extracted the road layer within Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-aspatial-datasets",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-aspatial-datasets",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "2.4 Importing Aspatial Datasets",
    "text": "2.4 Importing Aspatial Datasets\n\n2.4.1 Grab-Posisi\nGrab-Posisi, is a GPS trajectory dataset. Each trajectory is serialised in a file in Apache Parquet format.\nWe will use the read_parquet function from the arrow package, to read Parquet files.\n\ngrab0 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00000.parquet\", as_data_frame = TRUE)\ngrab1 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00001.parquet\", as_data_frame = TRUE)\ngrab2 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00002.parquet\", as_data_frame = TRUE)\ngrab3 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00003.parquet\", as_data_frame = TRUE)\ngrab4 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00004.parquet\", as_data_frame = TRUE)\ngrab5 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00005.parquet\", as_data_frame = TRUE)\ngrab6 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00006.parquet\", as_data_frame = TRUE)\ngrab7 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00007.parquet\", as_data_frame = TRUE)\ngrab8 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00008.parquet\", as_data_frame = TRUE)\ngrab9 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00009.parquet\", as_data_frame = TRUE)\n\nThen we join all the read files into one dataframe.\n\ngrab &lt;- bind_rows(grab0,grab1, grab2,grab3,grab4,grab5,grab6,grab7,grab8,grab9) \n\n\nhead(grab)\n\nThe head function reveals that there are 9 columns in the dataframe.\nThe field pingtimestamp is not in proper date-time format. It is stored as an int value. The following code chunk converts the data type of pingtimestamp from int to date-time format.\n\ngrab$pingtimestamp &lt;- as_datetime(grab$pingtimestamp)\n\n\n\n2.4.1.2 Converting Aspatial Data Frame into a Simple Feature Data Frame\nWe will proceed to convert the grab dataset, currently in an aspatial data frame, into an sf tibble dataframe.\n\ngrab_sf &lt;- st_as_sf(grab, \n                       coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\n\n# write_rds(grab_sf, \"data/rds/grab_sf.rds\")\ngrab_sf &lt;- read_rds(\"data/rds/grab_sf.rds\")\n\n\n\n\n\n\n\nImportant\n\n\n\nProject Transformation\nAssuming the dataset is initially in the WGS84 Geographic Coordinate System, as indicated by the latitude/longitude fields, we need to define the suitable CRS for spatial analysis within Singapore. The st_transform() function is utilised to convert the CRS of the grab dataset to SVY21 (EPSG: 3414).\n\n\nThis gives us the new simple feature data frame, grab_sf"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "2.5 Data Wrangling",
    "text": "2.5 Data Wrangling\n\n2.5.1 Extracting Grab Trips Starting Locations\nWe will extract trip starting point for all unqiue trajectories and store them to a new df named grab_origin. To isolate the origin locations, we use the following methodology:\n\nGrouping by Trajectory ID:\n\nThe dataset is grouped by the unique trajectory identifier (trj_id).\n\nArranging by Timestamp:\n\nWithin each trajectory group, records are arranged in ascending order based on the timestamp (pingtimestamp).\n\nFiltering for the First Row:\n\nBy selecting the first row within each grouped trajectory (row_number() == 1), we identify the earliest recorded location for each trip. This is indicative of the trip’s starting point.\n\nAdding Temporal Information:\n\nAdditional temporal context is provided by introducing new columns:\n\nweekday: Day of the week based on the timestamp\nstart_hr: Starting hour of the trip\nday: Day of the month when the trip started\n\n\n\n\ngrab_origin &lt;- grab_sf %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(pingtimestamp) %&gt;%\n  filter(row_number()==1) %&gt;% #after sorting by timestamp, first row gives origin location \n  mutate(weekday = wday(pingtimestamp, #define workday\n                        label = TRUE,\n                        abbr = TRUE), #Monday = MON \n        start_hr = factor(hour(pingtimestamp)),\n        day = factor(mday(pingtimestamp))) #to change to ordinal scale\n\n\n#write_rds(grab_origin, \"data/rds/grab_origin.rds\")\ngrab_origin &lt;- read_rds(\"data/rds/grab_origin.rds\")\n\n\n\n\n\n\n\nTip\n\n\n\n✅ Task Complete! We have retrieved the origin location coordinates for Grab services.\n\n\n\n\n2.5.2 Extracting Grab Trips Ending Locations\nWe will extract trip ending point for all unique trajectories and store them to a new df named grab_dest. We employ a similar methodology to extracting a trips origin location. Except here, within each trajectory group, records are arranged in descending order based on the timestamp (pingtimestamp). By selecting the first row within each grouped trajectory (row_number() == 1), we identify the latest recorded location for each trip. This corresponds to the trip’s ending point.\n\ngrab_dest &lt;- grab_sf %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(desc(pingtimestamp)) %&gt;% #function from dplyr\n  filter(row_number()==1) %&gt;% #first row after arranging in desc order gives dest  \n  mutate(weekday = wday(pingtimestamp, #define workday\n                        label = TRUE,\n                        abbr = TRUE), #Monday = MON \n        end_hr = factor(hour(pingtimestamp)),\n        day = factor(mday(pingtimestamp))) #to change to ordinal scale\n\n\n#write_rds(grab_dest, \"data/rds/grab_dest.rds\")\ngrab_dest &lt;- read_rds(\"data/rds/grab_dest.rds\")\n\n\n\n\n\n\n\nTip\n\n\n\n✅ Task Complete! We have retrieved the destination location coordinates for Grab services.\n\n\n\n\n2.5.3 Converting Simple Features to Planar Point Pattern Objects\nTo perform spatial point pattern analysis, firstly, we’ll need to convert the simple features objects (grab_orign and grab_dest) into Spatial* classes. For this we use as.ppp from spatstat package. The st_coordinates function extracts the coordiates from our sf objects and st_bbox will extract the minimum and maximum coordinates of the object along each axis.\n\ngrab_origin_ppp &lt;- as.ppp(st_coordinates(grab_origin), st_bbox(grab_origin))\n\npar(mar = c(1,1,1,1))\nplot(grab_origin_ppp, main = \"Grab Origin Points as PPP Objects\")\n\n\ngrab_dest_ppp &lt;- as.ppp(st_coordinates(grab_dest), st_bbox(grab_dest))\n\npar(mar = c(1,1,1,1))\nplot(grab_dest_ppp, main = \"Grab Destination Points as PPP Objects\")\n\n\n\n\n\n\n\nTip\n\n\n\nIt is not neccessary to change sg_sf into a ppp object as it will be converted to owin instead.\n\n\n\n\n2.5.4 Check for Duplicates and Handle Data Errors\nLet’s have a look at the ppp objects we have created to make sure that there is no duplicates or errors in our data.\n\nsummary(grab_origin_ppp)\nsummary(grab_dest_ppp)\n\n\n\n\n\n\n\nNote\n\n\n\ngrab_origin_ppp and grab_dest_ppp objects have no duplicated points, but just to be sure, we check again using the any(duplicated() function.\n\n\n\nany(duplicated(grab_origin_ppp)) \nany(duplicated(grab_dest_ppp)) \n\nThe output is false for both objects so we move on to the next step.\n\n\n2.5.5 Introducing OWIN\nWhen analysing spatial point patterns, we’ll confine our analysis within a certain geographical area - such as the Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\n\n\n2.5.5.1 Creating OWIN Object\nTo create a two dimensional observation window using sg_sf coastal boundary we created earlier, we use the as.owin function.\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n2.5.5.2 Combining Point Events and OWIN Object\nNow, we’ll extract the relevant point events that are located within Singapore.\n\n\n2.5.5.2.1 Origin Points in OWIN Object\n\ngrab_origin_ppp_sg &lt;- grab_origin_ppp[sg_owin]\npar(mar = c(1,1,1,1))\nplot(grab_origin_ppp_sg, main = '[OWIN] Grab Origin Points' )\n\n\n\n2.5.5.2.1 Destination Points in OWIN Object\n\ngrab_dest_ppp_sg &lt;- grab_dest_ppp[sg_owin]\npar(mar = c(1,1,1,1))\nplot(grab_dest_ppp_sg, main = '[OWIN] Grab Destination Points' )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "3.0 Exploratory Data Analysis",
    "text": "3.0 Exploratory Data Analysis\nTo better understand the spatial data, we employ a series of exploratory techniques.\n\n3.1 Spatial Relationship between Origin and Destination Points\nThe map below shows the geographical distribution of origin and destination points. By overlaying both sets of points, we can observe areas where origin and destination locations overlap. These overlapping areas indicate regions with bidirectional travel.\n\ncombined_map &lt;- ggplot() +\n  geom_sf(data = grab_origin, aes(color = \"Origin\"), alpha = 0.7) +\n  geom_sf(data = grab_dest, aes(color = \"Destination\"), alpha = 0.7) +\n  ggtitle(\"Spatial Relationship Between Origin and Destination Locations\") +\n  labs(color = \"Location Type\") +\n  scale_color_manual(values = c(\"Origin\" = \"blue\", \"Destination\" = \"red\"), \n                     name = \"Location Type\", \n                     labels = c(\"Origin\", \"Destination\")) +\n  theme_minimal()\n\nprint(combined_map)\n\n\n\n3.2 Spatio-Temporal Visualisations\nSpatio-temporal visualisations show us a view of how data evolves over both space and time. These visualisations are particularly useful for analysing patterns, trends, and relationships within datasets.\n\n\n3.2.1 Frequency of Trip by Hour\nLet’s create interactive plots to provide an insightful representation of the distribution of origin/destination locations and emphasise the specific hours that stand out in terms of pickup/drop-off frequency.\n\n\n3.2.1.1 Origin or Pickup Frequency\nFor creating a bar plot with ggplot, the pickup hours are first converted to numeric values for analysis. TThe x-axis represents the pickup hours, and the y-axis represents the count of origin locations. To highlight the hours with the highest count with a visual indication, we add a red dashed vertical line on the plot. The ggplot object is then converted into an interactive plot using ggplotly, allowing users to hover over bars for detailed information.\n\ngrab_origin$start_hr &lt;- as.numeric(grab_origin$start_hr)\norg&lt;- ggplot(data = grab_origin, aes(x = start_hr)) +\n  geom_bar() +\n  labs(title = \"Distribution of Origin Locations by Pickup Hour\",\n       x = \"Pickup Hour\",\n       y = \"Count\") +\n  scale_x_continuous(breaks = seq(0, 24, by = 1)) +\n  theme_minimal()\nmax_hour &lt;- which.max(table(grab_origin$start_hr))\norg &lt;- org + geom_vline(xintercept = max_hour, linetype = \"dashed\", color = \"red\")\n\norg &lt;- ggplotly(org)\norg\n\nThe chart above indicates that most pickups occur at 2-3pm, a potential reason could include:\n\nAfter-School Activities: this time period may coincide with school release times and after-school activities. Parents might be picking up children or transporting them to various activities.\n\n\n\n3.2.1.2 Destination or Drop-off Frequency\nFor creating a bar plot with ggplot, the drop-off hours are first converted to numeric values for analysis. TThe x-axis represents the drop-off hours, and the y-axis represents the count of destination locations. To highlight the hours with the highest count with a visual indication, we add a red dashed vertical line on the plot. The ggplot object is then converted into an interactive plot using ggplotly, allowing users to hover over bars for detailed information.\n\ngrab_dest$end_hr &lt;- as.numeric(grab_dest$end_hr)\ndest&lt;- ggplot(data = grab_dest, aes(x = end_hr)) +\n  geom_bar() +\n  labs(title = \"Distribution of Destinatioon Locations by Drop-off Hour\",\n       x = \"Drop-off Hour\",\n       y = \"Count\") +\n  scale_x_continuous(breaks = seq(0, 24, by = 1)) +\n  theme_minimal()\nmax_hour &lt;- which.max(table(grab_dest$end_hr))\ndest &lt;- dest + geom_vline(xintercept = max_hour, linetype = \"dashed\", color = \"red\")\n\ndest &lt;- ggplotly(dest)\ndest\n\nThe chart above indicates that most drop-offs occur at 2pm, a potential reason could include:\n\nLunchtime Rush: 2pm is often around the time people finish their lunch breaks. This could result in increased travel demand as people return to work or resume their activities.\n\n\n\n3.2.2 Frequency of Trip by Day of Week\nLet’s create a bar chart to explore the frequency of origins/destinations across different days and identify any noteworthy patterns.\n\n\n3.2.2.1 Origin or Pickup Frequency by Days\nThe code uses ggplot to create a bar plot, where each bar represents the frequency of pickups on a specific day. This code produces a informative visualisation to explore patterns in pickup frequency throughout the week.\n\norigin_day &lt;- ggplot(data = grab_origin, aes(x = weekday))  +\n              geom_bar(fill = \"#4C78A8\", color = \"#4C78A8\", alpha = 0.8) +\n              labs(title = \"Frequency of Pickup by Day of Week\",\n                   x = \"Day\",\n                   y = \"Count\") +\n              theme_minimal()\norigin_day &lt;- ggplotly(origin_day)\norigin_day\n\n\nThe distribution of trips across days appears generally uniform, with a subtle increase observed on Wednesdays.\n\n\n\n3.2.2.2 Destination or Drop-off Frequency by Days\nThe code uses ggplot to create a bar plot, where each bar represents the frequency of drop-offs on a specific day. This code produces a informative visualisation to explore patterns in drop-off frequency throughout the week.\n\ndest_day &lt;- ggplot(data = grab_dest, aes(x = weekday))  +\n              geom_bar(fill = \"#FF0000\", color = \"#FF0000\", alpha = 0.8) +\n              labs(title = \"Frequency of Drop-off by Day of Week\",\n                   x = \"Day\",\n                   y = \"Count\") +\n              theme_minimal()\ndest_day &lt;- ggplotly(dest_day)\ndest_day\n\n\nIf we plot by destination, we see the same result. This is expected, considering that each trip’s origin corresponds to a destination."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#first-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#first-order-spatial-point-patterns-analysis",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "4.0 First-Order Spatial Point Patterns Analysis",
    "text": "4.0 First-Order Spatial Point Patterns Analysis\nFirst-order spatial point pattern analysis focuses on the distribution of individual points in a given spatial domain. It involves examining the basic characteristics and properties of the point pattern itself, without considering the interactions or relationship between points.\n\n4.1 Rescale grab_original_ppp_sg and grab_dest_ppp_sg\nFor further analysis, it is necessary to convert our data to kilometers, and we can achieve this by utilising the rescale function on grab_original_ppp_sg and grab_dest_ppp_sg which are in metres.\n\ngrab_origin_ppp_sg_km &lt;- rescale(grab_origin_ppp_sg, 1000, 'km')\ngrab_dest_ppp_sg_km &lt;- rescale(grab_dest_ppp_sg, 1000, 'km')\n\n\n\n4.2 Kernel Density Estimation\nKernel Density Estimation (KDE) is a technique used in spatial point pattern analysis to estimate the density of events across a continuous space based on a set of observed point locations. It is particularly when we have a set of spatial points and want to visualise the spatial distribution of these points in a smoother and more continuous way.\nThe are different approaches for selecting the bandwidth or smoothing parameter of the kernel.\n\nautomatic bandwidth method\nfixed bandwidth method\n\n\n\n4.2.1 Automatic bandwidth method\nHere the bandwidth is determined automatically by the algorithm based on some optimisation criterion.\nThere are several spatstat functions that we can use for automatic bandwidth selection.\nThe density function allows us to compute a kernel density for a given set of point events.\nFirst, we use the bw.diggle() method.\n\nbw.diggle() Cross Validated Bandwidth Selection for Kernel Density\n\n\nkde_grab_origin_sg_bw &lt;- density(grab_origin_ppp_sg_km,\n                                   sigma=bw.diggle,\n                                   edge=TRUE,\n                                   kernel=\"gaussian\")\n\n\npar(mar = c(1,1,1,1))\nplot(kde_grab_origin_sg_bw,main = \"KDE Automatic Bandwidth for Origin Points\")\n\n\nkde_grab_dest_sg_bw &lt;- density(grab_dest_ppp_sg_km,\n                                   sigma=bw.diggle,\n                                   edge=TRUE,\n                                   kernel=\"gaussian\")\nkde_grab_dest_sg_bw\n\n\npar(mar = c(1,1,1,1))\nplot(kde_grab_dest_sg_bw,main = \"KDE Automatic Bandwidth for Destination Points\")\n\n\n\n4.2.1.1 Other Bandwidth Selection Methods\nAdditionally we can choose from a series of options for ‘kernel’ which is the smoothing parameter that we will explore later. Lets explore the other methods for automatic bandwidth selection and retrieve sigma value. The sigma value tells us the amount of smoothing applied when estimating the kernel density.\n\nbw.diggle() Cross Validated Bandwidth Selection for Kernel Density\n\n\nbw_diggle &lt;- bw.diggle(grab_origin_ppp_sg_km)\nbw_diggle\n\n\nbw.CvL() Cronie and Van Lieshout’s Criterion for Bandwidth Selection for Kernel Density\n\n\nbw_CvL &lt;- bw.CvL(grab_origin_ppp_sg_km)\nbw_CvL\n\n\nbw.scott() Scott’s Rule for Bandwidth Selection for Kernel Density\n\n\nbw_scott &lt;- bw.scott(grab_origin_ppp_sg_km)\nbw_scott\n\n\nbw.ppl() Likelihood Cross Validation Bandwidth Selection for Kernel Density\n\n\nbw_ppl &lt;- bw.ppl(grab_origin_ppp_sg_km)\nbw_ppl\n\nLet’s plot to compare the output of each method, so that we can see the distinct differences in KDE layers .\n\nkde_diggle &lt;- density(grab_origin_ppp_sg_km, bw_diggle)\nkde_CvL &lt;- density(grab_origin_ppp_sg_km, bw_CvL)\nkde_scott &lt;- density(grab_origin_ppp_sg_km, bw_scott)\nkde_ppl &lt;- density(grab_origin_ppp_sg_km, bw_ppl)\n\npar(mfrow = c(2,2), mar = c(1,1,1,1))\nplot(kde_diggle,main = \"KDE diggle\")\nplot(kde_CvL,main = \"KDE CvL\")\nplot(kde_scott,main = \"KDE Scott\")\nplot(kde_ppl,main = \"KDE ppl\")\n\n\nFrom first glance, it looks as though KDE Scott shows the best resuts with the clearest peaks.\nBut in order to pick the most suitable method for our analysis, we need to compare the distribution of KDE values. We can do so simply by visualising the distribution using histograms. Let’s check again KDE Scott shows the most ideal result.\n\n\npar(mfrow = c(2,2),mar = c(3,3,3,3))\nhist(kde_diggle,main = \"KDE diggle\")\nabline(v=50, \n       col=\"red\")\nhist(kde_CvL,main = \"KDE CvL\")\nabline(v=50, \n       col=\"red\")\nhist(kde_scott,main = \"KDE Scott\")\nabline(v=50, \n       col=\"red\")\nhist(kde_ppl,main = \"KDE ppl\")\nabline(v=50, \n       col=\"red\")\n\n\n\n4.2.1.2 Choosing the Most Appropriate KDE Selection Method\n\nLooking at the histograms, the one for bw_scott() shows that it has a broad spread as compared to the others and does not peak which means there is an even distribution of points across all bins. Therefore we will pick bw_scott().\n\n\n\n4.2.2 Fixed Bandwidth Selection\nHere, we manually specify a fixed bandwidth value for the KDE layer. This allows us to control the level of smoothing applied to the point pattern. We will plot using bw_scott()as identified previously as the most suitable method.\n\nfixed_bw_scott &lt;- bw.scott(grab_origin_ppp_sg_km)\nfixed_bw_scott\n\nThe values returned are 1.59 and 0.94 for sigma.x and sigma.y respectively.\nThen, we plot to visualise the fixed bandwidth using bw_scott\n\nkde_fixed_bw_scott &lt;- density(grab_origin_ppp_sg_km, fixed_bw_scott)\npar(mar = c(1,1,1,1))\nplot(kde_fixed_bw_scott, main ='Scott Method Fixed Bandwidth KDE for Origin Points')\n\n\n\n4.2.3 Different Kernel Function Selection Methods for Fixed Bandwidth\nThe default kernel in density.ppp() is the gaussian. There are other options such as epanechnikov, quartic and disc.\nLet’s explore the different kernel function selection methods.\n\nkde_fixed_bw_scott_gaussian &lt;- density(grab_origin_ppp_sg_km, \n                          sigma=fixed_bw_scott, \n                          edge=TRUE, \n                          kernel=\"gaussian\")\n\n\nkde_fixed_bw_scott_epanechnikov &lt;- density(grab_origin_ppp_sg_km, \n                          sigma=fixed_bw_scott, \n                          edge=TRUE, \n                          kernel=\"epanechnikov\")\n   \nkde_fixed_bw_scott_quartic &lt;- density(grab_origin_ppp_sg_km, \n                          sigma=fixed_bw_scott, \n                          edge=TRUE, \n                          kernel=\"quartic\")\n       \n   \nkde_fixed_scott_disc &lt;- density(grab_origin_ppp_sg_km, \n                          sigma=fixed_bw_scott, \n                          edge=TRUE, \n                          kernel=\"disc\")\n\nLet’s visualise the different kernel methods.\n\npar(mfrow = c(2,2), mar = c(2,2,2,2))\nplot(kde_fixed_bw_scott_gaussian, main=\"Gaussian\")\nplot(kde_fixed_bw_scott_epanechnikov, main=\"Epanechnikov\")\nplot(kde_fixed_bw_scott_quartic, main=\"Quartic\")\nplot(kde_fixed_scott_disc,main=\"Disc\")\n\nThere are subtle differences in the smoothness and dispersion among the four plots, but they collectively show the same pattern in the end.\n\n\n4.2.3 KDE Layers with Spatially Adaptive Bandwidth\nHere, we use the most common adaptive bandwidth method called Adaptive Kernel Density Estimate.\n\nkde_adaptive &lt;- adaptive.density(grab_origin_ppp_sg_km, method=\"kernel\")\n\n\n\n4.2.4 Comparing Fixed and Adaptive Bandwidth\nLet’s do a side-by-side comparision of fixed bandwidth and adaptive bandwidth method .\n\npar(mfrow=c(1,2), mar = c(3,3,3,3))\nplot(kde_fixed_bw_scott_gaussian, main = \"Fixed bandwidth\")\nplot(kde_adaptive, main = \"Adaptive bandwidth\")\n\n\nThe fixed bandwidth method makes it easier to identify areas of higher origin point clusters\n\n\n\n4.2.5 Interactive KDE Maps\nNow lets plot interactive KDE maps to have a closer look.\n\n\n4.2.5.1 Converting KDE Output into Grid Object into RasterLayer Object\nWe need to convert our KDE output into grid objects for mapping purposes, here we use the raster() function.\n\nkde_fixed_bw_scott_raster &lt;- raster(kde_fixed_bw_scott)\nkde_adaptive_kernel_raster &lt;- raster(kde_adaptive)\n\nThen we perform project transformation.\n\nprojection(kde_fixed_bw_scott_raster) &lt;- CRS(\"+init=EPSG:3414 +units=km\")\nprojection(kde_adaptive_kernel_raster) &lt;- CRS(\"+init=EPSG:3414 +units=km\")\n\n\n\n4.2.5.2 Kernel Density Maps on OpenStreetMap\nFinally, we can visualise our Kernel Density Maps on OpenStreetMap\n\ntmap_mode('view')\nkde_fixed_bw_scott_map &lt;- tm_basemap(\"OpenStreetMap\") +\n  tm_view(set.zoom.limits=c(10, 15)) +\n  tm_shape(kde_fixed_bw_scott_raster) +\n  tm_raster(alpha = 0.65, title = \"KDE_Fixed_Scott\", palette = brewer.pal(12, \"Set3\")) +\n  tm_shape(mpsz_sf)+\n  tm_polygons(alpha=0.1, id=\"PLN_AREA_N\")+\n  tmap_options(check.and.fix = TRUE)+\n  tm_layout(title = \"Scott Method Fixed Bandwidth KDE for Origin Points\")\ntmap_leaflet(kde_fixed_bw_scott_map)\n\n\ntmap_mode('view')\nkde_adaptive_kernel_map &lt;- tm_basemap(\"OpenStreetMap\") +\n  tm_view(set.zoom.limits=c(10, 15)) +\n  tm_shape(kde_adaptive_kernel_raster) +\n  tm_raster(alpha = 0.65, title = \"KDE_Adaptive_Kernel\", palette = brewer.pal(12, \"Set3\")) +\n  tm_shape(mpsz_sf)+\n  tm_polygons(alpha=0.1, id=\"PLN_AREA_N\")+\n  tmap_options(check.and.fix = TRUE)+\n  tm_layout(title = \"Adaptive Bandwidth KDE for Origin Points\")\ntmap_leaflet(kde_adaptive_kernel_map)\n\n\n\n4.2.6 Kernel Density Map Analysis\nLet’s begin by extracting insights from the fixed bandwidth map, where it’s notably easier to identify the high-density pickup areas represented by yellow clusters. A prominent cluster emerges in the central-south region, encompassing stations such as Newton, Orchard, Downtown East, and Rochor. These areas exhibit increased demand for Grab pickups, potentially influenced by their status as tourist attractions. The tendency for individuals to explore these locales and then opt for Grab as their origin point prompts questions about the efficacy of public transport planning in encouraging more sustainable transportation choices.\nAdditionally, a big cluster forms at Changi Airport, which is quite understandable. Travelers landing in Singapore, often fatigued and burdened with luggage, may prefer the convenience of Grab over public transportation for their journey home.\nBeyond these, smaller yet discernible clusters show up in various residential zones. Referencing the adaptive bandwidth map for precise locations, we observe clusters in the north (Choa Chu Kang, Bukit Panjang), west (Jurong West, Jurong East), east (Tampines, Pasir Ris), and north-east (Woodlands, Sembawang, Yishun). This prompts further inquiries into the connectivity of these regions to public transport networks and the factors influencing residents to choose Grab over alternative transportation modes.\nIn essence, these spatial patterns raise intriguing questions about the accessibility and appeal of public transportation in these specific areas.\n\n\n4.2.7 Extract Planning Areas\nFrom the array of residential clusters pinpointed in the previous section, we will focus on four specific stations, each corresponding to distinct geographical regions: north, east, west, and north-east.\n\nNorth: Choa Chu Kang\nWest: Jurong East\nEast: Tampines\nNorth-East: Woodlands\n\nLet’s extract out these study areas from mpsz_sf using filter and store it in new objects.\n\nje = mpsz_sf%&gt;%\n  filter(PLN_AREA_N == \"JURONG EAST\")\ntm = mpsz_sf%&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck = mpsz_sf%&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\nwd = mpsz_sf%&gt;%\n  filter(PLN_AREA_N == \"WOODLANDS\")\n\n\n\n4.2.7.1 Plotting Target Planning Areas\n\npar(mfrow=c(2,2))\nplot(st_geometry(je), main = \"Jurong East\")\nplot(st_geometry(tm), main = \"Tampines\")\nplot(st_geometry(ck), main = \"Choa Chu Kang\")\nplot(st_geometry(wd), main = \"Woodlands\")\n\nNext, we will create owin objects to represent the observation windows for respective planning area.\n\nje_owin = as.owin(je)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\nwd_owin = as.owin(wd)\n\norigin_je_ppp = grab_origin_ppp_sg[je_owin]\norigin_tm_ppp = grab_origin_ppp_sg[tm_owin]\norigin_ck_ppp = grab_origin_ppp_sg[ck_owin]\norigin_wd_ppp = grab_origin_ppp_sg[wd_owin]\n\n\n4.2.7.2 KDE Fixed-Bandwidth for Target Planning Areas\n\nje_kde_scott &lt;- density(origin_je_ppp, sigma=bw.scott, main=\"Jurong East\")\ntm_kde_scott &lt;- density(origin_tm_ppp, sigma=bw.scott, main=\"Tampines\")\nck_kde_scott &lt;- density(origin_ck_ppp, sigma=bw.scott, main=\"Choa Chu Kang\")\nwd_kde_scott &lt;- density(origin_wd_ppp, sigma=bw.scott, main=\"Woodlands\")\n\n\npar(mfrow = c(2,2))\nplot(je_kde_scott,main = \"KDE Jurong East\")\nplot(tm_kde_scott,main = \"KDE Tampines\")\nplot(ck_kde_scott,main = \"KDE Choa Chu Kang\")\nplot(wd_kde_scott,main = \"KDE Woodlands\")\n\nNow, identifying clusters within each planning area is easily achievable. However, pinpointing the exact locations of these clusters requires the incorporation of road networks for each planning area. To achieve this precision, we will leverage a more advanced KDE technique known as Network Kernel Density Estimation (NKDE) in the upcoming sections. This approach will provide deeper insights into the specific roads or areas within each planning area that host these clusters.\n\n\n\n4.2.8 Nearest Neighbour Analysis\nNearest Neighbor Analysis helps assess whether the observed spatial pattern is clustered, dispersed, or random.\nHere we will be using the Clark-Evans Test of Aggregation.\n\n\n4.2.8.1 Clark-Evans Test of Aggregation\nHere, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\n\n\n4.2.8.1.1 Origin Points in Jurong East\nThe test hypotheses are:\n\nH0 = The distribution of origin points in Jurong East are randomly distributed\nH1= The distribution of origin points in Jurong East are not randomly distributed\n\nThe 95% confident interval will be used.\n\nclarkevans.test(origin_je_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\nWe can conclude that the distribution of origin points in Jurong East is not randomly distributed\n\n\n4.2.8.1.2 Origin Points in Tampines\nThe test hypotheses are:\n\nH0 = The distribution of origin points in Tampines are randomly distributed\nH1= The distribution of origin points in Tampines are not randomly distributed\n\nThe 95% confidence interval will be used.\n\nclarkevans.test(origin_tm_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\nWe can conclude that the distribution of origin points in Tampines is not randomly distributed\n\n\n4.2.8.1.3 Origin Points in Choa Chu Kang\nThe test hypotheses are:\n\nH0 = The distribution of origin points in Choa Chu Kang are randomly distributed\nH1= The distribution of origin points in Choa Chu Kang are not randomly distributed\n\nThe 95% confidence interval will be used.\n\nclarkevans.test(origin_ck_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\nWe can conclude that the distribution of origin points in Choa Chu Kang is not randomly distributed\n\n\n4.2.8.1.4 Origin Points in Woodlands\nThe test hypotheses are:\n\nH0 = The distribution of origin points in Woodlands are randomly distributed\nH1= The distribution of origin points in Woodlands are not randomly distributed\n\nThe 95% confidence interval will be used.\n\nclarkevans.test(origin_wd_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\nWe can conclude that the distribution of origin points in Woodlands is not randomly distributed"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-constrained-kernel-density-estimation-nkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-constrained-kernel-density-estimation-nkde",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "5.0 Network Constrained Kernel Density Estimation (NKDE)",
    "text": "5.0 Network Constrained Kernel Density Estimation (NKDE)\nNetwork Kernel Density Estimation (NKDE) is an advanced technique that builds upon the traditional KDE method.\nWe employ NKDE because the distribution of origin points in our planning areas is not randomly distributed; it is significantly influenced by network structures. NKDE allows us to incorporate this network context, providing a more accurate representation of spatial patterns, particularly along roadways. By considering the connectivity and pathways of the network, NKDE enhances our ability to capture the nuanced distribution of clusters within each planning area, leading to more insightful and precise spatial analysis results\nThe main difference between the KDE and NKDE is that KDE treats space as a continuous field, and overlooks the underlying network structure, such as roads. NKDE takes into account the network structure, and recognises that spatial relationships may be constrained by the existing road infrastructure. Therefore, NKDE offers better localization of clusters by considering the connectivity and pathways of the network.\nHere, we will use spNetwork to create NKDE maps for each of our planning areas and explore what insights we can yield from each."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extract-origin-points-and-road-network-of-our-study-areas",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extract-origin-points-and-road-network-of-our-study-areas",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "5.1 Extract origin points and road network of our study areas",
    "text": "5.1 Extract origin points and road network of our study areas\nFirstly we need to extract the road networks within each of our study area by using st_intersection. We also use st_union to combine all the geometries of each object into a single geometry.\n\nje_roads = st_intersection(sg_roads,st_union(je))\ntm_roads = st_intersection(sg_roads,st_union(tm))\nck_roads = st_intersection(sg_roads,st_union(ck))\nwd_roads = st_intersection(sg_roads,st_union(wd))\n\nAfter that, we will use st_intersection again to find the origin spots that intersect with our planning areas.\n\nje_origin = st_intersection(grab_origin,st_union(je))\ntm_origin = st_intersection(grab_origin,st_union(tm))\nck_origin = st_intersection(grab_origin,st_union(ck))\nwd_origin = st_intersection(grab_origin,st_union(wd))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#lixels",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#lixels",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "5.2 Lixels",
    "text": "5.2 Lixels\nEach network edge is divided into lixels which represent the lines of the network. To get the lixels of each planning area we use the st_cast function first to convert the geometry types of the features in our object to LINESTRING.\n\nje_roads &lt;- st_cast(je_roads, \"LINESTRING\")\ntm_roads &lt;- st_cast(tm_roads, \"LINESTRING\")\nck_roads &lt;- st_cast(ck_roads, \"LINESTRING\")\nwd_roads &lt;- st_cast(wd_roads, \"LINESTRING\")\n\nAfter we have converted the geometry type of our planning areas, we use lixelize_lines to create lixels from a set of road lines represented by the planning area objects. The road lines are divided into lixels, each with a length of 750 units. mindist represents the minimum distance between lixels to ensure that resulting lixels are not too close to each other. If the length of the resulting lixel is less than the specified minimum distance, it is combined with the previous lixel.\n\nje_lixels &lt;- lixelize_lines(je_roads, \n                         750, \n                         mindist = 375)\n\ntm_lixels &lt;- lixelize_lines(tm_roads, \n                         750, \n                         mindist = 375)\n\nck_lixels &lt;- lixelize_lines(ck_roads, \n                         750, \n                         mindist = 375)\n\nwd_lixels &lt;- lixelize_lines(wd_roads, \n                         750, \n                         mindist = 375)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#line-center",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#line-center",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "5.3 Line Center",
    "text": "5.3 Line Center\nThen we extract the centers of the lixels using lines_center. These serve as the locations for intensity estimation.\n\nje_samples &lt;- lines_center(je_lixels)\ntm_samples &lt;- lines_center(tm_lixels)\nck_samples &lt;- lines_center(ck_lixels)\nwd_samples &lt;- lines_center(wd_lixels)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#using-simple-method-to-compute-nkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#using-simple-method-to-compute-nkde",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "5.4 Using Simple Method to Compute NKDE",
    "text": "5.4 Using Simple Method to Compute NKDE\nFinally we use the nkde function from spNetwork to get the NKDE. There are several parameters that we can define\n\nevents: the event associated with the analysis\nw: weight vector, creates a vector of ones with a length equal to the number of rows in the planning area data frame\nsamples: samples used for density estimation\nkernel_name: type of kernel to be used\nbw: determines the scale of influence for each point in the density estimation\ndiv: the method used to determine the bandwidth\nmethod: method used for density estimation\ndigits: number of significant digits displayed in the output\ntol: tolerance level for convergence in iterative algorithms\ngrid_shape: shape of the grid for calculating the density\nmax_depth: Maximum depth of the tree when building the spatial index\nagg: number of points aggregated into each grid cell\nsparse: whether to use sparse matrix representation for efficiency\nverbose: suppresses verbose output during the process\n\n\nje_density &lt;- nkde(je_roads, \n                  events = je_origin,\n                  w = rep(1,nrow(je_origin)),\n                  samples = je_samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\ntm_density &lt;- nkde(tm_roads, \n                  events = tm_origin,\n                  w = rep(1,nrow(tm_origin)),\n                  samples = tm_samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nck_density &lt;- nkde(ck_roads, \n                  events = ck_origin,\n                  w = rep(1,nrow(ck_origin)),\n                  samples = ck_samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nwd_density &lt;- nkde(wd_roads, \n                  events = wd_origin,\n                  w = rep(1,nrow(wd_origin)),\n                  samples = wd_samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nWe are also required to join the density values into the samples and lixels objects. The obtained densities will be scaled by the total number of origin points and we will multiply by 1000 for km measurement.\n\nje_samples$density &lt;- je_density*nrow(je_origin)*1000\nje_lixels$density &lt;- je_density*nrow(je_origin)*1000\n\ntm_samples$density &lt;- tm_density*nrow(tm_origin)*1000\ntm_lixels$density &lt;- tm_density*nrow(tm_origin)*1000\n\nck_samples$density &lt;- ck_density*nrow(ck_origin)*1000\nck_lixels$density &lt;- ck_density*nrow(ck_origin)*1000\n\nwd_samples$density &lt;- wd_density*nrow(wd_origin)*1000\nwd_lixels$density &lt;- wd_density*nrow(wd_origin)*1000"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plotting-maps-for-different-study-areas",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plotting-maps-for-different-study-areas",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "5.5 Plotting Maps for Different Study Areas",
    "text": "5.5 Plotting Maps for Different Study Areas\nLet’s plot the NKDE map for each planning area.\n\n5.5.1 Jurong East\n\ntmap_mode('view')\nje_density_map &lt;- tm_basemap(\"OpenStreetMap\") +\ntm_shape(je_lixels)+\n  tm_lines(col =\"density\", lwd = 3, palette = brewer.pal(12, \"Set3\"))+\ntm_shape(je_origin)+\n  tm_dots(size=0.05)+\n  tm_layout(title = \"Jurong East NKDE\")\ntmap_leaflet(je_density_map)\n\n\n\n\n\n\n\nNote\n\n\n\nAnalysis\nIn Jurong East, notable clusters of taxi pick-up points have been observed around Yuhua Place, Yuhua Senior Activity Center, New Jurong Polyclinic, and the nursing home vicinity. Additionally, clusters are prevalent near Parc Oasis, Singtel, Zai Shun Seafood, in proximity to Toh Guan, Westgate, Shen Hong Temple, Jurong East Interchange, IMM, Yuhua Primary School, and Crest Secondary School.\nThis clustering phenomenon may be attributed to\n\nCommercial Hubs: Areas like Westgate and IMM are major commercial centers, attracting a higher demand for Grab services. For example, people may book Grab to pick them up after they finish shopping in these areas.\nHealthcare Facilities: Proximity to healthcare facilities such as the New Jurong Polyclinic and nursing homes may lead to increased transportation needs. For example, patients or visitors might utilise Grab for convenient travel from medical appointments, contributing to the clustering effect around healthcare establishments.\nEducational Institutions: The presence of schools like Yuhua Primary School and Crest Secondary School could contribute to higher Grab demand during school-related activities. For example, parents may pick up their children after school and book Grab to their residence.\nTransportation Hubs: Jurong East Interchange serves as a transportation hub, leading to concentrated Grab activity in the area. Commuters arriving at or departing from the interchange might prefer Grab for last-mile connectivity, resulting in a clustering effect around this transportation hub.\nRecreational Areas: Clusters around Parc Oasis and Yuhua Senior Activity Center may be influenced by recreational and leisure activities. Caregivers visiting seniors at the Senior Activity Center may book Grab from there to their homes.\nCultural and Religious Centers: Locations like Shen Hong Temple may attract Grab pick-ups during events or gatherings. Attendees of cultural or religious events may use Grab for transportation from these centers.\nResidential Areas: Proximity to residential areas like Yuhua Place may result in frequent Grab pickup requests for residents. Residents in these areas might regularly utilise Grab for daily commuting or transportation needs.\nCulinary Hotspots: Clusters around Zai Shun Seafood restaurant may be influenced by popular dining establishments, drawing people to the area and making them book Grab from there to their journey back.\n\n\n\n\n\n5.5.2 Tampines\n\ntmap_mode('view')\ntm_density_map &lt;- tm_basemap(\"OpenStreetMap\") +\ntm_shape(tm_lixels)+\n  tm_lines(col =\"density\", lwd = 3, palette = brewer.pal(12, \"Set3\"))+\ntm_shape(tm_origin)+\n  tm_dots(size=0.05)+\n  tm_layout(title = \"Tampines NKDE\")\ntmap_leaflet(tm_density_map)\n\n\n\n\n\n\n\nNote\n\n\n\nAnalysis\nIn Tampines, clusters of Grab pick-up points are notable around Our Tampines Hub, Tanah Merah Country Club, opposite Tampines Neighbourhood Police Center, opposite Ngee Ann Secondary School, Tampines East, Laguna Country Club, and East Coast Park.\nThis clustering phenomenon may be attributed to\nRecreational Clubs: Areas like Tanah Merah Country Club and Laguna Country Club may contribute to clusters of Grab pick-up points. Individuals visiting these recreational clubs for leisure activities may opt for Grab services for their journey back from here for convenience.\nPolice Center: The area opposite Tampines Neighbourhood Police Center may attract Grab pick-ups due visitors requiring transportation from the area.\nCommunity and Recreational Center: Our Tampines Hub is a central community and recreational center, leading to higher demand for Grab services. People utilising the various facilities may book Grab for their journeys back.\nEducational Institutions: The area opposite Ngee Ann Secondary School could contribute to higher Grab demand during school-related activities. For example, parents may pick up their children after school and book Grab to their residence.\nResidential Areas: Tampines East, being a residential area, may result in frequent Grab pickup requests for residents. Residents in these areas might regularly utilise Grab for daily commuting or transportation needs.\nRecreational Destination: East Coast Park, a popular recreational area, may attract individuals for outdoor activities. Visitors to the park may choose to book Grab for their journey back home, contributing to the clustering effect.\n\n\n\n\n5.5.3 Choa Chu Kang\n\ntmap_mode('view')\nck_density_map &lt;- tm_basemap(\"OpenStreetMap\") +\ntm_shape(ck_lixels)+\n  tm_lines(col =\"density\", lwd = 3, palette = brewer.pal(12, \"Set3\"))+\ntm_shape(ck_origin)+\n  tm_dots(size=0.05)+\n  tm_layout(title = \"Choa Chu Kang NKDE\")\ntmap_leaflet(ck_density_map)\n\n\n\n\n\n\n\nNote\n\n\n\nAnalysis\nIn Choa Chu Kang, clusters of Grab pick-up points can be seen around Inn See Temple, Choa Chu Kang Interchange, SAFRA@CCK, Gain City, Lot One, Keat Hong Colours, Phoenix Station, Bukit Panjang Post Office, Yew Mei Condominium, MWS Nursing Home, and Yew Tee Point.\nThis clustering phenomenon may be attributed to\n\nCultural and Religious Centers: Inn See Temple’s vicinity may attract Grab pick-ups during religious events, contributing to the observed cluster.\nTransportation Hub: Choa Chu Kang Interchange serves as a transportation hub, leading to concentrated Grab activity in the area. Commuters arriving at or departing from the interchange might prefer Grab for last-mile connectivity, resulting in a clustering effect around this transportation hub.\nRecreational Facility: The presence of SAFRA@CCK could contribute to increased Grab pickup activity, especially after events and recreational activities hosted at the facility.\nShopping Centers: Yew Tee Point, Gain City and Lot One, being prominent shopping destinations, may experience a higher level of Grab pick-up points as shoppers prefer convenient transportation after their shopping sprees.\nResidential Areas: Clusters around Keat Hong Colours, and Yew Mei Condominium may be attributed to the residential nature of these areas, with residents relying on Grab for commuting needs.\nPostal Area: Bukit Panjang Post Office may attract Grab pick-ups, for individuals who have completed their postal services or nearby activities.\nHealthcare: Presence of MWS Nursing Home may lead to increased transportation needs. Caregivers visiting seniors at the nursing home may book Grab from there to their homes.\n\n\n\n\n\n5.5.4 Woodlands\n\ntmap_mode('view')\nwd_density_map &lt;- tm_basemap(\"OpenStreetMap\") +\ntm_shape(wd_lixels)+\n  tm_lines(col =\"density\", lwd = 3, palette = brewer.pal(12, \"Set3\"))+\ntm_shape(wd_origin)+\n  tm_dots(size=0.05)+\n  tm_layout(title = \"Woodlands NKDE\")\ntmap_leaflet(wd_density_map)\n\n\n\n\n\n\n\nNote\n\n\n\nIn Woodlands, distinct clusters of taxi pick-up points have been identified around Innova Junior College, Singapore Sports School, Civic Centre, STELLAR@TE2, Singapore Turf Club, Old Woodlands Town Centre, Masjid An Nur, Woodlands Cinema, Greenwood Primary School, and Mega@Woodlands.\nThis clustering phenomenon may be attributed to\n\nEducational Institutions: Clusters around Innova Junior College and Singapore Sports School could be attributed to the presence of these educational institutions. Students, staff, and visitors may opt for Grab for convenient transportation from these locations.\nCivic and Community Center: Civic Centre, being a civic and community hub, may experience higher demand for Grab pickup services.\nCommercial Hub: STELLAR@TE2’s may have individuals possibly relying on Grab for commuting on their journey back from here.\nSports and Recreation: The presence of Singapore Turf Club may contribute to the clustering effect, with people choosing Grab for transportation from sports and recreational activities.\nCommercial and Residential Hub: Old Woodlands Town Centre’s central location may attract Grab pick-ups from both commercial and residential areas.\nReligious Center: Masjid An Nur’s may witness increased Grab activity during religious events.\nEntertainment Venue: Woodlands Cinema’s indicates a potential concentration of Grab pick-up points, especially after movie screenings, as patrons opt for Grab for their journey home.\nEducational Facility: Greenwood Primary School’s location could contribute to higher Grab demand during school-related activities. For example, parents may pick up their children after school and book Grab to their residence."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusion",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "6.0 Conclusion",
    "text": "6.0 Conclusion\nThrough this take-home exercise, we delved into Spatial Point Patterns Analysis to unravel the geographical distribution of Grab Hailing Services in Singapore. Our analyses provided valuable insights, unveiling patterns such as the peak day and time for Grab pick-ups, the specific locations where these pickups occur, hotspots, and the particular roads that witness heightened activity. This information serves as a strategic tool for better planning and decision-making.\nFor instance, we can leverage these findings to enhance public transport accessibility. Understanding the road networks with the highest Grab pick-up activity allows us to identify areas where improved public transportation services could be implemented. This strategic planning aims to encourage people to opt for public transport, contributing to even pollution reduction by minimising car usage.\nIn our future endeavors, we can expand our exploration by delving into temporal Network Kernel Density Estimation (NKDE). This advanced analysis will enable us to scrutinise the intricate relationship between time and Grab Hailing Services. By identifying popular pick-up points during specific time intervals, we can propose strategic interventions, such as increasing the number of buses, adjusting bus frequencies, or implementing targeted measures to enhance transportation infrastructure in those areas. This forward-looking approach ensures a nuanced understanding of temporal patterns and facilitates more informed decisions for optimizing transportation services in Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#references",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#references",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore",
    "section": "7.0 References",
    "text": "7.0 References\n\nKam, T. S. (2022). R for Geospatial Data Science and Analytics. Retrieved from https://r4gdsa.netlify.app.\nGimond (2023). Chapter 11 Point Pattern Analysis. Retrieved from https://mgimond.github.io/Spatial/index.html.\nRey, S.J., Arribas-Bel, D., & Wolf, L.J. (2023). Point Pattern Analysis. In: Geographic Data Science with python. CRC Press.\nMoraga, P. Spatial Statistics for Data Science: Theory and Practice with R. Retrieved from https://www.paulamoraga.com/book-spatial/spatial-point-patterns.html."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this exercise, I will:\n\ninstall and load of basic R packages\nhandle geospatial files\nplot geospatial data\n\n\n\n\nMaster Plan 2014 Subzone Boundary (Web)\nPre-Schools Location\nCycling Path\nSingapore Airbnb Listing CSV\n\n\n\n\nIn this exercise, we will use the tidyverse and sf packages. The p_load function from the package will assist in installing and loading these packages.\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#datasets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#datasets",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "Master Plan 2014 Subzone Boundary (Web)\nPre-Schools Location\nCycling Path\nSingapore Airbnb Listing CSV"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this exercise, we will use the tidyverse and sf packages. The p_load function from the package will assist in installing and loading these packages.\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#master-plan-2014-subzone-boundary",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#master-plan-2014-subzone-boundary",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.2.1 Master Plan 2014 Subzone Boundary",
    "text": "1.2.1 Master Plan 2014 Subzone Boundary\n\n\n\n\n\n\nNote\n\n\n\n\ndsn: filepath\nlayer: file name\n\n\n\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\fathimak2020\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe projected CRS of mpsz is SVY21."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#cycling-path",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#cycling-path",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.2.2 Cycling Path",
    "text": "1.2.2 Cycling Path\n\ncyclingpath = st_read(dsn=\"data/geospatial\",\n                       layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\fathimak2020\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe projected CRS of cyclingpath is SVY21."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#pre-schools-location",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#pre-schools-location",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.2.3 Pre-Schools Location",
    "text": "1.2.3 Pre-Schools Location\n\npreschool = st_read(dsn = \"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\fathimak2020\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe Geodetic CRS of prechool is WGS 84."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#retrieve-geometries",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#retrieve-geometries",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.3.1 Retrieve Geometries",
    "text": "1.3.1 Retrieve Geometries\nst_geometry(mpsz) displays basic information of the geometries.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#view-attributes-in-simple-feature-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#view-attributes-in-simple-feature-dataframe",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.3.2 View Attributes in simple feature DataFrame",
    "text": "1.3.2 View Attributes in simple feature DataFrame\nglimpse() will retrieve each field’s datatype.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#view-complete-information-of-feature-object",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#view-complete-information-of-feature-object",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.3.3 View Complete Information of Feature Object",
    "text": "1.3.3 View Complete Information of Feature Object\nRetrieve top 5 feature object’s complete information.\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometry-plot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometry-plot",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.4.1 Geometry Plot",
    "text": "1.4.1 Geometry Plot\nThe code will display a plot with only the basic geometry.\n\nplot(st_geometry(mpsz))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#attribute-plot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#attribute-plot",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.4.2 Attribute Plot",
    "text": "1.4.2 Attribute Plot\nWe can also specify the column of interest to plot only the selected feature.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.5.1 Assigning EPSG code",
    "text": "1.5.1 Assigning EPSG code\nIn MPSZ, the EPSG code is 9001 although it is projected in SVY21.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nst_set_crs() can be used for EPSG code assignment to 3414.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-projection",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.5.2 Transforming Projection",
    "text": "1.5.2 Transforming Projection\nThe geographic coordinate system is not suitable for distance and area measurements. Therefore, transforming from a geographic coordinate system to a projected coordinate system is necessary. To achieve this transformation, use st_transform().\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.6.1 Importing Aspatial Data",
    "text": "1.6.1 Importing Aspatial Data\nWe get a Tibble from using the function read_csv()\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nlatitude and longitude are the columns that we are interested to look at."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#converting-from-aspatial-dataframe-to-simple-feature-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#converting-from-aspatial-dataframe-to-simple-feature-dataframe",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.6.2 Converting from Aspatial DataFrame to Simple Feature DataFrame",
    "text": "1.6.2 Converting from Aspatial DataFrame to Simple Feature DataFrame\nParameters for st_as_sf():\n\ncoords: Column names for x and y coordinates\ncrs: Coordinate system in EPSG format\n%&gt;% nests st_transform() to convert the DataFrame into SVY21 projected CRS\n\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThe new sf DataFrame can be seen below.\n\nglimpse(listings_sf)\n\nRows: 3,457\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nAs seen, longtitude and latitude columns are dropped, and a geometry column is added."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.7.1 Buffering",
    "text": "1.7.1 Buffering\n\nScenario\nThe authority intends to enhance the existing cycling path. To achieve this, they must obtain 5 meters of reserved land on both sides of the current cycling path. Your responsibility is to ascertain the extent of the land that needs to be acquired and calculate its total area.\n\nst_buffer() is used to calculate buffers.\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                            dist=5, nQuadSegs = 30)\n\nst_area() will compute the area of the buffers and generate an AREA column for buffer_cycling\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nTo derive total land, sum() is used\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.7.2 Point in Polygon Count",
    "text": "1.7.2 Point in Polygon Count\n\nScenario\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\n\nPreschools within each planning subzone are identified using st_intersects(). The number of preschools in each subzone is then calculated using Length(). \n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\ntop_n() will find the planning subzone with the highest number of pre-schools\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nParamters of top_n:\n\nx: DataFrame\nn: Number of rows to return\nwt: Ordering"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#density-of-pre-schools-by-planning-subzones",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#density-of-pre-schools-by-planning-subzones",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.7.3 Density of Pre-schools by Planning Subzones",
    "text": "1.7.3 Density of Pre-schools by Planning Subzones\nUse st_area() to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nmutate() will compute density and create “PreSch Density” column.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#histogram",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#histogram",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.8.1 Histogram",
    "text": "1.8.1 Histogram\nPlotting a histogram using hist() from base R\n\nhist(mpsz3414$`PreSch Density`)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#ggplot2-library",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#ggplot2-library",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.8.2 ggplot2 Library",
    "text": "1.8.2 ggplot2 Library\n\nggplot(data = mpsz3414,\n       aes(x = as.numeric(`PreSch Density`))) +\n    geom_histogram(bins = 20,\n                   color = \"darkgrey\",\n                   fill = \"lavender\") +\n    labs(title = \"Are pre-schools evenly distributed in Singapore?\",\n         subtitle = \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n         x = \"Pre-school density (per km sq)\",\n         y = \"Frequency\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#scatterplot",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.8.3 Scatterplot",
    "text": "1.8.3 Scatterplot\n\nggplot(data = mpsz3414,\n       aes(y = `PreSch Count`,\n            x = as.numeric(`PreSch Density`))) +\n    geom_point(color = \"darkorange\",\n               fill = \"mintcream\") +\n    xlim(0, 40) +\n    ylim(0, 40) +\n    labs(title = \"Are pre-schools evenly distributed in Singapore?\",\n         x = \"Pre-school density (per km sq)\",\n         y = \"Pre-school count\")"
  }
]