[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me!",
    "section": "",
    "text": "Hello! I am Fathima, a Y4 Information Systems from Singapore Management University ðŸ˜¸"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "title": "Hands-on Exercise 9:Geographically Weighted Predictive Models",
    "section": "",
    "text": "Predictive modelling uses statistical learning or machine learning techniques to predict outcomes. By and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models.\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. When geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur. Geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#preparing-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#preparing-data",
    "title": "Hands-on Exercise 9:Geographically Weighted Predictive Models",
    "section": "9.2 Preparing Data",
    "text": "9.2 Preparing Data\n\n9.2.1 Reading Data File to rds\n\nmdata &lt;- read_rds(\"data/aspatial/mdata.rds\")\n\n\n\n9.2.2 Data Sampling\n\nset.seed(1234)\nresale_split &lt;- initial_split(mdata, \n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\n\nwrite_rds(train_data, \"data/model/train_data.rds\")\nwrite_rds(test_data, \"data/model/test_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#computing-correlation-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#computing-correlation-matrix",
    "title": "Hands-on Exercise 9:Geographically Weighted Predictive Models",
    "section": "9.3 Computing Correlation Matrix",
    "text": "9.3 Computing Correlation Matrix\n\nmdata_nogeo &lt;- mdata %&gt;%\n  st_drop_geometry()\ncorrplot::corrplot(cor(mdata_nogeo[, 2:17]), \n                   diag = FALSE, \n                   order = \"AOE\",\n                   tl.pos = \"td\", \n                   tl.cex = 0.5, \n                   method = \"number\", \n                   type = \"upper\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#retriving-the-stored-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#retriving-the-stored-data",
    "title": "Hands-on Exercise 9:Geographically Weighted Predictive Models",
    "section": "9.4 Retriving the Stored Data",
    "text": "9.4 Retriving the Stored Data\n\ntrain_data &lt;- read_rds(\"data/model/train_data.rds\")\ntest_data &lt;- read_rds(\"data/model/test_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-a-non-spatial-multiple-linear-regression",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-a-non-spatial-multiple-linear-regression",
    "title": "Hands-on Exercise 9:Geographically Weighted Predictive Models",
    "section": "9.5 Building a Non-spatial Multiple Linear Regression",
    "text": "9.5 Building a Non-spatial Multiple Linear Regression\n\nprice_mlr &lt;- lm(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_data)\nsummary(price_mlr)\n\n\nwrite_rds(price_mlr, \"model/price_mlr.rds\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#gwr-predictive-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#gwr-predictive-method",
    "title": "Hands-on Exercise 9:Geographically Weighted Predictive Models",
    "section": "9.6 GWR Predictive Method",
    "text": "9.6 GWR Predictive Method\n\n9.6.1 Converting the sf data.frame to SpatialPointDataFrame\n\ntrain_data_sp &lt;- as_Spatial(train_data)\ntrain_data_sp\n\n\n\n9.6.2 Computing Adaptive Bandwidth\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\nwrite_rds(bw_adaptive, \"data/model/bw_adaptive.rds\")\n\n\n\n9.6.3 Constructing the Adaptive Bandwidth GWR Model\n\nbw_adaptive &lt;- read_rds(\"data/model/bw_adaptive.rds\")\n\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data_sp,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n\n\nwrite_rds(gwr_adaptive, \"data/model/gwr_adaptive.rds\")\n\n\n\n9.6.4 Retrieve GWR Output Object\n\ngwr_adaptive &lt;- read_rds(\"data/model/gwr_adaptive.rds\")\n\n\ngwr_adaptive\n\n\n\n9.6.5 Converting the Test Data from Special Feature Data Frame to Spatial Point Data Frame\n\ntest_data_sp &lt;- test_data %&gt;%\n  as_Spatial()\ntest_data_sp\n\n\n\n9.6.6 Computing Adaptive Bandwidth for the Test Data\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\n\n9.6.7 Computing Predicted Values of the Test Data\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data_sp, \n                        predictdata = test_data_sp, \n                        bw=40, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#preparing-coordinates-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#preparing-coordinates-data",
    "title": "Hands-on Exercise 9:Geographically Weighted Predictive Models",
    "section": "9.7 Preparing Coordinates Data",
    "text": "9.7 Preparing Coordinates Data\n\n9.7.1 Extracting Coordinates Data\n\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\n\ncoords_train &lt;- write_rds(coords_train, \"data/model/coords_train.rds\" )\ncoords_test &lt;- write_rds(coords_test, \"data/model/coords_test.rds\" )\n\n\n\n9.7.2 Dropping Geometry Field\n\ntrain_data &lt;- train_data %&gt;% \n  st_drop_geometry()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#calibrating-random-forest-model",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#calibrating-random-forest-model",
    "title": "Hands-on Exercise 9:Geographically Weighted Predictive Models",
    "section": "9.8 Calibrating Random Forest Model",
    "text": "9.8 Calibrating Random Forest Model\n\nset.seed(1234)\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data=train_data)\nrf\n\n\nwrite_rds(rf, \"data/model/rf.rds\")\n\n\nrf &lt;- read_rds(\"data/model/rf.rds\")\nrf"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#calibrating-geographical-random-forest-model",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#calibrating-geographical-random-forest-model",
    "title": "Hands-on Exercise 9:Geographically Weighted Predictive Models",
    "section": "9.9 Calibrating Geographical Random Forest Model",
    "text": "9.9 Calibrating Geographical Random Forest Model\n\n9.9.1 Calibrating using Training Data\n\nset.seed(1234)\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data, \n                     bw=55,\n                     kernel=\"adaptive\",\n                     coords=coords_train)\n\n\nwrite_rds(gwRF_adaptive, \"data/model/gwRF_adaptive.rds\")\n\n\ngwRF_adaptive &lt;- read_rds(\"data/model/gwRF_adaptive.rds\")\n\n\n\n9.9.2 Predicting by using Test Data\n\n9.9.2.1 Preparing the Test Data\n\ntest_data &lt;- cbind(test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\n\n\n9.9.2.2 Predicting with Test Data\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n\n\nGRF_pred &lt;- write_rds(gwRF_pred, \"data/model/GRF_pred.rds\")\n\n\n\n9.9.2.3 Converting the Predicting Output into a Data Frame\n\nGRF_pred &lt;- read_rds(\"data/model/GRF_pred.rds\")\nGRF_pred_df &lt;- as.data.frame(GRF_pred)\n\n\ntest_data_p &lt;- cbind(test_data, GRF_pred_df)\n\n\nwrite_rds(test_data_p, \"data/model/test_data_p.rds\")\n\n\n\n\n9.9.3 Calculating Root Mean Square Error\n\nrmse(test_data_p$resale_price, \n     test_data_p$GRF_pred)\n\n\n\n9.9.4 Visualising the Predicted Values\n\nggplot(data = test_data_p,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "",
    "text": "This project investigates the determinants of public bus demand in Singapore through the application of Spatial Econometric Interaction Modeling. The findings offer valuable insights for urban planners, policymakers, and researchers aiming to optimise mixed-use developments and promote sustainable urban living through a deeper understanding of public bus demand factors."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-import-and-preparation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-import-and-preparation",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Data import and preparation",
    "text": "Data import and preparation\n\nImport R packages\n\npacman::p_load(sf, sfdep, tidyverse, tmap, spdep, knitr, leaflet, ggthemes, knitr, plotly, igraph, ggraph, corrplot, data.table, reshape2, heatmaply)\n\n\n\nImport data\nIn our analysis we need these data\n\nURAâ€™s Masterplan Subzone 2019 Layer\nBus Stop Locations (LTA)\nPassenger Volume by Origin Destination Bus Stops (LTA Data Mall)\nPopulation Data\nResidential Areas\nSchools from MOE\nPlaces of Interest\n\n\nAspatial data\n\nbus_nov &lt;- read_csv(\"data/origin_destination_bus_202311.csv\")\nbus_dec &lt;- read_csv(\"data/origin_destination_bus_202312.csv\")\nbus_jan &lt;- read_csv(\"data/origin_destination_bus_202401.csv\")\npopulation &lt;- read_csv(\"data/respopagesextod2011to2020.csv\")\n\n\n\nGeospatial data\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nbus_coords &lt;- read_csv(\"data/bus_stop.csv\")\n\nbusiness &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"Business\")\n  \nfininst &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"FinServ\")\n\nentertainment &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"entertn\")\n\nf_and_b &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"F&B\")\n\nleisure &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"Liesure&Recreation\")\n\nretail &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"Retails\") \n\nresidential &lt;- read_csv('data/hdb.csv')\n\nschools &lt;- read_csv('data/schoolsclean.csv')\n\nhospitals &lt;- read_csv('data/HospitalsPolyclinics v_2024.csv')"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "1.0 Data Preparation",
    "text": "1.0 Data Preparation\n\nbus_coords_sf &lt;- st_as_sf(bus_coords, coords = c(\"Longitude\", \"Latitude\"), crs = 4326)\n\n\nbus_coords_sf &lt;- st_transform(bus_coords_sf, st_crs(mpsz_sf))\n\n\nExtracting Singapore Bus Stop Locations\n\nsg_bus_stops &lt;- st_intersection(bus_coords_sf, mpsz_sf)\nbus_stop_subzone &lt;- st_intersection(sg_bus_stops, mpsz_sf)\nsg_bus_stops$Subzone &lt;- bus_stop_subzone$PLN_AREA_N\n\n\n\nAdding Subzone Information to Singapore Bus Stop Locations\n\nmerged_data &lt;- merge(bus_coords, sg_bus_stops, by = \"BusStopCode\", all.x = TRUE)\nbus_coords$Subzone &lt;- merged_data$PLN_AREA_N\nbus_coords &lt;- bus_coords[, c(\"BusStopCode\", \"RoadName\", \"Description\", \"Subzone\", \"Latitude\", \"Longitude\")]\nbus_coords_subzone &lt;- bus_coords\n\n\npunggol_end &lt;- data.frame(BusStopCode = 65139,\n                         RoadName = \"Punggol Rd\",\n                         Description = \"Punggol End/Punggol Jetty\",\n                         Subzone = \"PUNGGOL\",\n                         Latitude = 1.421640,\n                         Longitude = 103.9107)\n\nbus_coords_subzone &lt;- rbind(bus_coords_subzone, punggol_end)\n\n\n#write_rds(bus_coords_subzone, \"data/rds/bus_coords_subzone.rds\")\n\nNote: Bus Stop 65139 is missing from bus_coords, manually inserting a record for it."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#adding-bus-stop-description-coordinates-and-subzone-information-for-november-2023",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#adding-bus-stop-description-coordinates-and-subzone-information-for-november-2023",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Adding Bus Stop Description, Coordinates and Subzone Information for November 2023",
    "text": "Adding Bus Stop Description, Coordinates and Subzone Information for November 2023\n\nmerged_bus_nov &lt;- left_join(bus_nov, bus_coords_subzone, by = c(\"ORIGIN_PT_CODE\" = \"BusStopCode\")) %&gt;%\n  rename(ORIGIN_SUBZONE = Subzone, ORIGIN_DESCRIPTION = Description, ORIGIN_LAT = Latitude, ORIGIN_LONG = Longitude) %&gt;%\n  left_join(bus_coords, by = c(\"DESTINATION_PT_CODE\" = \"BusStopCode\")) %&gt;%\n  rename(DESTINATION_SUBZONE = Subzone, DESTINATION_DESCRIPTION = Description, DESTINATION_LAT = Latitude, DESTINATION_LONG = Longitude) %&gt;%\n  select(YEAR_MONTH, DAY_TYPE, TIME_PER_HOUR, PT_TYPE, \n         ORIGIN_PT_CODE, ORIGIN_SUBZONE, ORIGIN_DESCRIPTION, ORIGIN_LAT, ORIGIN_LONG,\n         DESTINATION_PT_CODE, DESTINATION_SUBZONE, DESTINATION_DESCRIPTION, DESTINATION_LAT, DESTINATION_LONG,\n         TOTAL_TRIPS)\n\n\nmerged_bus_nov &lt;- merged_bus_nov %&gt;%\n  mutate(DESTINATION_SUBZONE = ifelse(DESTINATION_PT_CODE == 65139, \"PUNGGOL\", DESTINATION_SUBZONE),\n         DESTINATION_DESCRIPTION = ifelse(DESTINATION_PT_CODE == 65139, \"Punggol End / Punggol Jetty\", DESTINATION_DESCRIPTION),\n         DESTINATION_LAT = ifelse(DESTINATION_PT_CODE == 65139, 1.421640, DESTINATION_LAT),\n         DESTINATION_LONG = ifelse(DESTINATION_PT_CODE == 65139, 103.9107, DESTINATION_LONG))\n\nNote: Bus Stop 65139 is missing from bus_coords, manually inserting a record for it."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#looking-for-na-values",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#looking-for-na-values",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Looking for NA values",
    "text": "Looking for NA values\n\nmissing_stops &lt;- merged_bus_nov %&gt;%\n  summarise(ORIGIN_NA = any(is.na(ORIGIN_DESCRIPTION)),\n            DESTINATION_NA = any(is.na(DESTINATION_DESCRIPTION)),\n            ORIGIN_PT_WITH_NA = ifelse(any(is.na(ORIGIN_DESCRIPTION)), unique(ORIGIN_PT_CODE[is.na(ORIGIN_DESCRIPTION)]), NA),\n            DESTINATION_PT_WITH_NA = ifelse(any(is.na(DESTINATION_DESCRIPTION)), unique(DESTINATION_PT_CODE[is.na(DESTINATION_DESCRIPTION)]), NA))\n\nprint(missing_stops)\n\n\n#write_rds(merged_bus_nov, \"data/rds/merged_bus_nov.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#adding-bus-stop-description-coordinates-and-subzone-information-for-december-2023",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#adding-bus-stop-description-coordinates-and-subzone-information-for-december-2023",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Adding Bus Stop Description, Coordinates and Subzone Information for December 2023",
    "text": "Adding Bus Stop Description, Coordinates and Subzone Information for December 2023\n\nmerged_bus_dec &lt;- left_join(bus_dec, bus_coords_subzone, by = c(\"ORIGIN_PT_CODE\" = \"BusStopCode\")) %&gt;%\n  rename(ORIGIN_SUBZONE = Subzone, ORIGIN_DESCRIPTION = Description, ORIGIN_LAT = Latitude, ORIGIN_LONG = Longitude) %&gt;%\n  left_join(bus_coords, by = c(\"DESTINATION_PT_CODE\" = \"BusStopCode\")) %&gt;%\n  rename(DESTINATION_SUBZONE = Subzone, DESTINATION_DESCRIPTION = Description, DESTINATION_LAT = Latitude, DESTINATION_LONG = Longitude) %&gt;%\n  select(YEAR_MONTH, DAY_TYPE, TIME_PER_HOUR, PT_TYPE, \n         ORIGIN_PT_CODE, ORIGIN_SUBZONE, ORIGIN_DESCRIPTION, ORIGIN_LAT, ORIGIN_LONG,\n         DESTINATION_PT_CODE, DESTINATION_SUBZONE, DESTINATION_DESCRIPTION, DESTINATION_LAT, DESTINATION_LONG,\n         TOTAL_TRIPS)\n\n\nmerged_bus_dec &lt;- merged_bus_dec %&gt;%\n  mutate(DESTINATION_SUBZONE = ifelse(DESTINATION_PT_CODE == 65139, \"PUNGGOL\", DESTINATION_SUBZONE),\n         DESTINATION_DESCRIPTION = ifelse(DESTINATION_PT_CODE == 65139, \"Punggol End / Punggol Jetty\", DESTINATION_DESCRIPTION),\n         DESTINATION_LAT = ifelse(DESTINATION_PT_CODE == 65139, 1.421640, DESTINATION_LAT),\n         DESTINATION_LONG = ifelse(DESTINATION_PT_CODE == 65139, 103.9107, DESTINATION_LONG))\n\nNote: Bus Stop 65139 is missing from bus_coords, manually inserting a record for it."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#looking-for-na-values-1",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#looking-for-na-values-1",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Looking for NA values",
    "text": "Looking for NA values\n\nmissing_stops_dec &lt;- merged_bus_dec %&gt;%\n  summarise(ORIGIN_NA = any(is.na(ORIGIN_DESCRIPTION)),\n            DESTINATION_NA = any(is.na(DESTINATION_DESCRIPTION)),\n            ORIGIN_PT_WITH_NA = ifelse(any(is.na(ORIGIN_DESCRIPTION)), unique(ORIGIN_PT_CODE[is.na(ORIGIN_DESCRIPTION)]), NA),\n            DESTINATION_PT_WITH_NA = ifelse(any(is.na(DESTINATION_DESCRIPTION)), unique(DESTINATION_PT_CODE[is.na(DESTINATION_DESCRIPTION)]), NA))\n\nprint(missing_stops_dec)\n\n\n#write_rds(merged_bus_dec, \"data/rds/merged_bus_dec.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#adding-bus-stop-description-coordinates-and-subzone-information-for-january-2024",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#adding-bus-stop-description-coordinates-and-subzone-information-for-january-2024",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Adding Bus Stop Description, Coordinates and Subzone Information for January 2024",
    "text": "Adding Bus Stop Description, Coordinates and Subzone Information for January 2024\n\nhead(bus_jan)\nhead(bus_dec)\n\nbus_jan$ORIGIN_PT_CODE &lt;- ifelse(nchar(bus_jan$ORIGIN_PT_CODE) == 4,\n                                  paste0(\"0\", bus_jan$ORIGIN_PT_CODE),\n                                  bus_jan$ORIGIN_PT_CODE)\n\nbus_jan$DESTINATION_PT_CODE &lt;- ifelse(nchar(bus_jan$DESTINATION_PT_CODE) == 4,\n                                       paste0(\"0\", bus_jan$DESTINATION_PT_CODE),\n                                       bus_jan$DESTINATION_PT_CODE)\n\nNote: 0s have been omitted from some bus stop codes, making them 4 digits long only. Bus stop codes have to be 5 digits long so adding a 0 infront of codes that are 4 digits long.\n\nbus_jan$ORIGIN_PT_CODE &lt;- as.character(bus_jan$ORIGIN_PT_CODE)\nbus_jan$DESTINATION_PT_CODE &lt;- as.character(bus_jan$DESTINATION_PT_CODE)\n\nmerged_bus_jan &lt;- left_join(bus_jan, bus_coords_subzone, by = c(\"ORIGIN_PT_CODE\" = \"BusStopCode\")) %&gt;%\n  rename(ORIGIN_SUBZONE = Subzone, ORIGIN_DESCRIPTION = Description, ORIGIN_LAT = Latitude, ORIGIN_LONG = Longitude) %&gt;%\n  left_join(bus_coords, by = c(\"DESTINATION_PT_CODE\" = \"BusStopCode\")) %&gt;%\n  rename(DESTINATION_SUBZONE = Subzone, DESTINATION_DESCRIPTION = Description, DESTINATION_LAT = Latitude, DESTINATION_LONG = Longitude) %&gt;%\n  select(YEAR_MONTH, DAY_TYPE, TIME_PER_HOUR, PT_TYPE, \n         ORIGIN_PT_CODE, ORIGIN_SUBZONE, ORIGIN_DESCRIPTION, ORIGIN_LAT, ORIGIN_LONG,\n         DESTINATION_PT_CODE, DESTINATION_SUBZONE, DESTINATION_DESCRIPTION, DESTINATION_LAT, DESTINATION_LONG,\n         TOTAL_TRIPS)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#looking-for-na-values-2",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#looking-for-na-values-2",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Looking for NA values",
    "text": "Looking for NA values\n\nmissing_stops_jan &lt;- merged_bus_jan %&gt;%\n  summarise(ORIGIN_NA = any(is.na(ORIGIN_DESCRIPTION)),\n            DESTINATION_NA = any(is.na(DESTINATION_DESCRIPTION)),\n            ORIGIN_PT_WITH_NA = ifelse(any(is.na(ORIGIN_DESCRIPTION)), unique(ORIGIN_PT_CODE[is.na(ORIGIN_DESCRIPTION)]), NA),\n            DESTINATION_PT_WITH_NA = ifelse(any(is.na(DESTINATION_DESCRIPTION)), unique(DESTINATION_PT_CODE[is.na(DESTINATION_DESCRIPTION)]), NA))\n\nprint(missing_stops_jan)\n\n\n#write_rds(merged_bus_jan, \"data/rds/merged_bus_jan.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#creating-spacetime-object-for-november-2023",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#creating-spacetime-object-for-november-2023",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Creating Spacetime Object for November 2023",
    "text": "Creating Spacetime Object for November 2023\n\nNovember 2023 Origin Trip Generation\n\n#for spacetime\nnov_trip_generation_origin &lt;- merged_bus_nov %&gt;%\n   select(ORIGIN_PT_CODE, TIME_PER_HOUR, TOTAL_TRIPS, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n  group_by(ORIGIN_PT_CODE, TIME_PER_HOUR, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n  summarise(`TRIPS GENERATED` = sum(`TOTAL_TRIPS`)) %&gt;%\n  ungroup() %&gt;%\n  st_as_sf(coords = c(\"ORIGIN_LAT\", \"ORIGIN_LONG\"),\n           crs=4326)\n\n\nnov_org_tg_spacetime &lt;- as_spacetime(nov_trip_generation_origin, \n                    \"ORIGIN_PT_CODE\", \n                    \"TIME_PER_HOUR\")\nnov_org_tg_spacetime\n\n\nis_spacetime_cube(nov_org_tg_spacetime)\n\n\n#write_rds(nov_trip_generation_origin, \"data/rds/nov_trip_generation_origin.rds\")\n\n\n\nNovember 2023 Destination Trip Generation\n\n# for spacetime \n# nov_trip_generation_dest &lt;- merged_bus_nov %&gt;%\n#    select(DESTINATION_PT_CODE, TIME_PER_HOUR, TOTAL_TRIPS, DESTINATION_LAT, DESTINATION_LONG) %&gt;%\n#   group_by(DESTINATION_PT_CODE, TIME_PER_HOUR, DESTINATION_LAT, DESTINATION_LONG) %&gt;%\n#   summarise(`TRIPS GENERATED` = sum(`TOTAL_TRIPS`)) %&gt;%\n#   ungroup() %&gt;%\n#   st_as_sf(coords = c(\"DESTINATION_LAT\", \"DESTINATION_LONG\"),\n#            crs=4326)\n\n\n# nov_dest_tg_spacetime &lt;- as_spacetime(nov_trip_generation_dest, \n#                     \"DESTINATION_PT_CODE\", \n#                     \"TIME_PER_HOUR\")\n# nov_dest_tg_spacetime\n\n\n# is_spacetime_cube(nov_dest_tg_spacetime)\n\n\n#write_rds(nov_trip_generation_dest, \"data/rds/nov_trip_generation_dest.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#creating-spacetime-object-for-december-2023",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#creating-spacetime-object-for-december-2023",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Creating Spacetime Object for December 2023",
    "text": "Creating Spacetime Object for December 2023\n\nDecember 2023 Origin Trip Generation\n\n# for spacetime \n# dec_trip_generation_origin &lt;- merged_bus_dec %&gt;%\n#    select(ORIGIN_PT_CODE, TIME_PER_HOUR, TOTAL_TRIPS, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n#   group_by(ORIGIN_PT_CODE, TIME_PER_HOUR, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n#   summarise(`TRIPS GENERATED` = sum(`TOTAL_TRIPS`)) %&gt;%\n#   ungroup() %&gt;%\n#   st_as_sf(coords = c(\"ORIGIN_LAT\", \"ORIGIN_LONG\"),\n#            crs=4326)\n\n\n# dec_org_tg_spacetime &lt;- as_spacetime(dec_trip_generation_origin, \n#                     \"ORIGIN_PT_CODE\", \n#                     \"TIME_PER_HOUR\")\n# dec_org_tg_spacetime\n\n\n# is_spacetime_cube(dec_org_tg_spacetime)\n\n\n#write_rds(dec_trip_generation_origin, \"data/rds/dec_trip_generation_origin.rds\")\n\n\n\nDecember 2023 Destination Trip Generation\n\n# for spacetime \n# dec_trip_generation_dest &lt;- merged_bus_dec %&gt;%\n#    select(DESTINATION_PT_CODE, TIME_PER_HOUR, TOTAL_TRIPS, DESTINATION_LAT, DESTINATION_LONG) %&gt;%\n#   group_by(DESTINATION_PT_CODE, TIME_PER_HOUR, DESTINATION_LAT, DESTINATION_LONG) %&gt;%\n#   summarise(`TRIPS GENERATED` = sum(`TOTAL_TRIPS`)) %&gt;%\n#   ungroup() %&gt;%\n#   st_as_sf(coords = c(\"DESTINATION_LAT\", \"DESTINATION_LONG\"),\n#            crs=4326)\n\n\n# dec_dest_tg_spacetime &lt;- as_spacetime(dec_trip_generation_dest, \n#                     \"DESTINATION_PT_CODE\", \n#                     \"TIME_PER_HOUR\")\n# dec_dest_tg_spacetime\n\n\n# is_spacetime_cube(dec_dest_tg_spacetime)\n\n\n#write_rds(dec_trip_generation_dest, \"data/rds/dec_trip_generation_dest.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#creating-spacetime-object-for-january-2024",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#creating-spacetime-object-for-january-2024",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Creating Spacetime Object for January 2024",
    "text": "Creating Spacetime Object for January 2024\n\nJanuary Origin Trip Generation\n\n# for spacetime \n# jan_trip_generation_origin &lt;- merged_bus_jan %&gt;%\n#    select(ORIGIN_PT_CODE, TIME_PER_HOUR, TOTAL_TRIPS, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n#   group_by(ORIGIN_PT_CODE, TIME_PER_HOUR, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n#   summarise(`TRIPS GENERATED` = sum(`TOTAL_TRIPS`)) %&gt;%\n#   ungroup() %&gt;%\n#   st_as_sf(coords = c(\"ORIGIN_LAT\", \"ORIGIN_LONG\"),\n#            crs=4326)\n\n\n# jan_org_tg_spacetime &lt;- as_spacetime(jan_trip_generation_origin, \n#                     \"ORIGIN_PT_CODE\", \n#                     \"TIME_PER_HOUR\")\n# jan_org_tg_spacetime\n\n\n# is_spacetime_cube(jan_org_tg_spacetime)\n\n\n#write_rds(jan_trip_generation_origin, \"data/rds/jan_trip_generation_origin.rds\")\n\n\n\nJanuary Destination Trip Generation\n\n# for spacetime \n# jan_trip_generation_dest &lt;- merged_bus_jan %&gt;%\n#    select(DESTINATION_PT_CODE, TIME_PER_HOUR, TOTAL_TRIPS, DESTINATION_LAT, DESTINATION_LONG) %&gt;%\n#   group_by(DESTINATION_PT_CODE, TIME_PER_HOUR, DESTINATION_LAT, DESTINATION_LONG) %&gt;%\n#   summarise(`TRIPS GENERATED` = sum(`TOTAL_TRIPS`)) %&gt;%\n#   ungroup() %&gt;%\n#   st_as_sf(coords = c(\"DESTINATION_LAT\", \"DESTINATION_LONG\"),\n#            crs=4326)\n\n\n# jan_dest_tg_spacetime &lt;- as_spacetime(jan_trip_generation_dest, \n#                     \"DESTINATION_PT_CODE\", \n#                     \"TIME_PER_HOUR\")\n# jan_dest_tg_spacetime\n\n\n# is_spacetime_cube(jan_dest_tg_spacetime)\n\n\n#write_rds(jan_trip_generation_dest, \"data/rds/jan_trip_generation_dest.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#converting-.rds-files-to-.csv-files",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#converting-.rds-files-to-.csv-files",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Converting .rds files to .csv files",
    "text": "Converting .rds files to .csv files\n\n# merged_bus_nov &lt;- read_rds(\"data/rds/merged_bus_nov.rds\")\n# write.csv(merged_bus_nov, file = \"data/merged_bus_nov.csv\", row.names = FALSE)\n\n\n # merged_bus_dec &lt;- read_rds(\"data/rds/merged_bus_dec.rds\")\n # write.csv(merged_bus_dec, file = \"data/merged_bus_dec.csv\", row.names = FALSE)\n\n\n# merged_bus_jan &lt;- read_rds(\"data/rds/merged_bus_jan.rds\")\n# write.csv(merged_bus_jan, file = \"data/merged_bus_jan.csv\", row.names = FALSE)\n\n\n # bus_coords_subzone &lt;- read_rds(\"data/rds/bus_coords_subzone.rds\")\n # write.csv(bus_coords_subzone, file = \"data/bus_coords_subzone.csv\", row.names = FALSE)\n\n_______________________________________________________________________________________________________________"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#business",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#business",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Business",
    "text": "Business\n\ntmap_mode('view')\ntm_shape(business) + \n  tm_bubbles(col = 'blue', size = 0.001, alpha = 0.5, border.col = \"lightgrey\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#financial-institutions",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#financial-institutions",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Financial Institutions",
    "text": "Financial Institutions\n\ntmap_mode('view')\ntm_shape(fininst) + \n  tm_bubbles(col = 'red', size = 0.001, alpha = 0.5, border.col = \"lightgrey\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#entertainment",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#entertainment",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Entertainment",
    "text": "Entertainment\n\ntmap_mode('view')\ntm_shape(entertainment) + \n  tm_bubbles(col = 'black', size = 0.001, alpha = 0.5, border.col = \"lightgrey\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#fb-outlets",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#fb-outlets",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "F&B Outlets",
    "text": "F&B Outlets\n\ntmap_mode('view')\ntm_shape(f_and_b) + \n  tm_bubbles(col = 'green', size = 0.001, alpha = 0.5, border.col = \"lightgrey\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#leisure-recreation-spots",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#leisure-recreation-spots",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Leisure & Recreation Spots",
    "text": "Leisure & Recreation Spots\n\ntmap_mode('view')\ntm_shape(leisure) + \n  tm_bubbles(col = 'orange', size = 0.001, alpha = 0.5, border.col = \"lightgrey\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#retail-shops",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#retail-shops",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Retail Shops",
    "text": "Retail Shops\n\ntmap_mode('view')\ntm_shape(retail) + \n  tm_bubbles(col = 'purple', size = 0.001, alpha = 0.5, border.col = \"lightgrey\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#schools",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#schools",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Schools",
    "text": "Schools\n\nschools &lt;- schools %&gt;%\n  separate(latlong, into = c(\"latitude\", \"longitude\"), sep = \",\", convert = TRUE)\n\nschools &lt;- st_as_sf(schools, coords = c(\"longitude\",\"latitude\"), crs = 4326) %&gt;% \n  st_transform(crs=3414)\n\n\ntmap_mode('view')\ntm_shape(schools) + \n  tm_bubbles(col = 'turquoise', size = 0.001, alpha = 0.5, border.col = \"lightgrey\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#hospitals-and-polyclinics",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#hospitals-and-polyclinics",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Hospitals and Polyclinics",
    "text": "Hospitals and Polyclinics\n\nhospitals1 &lt;- st_as_sf(hospitals[1:42,], wkt = \"geometry\", crs = 4326) %&gt;% \n  st_transform(crs=3414)\n\nhospitals2 &lt;- st_as_sf(hospitals[43:1235,], wkt = \"geometry\", crs = 3414)\n\nhospitals &lt;- rbind(hospitals1, hospitals2)\n\n\ntmap_mode('view')\ntm_shape(hospitals1) + \n  tm_bubbles(col = 'lavender', size = 0.001, alpha = 0.5, border.col = \"lightgrey\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#residential-areas",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#residential-areas",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Residential Areas",
    "text": "Residential Areas\n\nresidential &lt;- st_as_sf(residential, coords = c(\"lng\", \"lat\"), crs = 4326)\n\n\ntmap_mode('view')\ntm_shape(residential) + \n  tm_bubbles(col = 'pink', size = 0.001, alpha = 0.5, border.col = \"lightgrey\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation-1",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation-1",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Data Preparation",
    "text": "Data Preparation\n\npopulation &lt;- population %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\npopulation &lt;- population %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nmpsz_population &lt;- left_join(mpsz_sf, population,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#young-population",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#young-population",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Young Population",
    "text": "Young Population\n\ntmap_mode('view')\ntm_shape(mpsz_population)+\n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Greens\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#economically-active-population",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#economically-active-population",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Economically Active Population",
    "text": "Economically Active Population\n\ntmap_mode('view')\ntm_shape(mpsz_population)+\n  tm_polygons(\"ECONOMY ACTIVE\", \n              style = \"quantile\", \n              palette = \"Oranges\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#aged-population",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#aged-population",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Aged Population",
    "text": "Aged Population\n\ntmap_mode('view')\ntm_shape(mpsz_population)+\n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Reds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#total-population",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#total-population",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Total Population",
    "text": "Total Population\n\ntmap_mode('view')\ntm_shape(mpsz_population)+\n  tm_polygons(\"TOTAL\", \n              style = \"quantile\", \n              palette = \"Blues\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#function-to-create-graph",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#function-to-create-graph",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Function to Create Graph",
    "text": "Function to Create Graph\n\ncreate_graph &lt;- function(filename, plot_title, day_type) {\n  data &lt;- read.csv(filename) %&gt;%\n    filter(DAY_TYPE == day_type) %&gt;%\n    select(ORIGIN_PT_CODE, TIME_PER_HOUR, TOTAL_TRIPS, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n    group_by(ORIGIN_PT_CODE, TIME_PER_HOUR) %&gt;%\n    summarise(TRIPS_GENERATED = sum(TOTAL_TRIPS)) %&gt;%\n    ungroup()\n  \n  data$TIME_INTERVAL &lt;- as.factor(data$TIME_PER_HOUR)\n  \n  ggplot(data, aes(x=TIME_INTERVAL, y=TRIPS_GENERATED)) +\n    geom_bar(stat=\"identity\", fill=\"deepskyblue4\") +\n    ggtitle(plot_title) +\n    xlab(\"Time Interval\") +\n    ylab(\"Total Trips\")\n}"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#weekday-trend",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#weekday-trend",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Weekday Trend",
    "text": "Weekday Trend"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#november-2023",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#november-2023",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "November 2023",
    "text": "November 2023\n\nnov_day &lt;- create_graph(\"data/merged_bus_nov.csv\", \"November 2023 Weekday\", \"WEEKDAY\")\nnov_day"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#december-2023",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#december-2023",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "December 2023",
    "text": "December 2023\n\ndec_day &lt;- create_graph(\"data/merged_bus_dec.csv\", \"December 2023 Weekday\", \"WEEKDAY\")\ndec_day"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#january-2024",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#january-2024",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "January 2024",
    "text": "January 2024\n\njan_day &lt;- create_graph(\"data/merged_bus_jan.csv\", \"January 2024 Weekday\", \"WEEKDAY\")\njan_day"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#weekend-trend",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#weekend-trend",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Weekend Trend",
    "text": "Weekend Trend"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#november-2023-1",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#november-2023-1",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "November 2023",
    "text": "November 2023\n\nnov_end &lt;- create_graph(\"data/merged_bus_nov.csv\", \"November 2023 Weekend\", \"WEEKENDS/HOLIDAY\")\nnov_end"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#december-2023-1",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#december-2023-1",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "December 2023",
    "text": "December 2023\n\ndec_end &lt;- create_graph(\"data/merged_bus_dec.csv\", \"December 2023 Weekend\", \"WEEKENDS/HOLIDAY\")\ndec_end"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#january-2024-1",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#january-2024-1",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "January 2024",
    "text": "January 2024\n\njan_end &lt;- create_graph(\"data/merged_bus_jan.csv\", \"January 2024 Weekend\", \"WEEKENDS/HOLIDAY\")\njan_end"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#function-to-find-popular-stations",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#function-to-find-popular-stations",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Function to Find Popular Stations",
    "text": "Function to Find Popular Stations\n\nt5b5 &lt;- function(filename, plot_title, day_type, time_interval){\n  \n  df &lt;- edges &lt;- read_csv(filename) %&gt;% \n  filter(DAY_TYPE == day_type & TIME_PER_HOUR %in% time_interval) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS_GENERATED = sum(TOTAL_TRIPS)) %&gt;%\n  na.omit() %&gt;%\n  arrange(desc(TRIPS_GENERATED))\n  \n  t5 &lt;- df %&gt;%\n    head(5) %&gt;%\n    rename(top_5 = ORIGIN_PT_CODE, top_5_trip_count = TRIPS_GENERATED)\n  \n  b5 &lt;- df %&gt;%\n    tail(5) %&gt;%\n    rename(bot_5 = ORIGIN_PT_CODE, bot_5_trip_count = TRIPS_GENERATED)\n\n  return(cbind(t5, b5))\n}"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#november-2023-weekday-top-5-most-and-least-popular-stations-by-time-of-day",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#november-2023-weekday-top-5-most-and-least-popular-stations-by-time-of-day",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "November 2023 Weekday Top 5 Most and Least Popular Stations by Time of Day",
    "text": "November 2023 Weekday Top 5 Most and Least Popular Stations by Time of Day\n\nnov_day_trip &lt;- t5b5(\"data/merged_bus_nov.csv\", \"Top 5 stations for November 2023 Weekdays\", \"WEEKDAY\", c(6, 7, 17, 18))\nnov_day_morn &lt;- t5b5(\"data/merged_bus_nov.csv\", \"Top 5 stations for November 2023 Weekdays 6am - 8am\", \"WEEKDAY\", c(6, 7))\nnov_day_eve &lt;- t5b5(\"data/merged_bus_nov.csv\", \"Top 5 stations for November 2023 Weekdays 5pm - 7pm\", \"WEEKDAY\", c(17, 18))\n\nnov_day_trip"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#december-2023-weekday-top-5-most-and-least-popular-stations-by-time-of-day",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#december-2023-weekday-top-5-most-and-least-popular-stations-by-time-of-day",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "December 2023 Weekday Top 5 Most and Least Popular Stations by Time of Day",
    "text": "December 2023 Weekday Top 5 Most and Least Popular Stations by Time of Day\n\ndec_day_trip &lt;- t5b5(\"data/merged_bus_dec.csv\", \"Top 5 stations for December 2023 Weekdays\", \"WEEKDAY\", c(6, 7, 17, 18))\ndec_day_morn &lt;- t5b5(\"data/merged_bus_dec.csv\", \"Top 5 stations for December 2023 Weekdays 6am - 8am\", \"WEEKDAY\", c(6, 7))\ndec_day_eve &lt;- t5b5(\"data/merged_bus_dec.csv\", \"Top 5 stations for December 2023 Weekdays 5pm - 7pm\", \"WEEKDAY\", c(17, 18))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#january-2024-weekday-top-5-most-and-least-popular-stations-by-time-of-day",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#january-2024-weekday-top-5-most-and-least-popular-stations-by-time-of-day",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "January 2024 Weekday Top 5 Most and Least Popular Stations by Time of Day",
    "text": "January 2024 Weekday Top 5 Most and Least Popular Stations by Time of Day\n\njan_day_trip &lt;- t5b5(\"data/merged_bus_jan.csv\", \"Top 5 stations for January 2024 Weekdays\", \"WEEKDAY\", c(6, 7, 17, 18))\njan_day_morn &lt;- t5b5(\"data/merged_bus_jan.csv\", \"Top 5 stations for January 2024 Weekdays 6am - 8am\", \"WEEKDAY\", c(6, 7))\njan_day_eve &lt;- t5b5(\"data/merged_bus_jan.csv\", \"Top 5 stations for January 2024 Weekdays 5pm - t5b5\", \"WEEKDAY\", c(17, 18))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#november-2023-weekend-top-5-most-and-least-popular-stations-by-time-of-day",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#november-2023-weekend-top-5-most-and-least-popular-stations-by-time-of-day",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "November 2023 Weekend Top 5 Most and Least Popular Stations by Time of Day",
    "text": "November 2023 Weekend Top 5 Most and Least Popular Stations by Time of Day\n\nnov_end_trip &lt;- t5b5(\"data/merged_bus_nov.csv\", \"Top 5 stations for November 2023 Weekends\", \"WEEKENDS/HOLIDAY\", c(11, 12, 16, 17))\nnov_end_morn &lt;- t5b5(\"data/merged_bus_nov.csv\", \"Top 5 stations for November 2023 Weekends 11am - 1pm\", \"WEEKENDS/HOLIDAY\", c(11, 12))\nnov_end_eve &lt;- t5b5(\"data/merged_bus_nov.csv\", \"Top 5 stations for November 2023 Weekends 4pm - 6pm\", \"WEEKENDS/HOLIDAY\", c(16, 17))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#december-2023-weekend-top-5-most-and-least-popular-stations-by-time-of-day",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#december-2023-weekend-top-5-most-and-least-popular-stations-by-time-of-day",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "December 2023 Weekend Top 5 Most and Least Popular Stations by Time of Day",
    "text": "December 2023 Weekend Top 5 Most and Least Popular Stations by Time of Day\n\ndec_end_trip &lt;- t5b5(\"data/merged_bus_dec.csv\", \"Top 5 stations for December 2023 Weekends\", \"WEEKENDS/HOLIDAY\", c(11, 12, 16, 17))\ndec_end_morn &lt;- t5b5(\"data/merged_bus_dec.csv\", \"Top 5 stations for December 2023 Weekends 11am - 1pm\", \"WEEKENDS/HOLIDAY\", c(11, 12))\ndec_end_eve &lt;- t5b5(\"data/merged_bus_dec.csv\", \"Top 5 stations for December 2023 Weekends 4pm - 6pm\", \"WEEKENDS/HOLIDAY\", c(16, 17))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#january-2024-weekend-top-5-most-and-least-popular-stations-by-time-of-day",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#january-2024-weekend-top-5-most-and-least-popular-stations-by-time-of-day",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "January 2024 Weekend Top 5 Most and Least Popular Stations by Time of Day",
    "text": "January 2024 Weekend Top 5 Most and Least Popular Stations by Time of Day\n\njan_end_trip &lt;- t5b5(\"data/merged_bus_jan.csv\", \"Top 5 stations for January 2024 Weekends\", \"WEEKENDS/HOLIDAY\", c(11, 12, 16, 17))\njan_end_morn &lt;- t5b5(\"data/merged_bus_jan.csv\", \"Top 5 stations for January 2024 Weekends 11am - 1pm\", \"WEEKENDS/HOLIDAY\", c(11, 12))\njan_end_evep &lt;- t5b5(\"data/merged_bus_jan.csv\", \"Top 5 stations for January 2024 Weekends 4pm - 6pm\", \"WEEKENDS/HOLIDAY\", c(16, 17))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#heatmap",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#heatmap",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Heatmap",
    "text": "Heatmap\n\nNovember 2023 Weekday Origin\n\ntrips_by_origin &lt;- bus_nov %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\" & TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 23) %&gt;%\n  group_by(TIME_PER_HOUR, ORIGIN_PT_CODE) %&gt;%\n  summarise(TOTAL_TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  ungroup()\n\nkable(head(trips_by_origin), format = \"html\", digits = 2)\n\np &lt;- ggplot(data = trips_by_origin,\n            aes(x = TIME_PER_HOUR, y = ORIGIN_PT_CODE, fill = TOTAL_TRIPS)) +\n  geom_tile() +\n  scale_fill_distiller(palette = \"Spectral\", name = \"Passenger Volume\") +\n  labs(x = NULL, y = NULL,\n       title = \"November 2023 Weekday Passenger Volume by Time of Day and Origin Station\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5)) +\n  scale_x_continuous(breaks = seq(6, 23, by = 1))\n\nprint(p)\n\n\n\nNovember 2023 Weekday Destination\n\ntrips_by_dest &lt;- bus_nov %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\" & TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 23) %&gt;%\n  group_by(TIME_PER_HOUR, DESTINATION_PT_CODE) %&gt;%\n  summarise(TOTAL_TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  ungroup()\n\nkable(head(trips_by_dest), format = \"html\", digits = 2)\n\np &lt;- ggplot(data = trips_by_dest,\n            aes(x = TIME_PER_HOUR, y = DESTINATION_PT_CODE, fill = TOTAL_TRIPS)) +\n  geom_tile() +\n  scale_fill_distiller(palette = \"Spectral\", name = \"Passenger Volume\") +\n  labs(x = NULL, y = NULL,\n       title = \"November 2023 Weekday Passenger Volume by Time of Day and Destination Station\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5)) +\n  scale_x_continuous(breaks = seq(6, 23, by = 1))\n\nprint(p)\n\n\n\nNovember 2023 Weekend Origin\n\ntrips_by_origin &lt;- bus_nov %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\" & TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 23) %&gt;%\n  group_by(TIME_PER_HOUR, ORIGIN_PT_CODE) %&gt;%\n  summarise(TOTAL_TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  ungroup()\n\nkable(head(trips_by_origin), format = \"html\", digits = 2)\n\np &lt;- ggplot(data = trips_by_origin,\n            aes(x = TIME_PER_HOUR, y = ORIGIN_PT_CODE, fill = TOTAL_TRIPS)) +\n  geom_tile() +\n  scale_fill_distiller(palette = \"Spectral\", name = \"Passenger Volume\") +\n  labs(x = NULL, y = NULL,\n       title = \"November 2023 Weekend Passenger Volume by Time of Day and Origin Station\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5)) +\n  scale_x_continuous(breaks = seq(6, 23, by = 1))\n\nprint(p)\n\n\n\nNovember 2023 Weekend Destination\n\ntrips_by_dest &lt;- bus_nov %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\" & TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 23) %&gt;%\n  group_by(TIME_PER_HOUR, DESTINATION_PT_CODE) %&gt;%\n  summarise(TOTAL_TRIPS = sum(TOTAL_TRIPS)) %&gt;%\n  ungroup()\n\nkable(head(trips_by_dest), format = \"html\", digits = 2)\n\np &lt;- ggplot(data = trips_by_dest,\n            aes(x = TIME_PER_HOUR, y = DESTINATION_PT_CODE, fill = TOTAL_TRIPS)) +\n  geom_tile() +\n  scale_fill_distiller(palette = \"Spectral\", name = \"Passenger Volume\") +\n  labs(x = NULL, y = NULL,\n       title = \"November 2023 Weekend Passenger Volume by Time of Day and Destination Station\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5)) +\n  scale_x_continuous(breaks = seq(6, 23, by = 1))\n\nprint(p)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#set-nodes-for-network-graph",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#set-nodes-for-network-graph",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Set Nodes for Network Graph",
    "text": "Set Nodes for Network Graph\n\nnodes_xy &lt;- bus_coords_subzone %&gt;%\n  select(Longitude, Latitude) %&gt;%\n  rename(x = Longitude, y = Latitude)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#function-to-create-weighted-graph",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#function-to-create-weighted-graph",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Function to Create Weighted Graph",
    "text": "Function to Create Weighted Graph\n\ncreate_weighted_graph &lt;- function(fn, origin, day, time_period, title) {\n  \n  edges &lt;- read_csv(fn) %&gt;% \n    filter(ORIGIN_PT_CODE == origin & DAY_TYPE == day & TIME_PER_HOUR %in% time_period) %&gt;%\n    rename(weight = \"TOTAL_TRIPS\") %&gt;%\n    select(ORIGIN_PT_CODE, DESTINATION_PT_CODE, weight) %&gt;%\n    na.omit()\n  \n  if (nrow(edges) == 0) {\n    stop(\"No data found for the specified criteria.\")\n  }\n  \n  if (nrow(bus_coords_subzone) == 0) {\n    stop(\"No nodes data found.\")\n  }\n  \n  tr_graph &lt;- graph_from_data_frame(edges, directed = TRUE, vertices = bus_coords_subzone)\n  \nggraph(tr_graph, layout = \"kk\") +\n    geom_edge_arc(aes(edge_width = weight), curvature = 0.33, alpha = 0.1) +\n    scale_edge_width_continuous(range = c(0.5, 8), guide = \"none\") +  \n    geom_node_point(aes(x = x, y = y)) +\n    ggtitle(title)\n}\n\n\ncreate_weighted_graph(\"data/merged_bus_jan.csv\", \"46009\", \"WEEKDAY\", c(6, 7), \"January Weekday Woodlands Int Bus Stop 6am - 8am\")\n\ncreate_weighted_graph(\"data/merged_bus_jan.csv\", \"22009\", \"WEEKDAY\", c(17, 18), \"January Weekday Boon Lay Int Bus Stop 5pm - 7pm\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#centrality-index",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#centrality-index",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Centrality Index",
    "text": "Centrality Index\n\nedges1 &lt;- read_csv(\"data/merged_bus_jan.csv\") %&gt;%\n  rename(weight = \"TOTAL_TRIPS\") %&gt;%\n  select(ORIGIN_PT_CODE, DESTINATION_PT_CODE, weight) %&gt;%\n  na.omit()\n\ntr_graph1 &lt;- graph_from_data_frame(edges1, directed = TRUE, vertices = bus_coords_subzone)\n\ntr_graph1 &lt;- set_vertex_attr(tr_graph1, \"betweenness_centrality\", value = betweenness(tr_graph1))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#function-to-calculate-sum-of-trips",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#function-to-calculate-sum-of-trips",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Function to Calculate Sum of Trips",
    "text": "Function to Calculate Sum of Trips\n\ncalculate_sum_of_trips_202311_WD &lt;- function(merged_bus_nov) {\n  data_filtered &lt;- subset(merged_bus_nov, DAY_TYPE == \"WEEKDAY\" & TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 23)\n  sum_data &lt;- aggregate(TOTAL_TRIPS ~ TIME_PER_HOUR + ORIGIN_PT_CODE + DESTINATION_PT_CODE, data = data_filtered, sum)\n  return(sum_data)\n}\n\ncalculate_sum_of_trips_202311_WE &lt;- function(merged_bus_nov) {\n  data_filtered &lt;- subset(merged_bus_nov, DAY_TYPE == \"WEEKENDS/HOLIDAY\" & TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 23)\n  sum_data &lt;- aggregate(TOTAL_TRIPS ~ TIME_PER_HOUR + ORIGIN_PT_CODE + DESTINATION_PT_CODE\n, data = data_filtered, sum)\n  return(sum_data)\n}\n\n\nWD_202311 &lt;- calculate_sum_of_trips_202311_WD(merged_bus_nov)\n\nWE_202311 &lt;- calculate_sum_of_trips_202311_WE(merged_bus_nov)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-transformation-using-pivot-wider",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-transformation-using-pivot-wider",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Data Transformation using Pivot Wider",
    "text": "Data Transformation using Pivot Wider\n\npivot_wider(\n  WD_202311,\n  id_cols = NULL,\n  id_expand = FALSE,\n  names_from = \"DESTINATION_PT_CODE\",\n  names_prefix = \"\",\n  names_sep = \"_\",\n  names_glue = NULL,\n  names_sort = FALSE,\n  names_vary = \"fastest\",\n  names_expand = FALSE,\n  names_repair = \"check_unique\",\n  values_from = \"TOTAL_TRIPS\",\n  values_fill = NULL,\n  values_fn = NULL,\n  unused_fn = NULL\n)\n\npivot_wider(\n  WE_202311,\n  id_cols = NULL,\n  id_expand = FALSE,\n  names_from = \"DESTINATION_PT_CODE\",\n  names_prefix = \"\",\n  names_sep = \"_\",\n  names_glue = NULL,\n  names_sort = FALSE,\n  names_vary = \"fastest\",\n  names_expand = FALSE,\n  names_repair = \"check_unique\",\n  values_from = \"TOTAL_TRIPS\",\n  values_fill = NULL,\n  values_fn = NULL,\n  unused_fn = NULL\n)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#correlation-analysis",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#correlation-analysis",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Correlation Analysis",
    "text": "Correlation Analysis\n\ncor_data &lt;- dcast(WD_202311, ORIGIN_PT_CODE ~ DESTINATION_PT_CODE, value.var = \"TOTAL_TRIPS\",fun.aggregate = sum, fill = 0)\n\ncor_data &lt;- dcast(WD_202311, ORIGIN_PT_CODE ~ DESTINATION_PT_CODE, value.var = \"TOTAL_TRIPS\",fun.aggregate = sum, fill = 0)\n\ncorrelation_matrix_WD202311 &lt;- cor(cor_data[, -1])\n\nprint(correlation_matrix_WD202311)\n\ncorrplot(correlation_matrix_WD202311, method = \"color\")\n\n\ncor_data &lt;- dcast(WE_202311, ORIGIN_PT_CODE ~ DESTINATION_PT_CODE, value.var = \"TOTAL_TRIPS\",fun.aggregate = sum, fill = 0)\n\ncor_data &lt;- dcast(WE_202311, ORIGIN_PT_CODE ~ DESTINATION_PT_CODE, value.var = \"TOTAL_TRIPS\",fun.aggregate = sum, fill = 0)\n\ncorrelation_matrix_WE202311 &lt;- cor(cor_data[, -1])\n\nprint(correlation_matrix_WE202311)\n\ncorrplot(correlation_matrix_WE202311, method = \"color\")\n\n\noptions(repr.plot.width = 8, repr.plot.height = 6)\n\ncorrplot(correlation_matrix_WD202311, method = \"color\",\n         tl.cex = 0.2,       \n         cl.cex = 0.2,       \n         tl.col = \"black\",   \n         col = colorRampPalette(c(\"blue\", \"white\", \"red\"))(100),  \n         title = \"Correlation Matrix WD_202311\")\n\n\noptions(repr.plot.width = 8, repr.plot.height = 6)\n\ncorrplot(correlation_matrix_WE202311, method = \"color\",\n         tl.cex = 0.2,       \n         cl.cex = 0.2,       \n         tl.col = \"black\",   \n         col = colorRampPalette(c(\"blue\", \"white\", \"red\"))(100),  \n         title = \"Correlation Matrix WE_202311\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#plot-correlation-matrix",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#plot-correlation-matrix",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "Plot Correlation Matrix",
    "text": "Plot Correlation Matrix\n\nheatmaply(normalize(correlation_matrix_WD202311),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          dendrogram = c(\"none\"),\n          margins = c(NA,10,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 4,\n          main=\"OD matrix\",\n          xlab = \"Destination stations\",\n          ylab = \"Origin stations\"\n          )\n\n\nheatmaply(normalize(correlation_matrix_WE202311),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          dendrogram = c(\"none\"),\n          margins = c(NA,10,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 4,\n          main=\"OD matrix\",\n          xlab = \"Destination stations\",\n          ylab = \"Origin stations\"\n          )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#shiny-storyboard-ehsa",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#shiny-storyboard-ehsa",
    "title": "Take Home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "10.1 Shiny Storyboard (EHSA)",
    "text": "10.1 Shiny Storyboard (EHSA)\nThis tab presents an emerging hot spot analysis for selected bus stops during the designated month, time, and day type, revealing areas of increased significance or activity.\n\n\n\n\n\nCalibration Parameters\n\n\n\n\n\n\n\n\nParameter\nType\nFilter Options\n\n\n\n\nMonth of Interest\nSingle Select, dropdown\nNovember 2023, December 2023, January 2024\n\n\nDay type\nSingle Select, dropdown\nWeekday, Weekend\n\n\nTime of Day\nSingle Select, dropdown\nMorning, Evening\n\n\nBus Stop Code\nSingle select, dropdown\nspecific bus stop"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/data_prep.html",
    "href": "Take-home_Ex/Take-home_Ex03/data_prep.html",
    "title": "OD Bus Data Preparation",
    "section": "",
    "text": "pacman::p_load(sf, sfdep, tidyverse, tmap, spdep, knitr, leaflet)\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\nbus_nov &lt;- read_csv(\"data/origin_destination_bus_202311.csv\")\nbus_dec &lt;- read_csv(\"data/origin_destination_bus_202312.csv\")\nbus_jan &lt;- read_csv(\"data/origin_destination_bus_202401.csv\")\nbus_coords &lt;- read_csv(\"data/bus_stop.csv\")\nbus_coords_sf &lt;- st_as_sf(bus_coords, coords = c(\"Longitude\", \"Latitude\"), crs = 4326)\nbus_coords_sf &lt;- st_transform(bus_coords_sf, st_crs(mpsz_sf))\nsg_bus_stops &lt;- st_intersection(bus_coords_sf, mpsz_sf)\n\ntmap_mode(\"plot\")\n\ntmap_options(check.and.fix = TRUE, max.categories = 55)\n\nmpsz_plot &lt;- tm_shape(mpsz_sf) +\n  tm_borders(lwd = 2, group = \"mpsz_borders\") +  \n  tm_layout(legend.show = FALSE)  \n\ncombined_plot &lt;- mpsz_plot +\n  tm_shape(mpsz_sf) +\n  tm_polygons(col = \"PLN_AREA_N\", title = \"Plan Area\", group = \"mpsz_polygons\") +\n  tm_shape(sg_bus_stops) +\n  tm_dots(col = \"blue\", size = 0.1, group = \"bus_coords\") +\n  tm_layout(legend.show = FALSE)  \n\ncombined_plot\nbus_stop_subzone &lt;- st_intersection(sg_bus_stops, mpsz_sf)\nsg_bus_stops$Subzone &lt;- bus_stop_subzone$PLN_AREA_N\nmerged_data &lt;- merge(bus_coords, sg_bus_stops, by = \"BusStopCode\", all.x = TRUE)\nbus_coords$Subzone &lt;- merged_data$PLN_AREA_N\nbus_coords &lt;- bus_coords[, c(\"BusStopCode\", \"RoadName\", \"Description\", \"Subzone\", \"Latitude\", \"Longitude\")]\nbus_coords_subzone &lt;- bus_coords\n#write_rds(bus_coords_subzone, \"data/rds/bus_coords_subzone.rds\")\nmerged_bus_nov &lt;- left_join(bus_nov, bus_coords, by = c(\"ORIGIN_PT_CODE\" = \"BusStopCode\")) %&gt;%\n  rename(ORIGIN_SUBZONE = Subzone, ORIGIN_DESCRIPTION = Description, ORIGIN_LAT = Latitude, ORIGIN_LONG = Longitude) %&gt;%\n  left_join(bus_coords, by = c(\"DESTINATION_PT_CODE\" = \"BusStopCode\")) %&gt;%\n  rename(DESTINATION_SUBZONE = Subzone, DESTINATION_DESCRIPTION = Description, DESTINATION_LAT = Latitude, DESTINATION_LONG = Longitude) %&gt;%\n  select(YEAR_MONTH, DAY_TYPE, TIME_PER_HOUR, PT_TYPE, \n         ORIGIN_PT_CODE, ORIGIN_SUBZONE, ORIGIN_DESCRIPTION, ORIGIN_LAT, ORIGIN_LONG,\n         DESTINATION_PT_CODE, DESTINATION_SUBZONE, DESTINATION_DESCRIPTION, DESTINATION_LAT, DESTINATION_LONG,\n         TOTAL_TRIPS)\nmissing_stops &lt;- merged_bus_nov %&gt;%\n  summarise(ORIGIN_NA = any(is.na(ORIGIN_DESCRIPTION)),\n            DESTINATION_NA = any(is.na(DESTINATION_DESCRIPTION)),\n            ORIGIN_PT_WITH_NA = ifelse(any(is.na(ORIGIN_DESCRIPTION)), unique(ORIGIN_PT_CODE[is.na(ORIGIN_DESCRIPTION)]), NA),\n            DESTINATION_PT_WITH_NA = ifelse(any(is.na(DESTINATION_DESCRIPTION)), unique(DESTINATION_PT_CODE[is.na(DESTINATION_DESCRIPTION)]), NA))\n\nprint(missing_stops)\nNote: bus stop 65139 is no longer in operation\nmerged_bus_nov &lt;- merged_bus_nov %&gt;%\n  filter(!is.na(ORIGIN_DESCRIPTION) & !is.na(DESTINATION_DESCRIPTION))\n#write_rds(merged_bus_nov, \"data/rds/merged_bus_nov.rds\")\nmerged_bus_dec &lt;- left_join(bus_dec, bus_coords, by = c(\"ORIGIN_PT_CODE\" = \"BusStopCode\")) %&gt;%\n  rename(ORIGIN_SUBZONE = Subzone, ORIGIN_DESCRIPTION = Description, ORIGIN_LAT = Latitude, ORIGIN_LONG = Longitude) %&gt;%\n  left_join(bus_coords, by = c(\"DESTINATION_PT_CODE\" = \"BusStopCode\")) %&gt;%\n  rename(DESTINATION_SUBZONE = Subzone, DESTINATION_DESCRIPTION = Description, DESTINATION_LAT = Latitude, DESTINATION_LONG = Longitude) %&gt;%\n  select(YEAR_MONTH, DAY_TYPE, TIME_PER_HOUR, PT_TYPE, \n         ORIGIN_PT_CODE, ORIGIN_SUBZONE, ORIGIN_DESCRIPTION, ORIGIN_LAT, ORIGIN_LONG,\n         DESTINATION_PT_CODE, DESTINATION_SUBZONE, DESTINATION_DESCRIPTION, DESTINATION_LAT, DESTINATION_LONG,\n         TOTAL_TRIPS)\nmissing_stops_dec &lt;- merged_bus_dec %&gt;%\n  summarise(ORIGIN_NA = any(is.na(ORIGIN_DESCRIPTION)),\n            DESTINATION_NA = any(is.na(DESTINATION_DESCRIPTION)),\n            ORIGIN_PT_WITH_NA = ifelse(any(is.na(ORIGIN_DESCRIPTION)), unique(ORIGIN_PT_CODE[is.na(ORIGIN_DESCRIPTION)]), NA),\n            DESTINATION_PT_WITH_NA = ifelse(any(is.na(DESTINATION_DESCRIPTION)), unique(DESTINATION_PT_CODE[is.na(DESTINATION_DESCRIPTION)]), NA))\n\nprint(missing_stops_dec)\nNote: bus stop 65139 is no longer in operation\nmerged_bus_dec &lt;- merged_bus_dec %&gt;%\n  filter(!is.na(ORIGIN_DESCRIPTION) & !is.na(DESTINATION_DESCRIPTION))\n#write_rds(merged_bus_dec, \"data/rds/merged_bus_dec.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/data_prep.html#january",
    "href": "Take-home_Ex/Take-home_Ex03/data_prep.html#january",
    "title": "OD Bus Data Preparation",
    "section": "January",
    "text": "January\n\nhead(bus_jan)\nhead(bus_dec)\n\n\nbus_jan$ORIGIN_PT_CODE &lt;- as.character(bus_jan$ORIGIN_PT_CODE)\nbus_jan$DESTINATION_PT_CODE &lt;- as.character(bus_jan$DESTINATION_PT_CODE)\n\nmerged_bus_jan &lt;- left_join(bus_jan, bus_coords, by = c(\"ORIGIN_PT_CODE\" = \"BusStopCode\")) %&gt;%\n  rename(ORIGIN_SUBZONE = Subzone, ORIGIN_DESCRIPTION = Description, ORIGIN_LAT = Latitude, ORIGIN_LONG = Longitude) %&gt;%\n  left_join(bus_coords, by = c(\"DESTINATION_PT_CODE\" = \"BusStopCode\")) %&gt;%\n  rename(DESTINATION_SUBZONE = Subzone, DESTINATION_DESCRIPTION = Description, DESTINATION_LAT = Latitude, DESTINATION_LONG = Longitude) %&gt;%\n  select(YEAR_MONTH, DAY_TYPE, TIME_PER_HOUR, PT_TYPE, \n         ORIGIN_PT_CODE, ORIGIN_SUBZONE, ORIGIN_DESCRIPTION, ORIGIN_LAT, ORIGIN_LONG,\n         DESTINATION_PT_CODE, DESTINATION_SUBZONE, DESTINATION_DESCRIPTION, DESTINATION_LAT, DESTINATION_LONG,\n         TOTAL_TRIPS)\n\n\nmissing_stops_jan &lt;- merged_bus_jan %&gt;%\n  summarise(ORIGIN_NA = any(is.na(ORIGIN_DESCRIPTION)),\n            DESTINATION_NA = any(is.na(DESTINATION_DESCRIPTION)),\n            ORIGIN_PT_WITH_NA = ifelse(any(is.na(ORIGIN_DESCRIPTION)), unique(ORIGIN_PT_CODE[is.na(ORIGIN_DESCRIPTION)]), NA),\n            DESTINATION_PT_WITH_NA = ifelse(any(is.na(DESTINATION_DESCRIPTION)), unique(DESTINATION_PT_CODE[is.na(DESTINATION_DESCRIPTION)]), NA))\n\nprint(missing_stops_jan)\n\nNote: dropping bus stop 4168 and 9022. Bus stop should be 5 digits.\n\nmerged_bus_jan &lt;- merged_bus_jan %&gt;%\n  filter(!is.na(ORIGIN_DESCRIPTION) & !is.na(DESTINATION_DESCRIPTION))\n\n\n#write_rds(merged_bus_jan, \"data/rds/merged_bus_jan.rds\")\n\n\n# for spacetime \nnov_trip_generation_origin &lt;- merged_bus_nov %&gt;%\n   select(ORIGIN_PT_CODE, ORIGIN_DESCRIPTION, ORIGIN_SUBZONE, TIME_PER_HOUR, TOTAL_TRIPS, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n  group_by(ORIGIN_PT_CODE, ORIGIN_DESCRIPTION,ORIGIN_SUBZONE, TIME_PER_HOUR, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n  summarise(`TRIPS GENERATED` = sum(`TOTAL_TRIPS`)) %&gt;%\n  ungroup() %&gt;%\n  st_as_sf(coords = c(\"ORIGIN_LAT\", \"ORIGIN_LONG\"),\n           crs=4326)\n\n\n#write_rds(nov_trip_generation_origin, \"data/rds/nov_trip_generation_origin.rds\")\n\n\n# for spacetime \nnov_trip_generation_dest &lt;- merged_bus_nov %&gt;%\n   select(DESTINATION_PT_CODE, DESTINATION_DESCRIPTION, DESTINATION_SUBZONE, TIME_PER_HOUR, TOTAL_TRIPS, DESTINATION_LAT, DESTINATION_LONG) %&gt;%\n  group_by(DESTINATION_PT_CODE, DESTINATION_DESCRIPTION,DESTINATION_SUBZONE, TIME_PER_HOUR, DESTINATION_LAT, DESTINATION_LONG) %&gt;%\n  summarise(`TRIPS GENERATED` = sum(`TOTAL_TRIPS`)) %&gt;%\n  ungroup() %&gt;%\n  st_as_sf(coords = c(\"DESTINATION_LAT\", \"DESTINATION_LONG\"),\n           crs=4326)\n\n\n#write_rds(nov_trip_generation_dest, \"data/rds/nov_trip_generation_dest.rds\")\n\n\n# for spacetime \ndec_trip_generation_origin &lt;- merged_bus_dec %&gt;%\n   select(ORIGIN_PT_CODE, ORIGIN_DESCRIPTION, ORIGIN_SUBZONE, TIME_PER_HOUR, TOTAL_TRIPS, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n  group_by(ORIGIN_PT_CODE, ORIGIN_DESCRIPTION,ORIGIN_SUBZONE, TIME_PER_HOUR, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n  summarise(`TRIPS GENERATED` = sum(`TOTAL_TRIPS`)) %&gt;%\n  ungroup() %&gt;%\n  st_as_sf(coords = c(\"ORIGIN_LAT\", \"ORIGIN_LONG\"),\n           crs=4326)\n\n\n#write_rds(dec_trip_generation_origin, \"data/rds/dec_trip_generation_origin.rds\")\n\n\n# for spacetime \ndec_trip_generation_dest &lt;- merged_bus_dec %&gt;%\n   select(DESTINATION_PT_CODE, DESTINATION_DESCRIPTION, DESTINATION_SUBZONE, TIME_PER_HOUR, TOTAL_TRIPS, DESTINATION_LAT, DESTINATION_LONG) %&gt;%\n  group_by(DESTINATION_PT_CODE, DESTINATION_DESCRIPTION,DESTINATION_SUBZONE, TIME_PER_HOUR, DESTINATION_LAT, DESTINATION_LONG) %&gt;%\n  summarise(`TRIPS GENERATED` = sum(`TOTAL_TRIPS`)) %&gt;%\n  ungroup() %&gt;%\n  st_as_sf(coords = c(\"DESTINATION_LAT\", \"DESTINATION_LONG\"),\n           crs=4326)\n\n\n#write_rds(dec_trip_generation_dest, \"data/rds/dec_trip_generation_dest.rds\")\n\n\n# for spacetime \njan_trip_generation_origin &lt;- merged_bus_jan %&gt;%\n   select(ORIGIN_PT_CODE, ORIGIN_DESCRIPTION, ORIGIN_SUBZONE, TIME_PER_HOUR, TOTAL_TRIPS, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n  group_by(ORIGIN_PT_CODE, ORIGIN_DESCRIPTION,ORIGIN_SUBZONE, TIME_PER_HOUR, ORIGIN_LAT, ORIGIN_LONG) %&gt;%\n  summarise(`TRIPS GENERATED` = sum(`TOTAL_TRIPS`)) %&gt;%\n  ungroup() %&gt;%\n  st_as_sf(coords = c(\"ORIGIN_LAT\", \"ORIGIN_LONG\"),\n           crs=4326)\n\n\n#write_rds(jan_trip_generation_origin, \"data/rds/jan_trip_generation_origin.rds\")\n\n\n# for spacetime \njan_trip_generation_dest &lt;- merged_bus_jan %&gt;%\n   select(DESTINATION_PT_CODE, DESTINATION_DESCRIPTION, DESTINATION_SUBZONE, TIME_PER_HOUR, TOTAL_TRIPS, DESTINATION_LAT, DESTINATION_LONG) %&gt;%\n  group_by(DESTINATION_PT_CODE, DESTINATION_DESCRIPTION,DESTINATION_SUBZONE, TIME_PER_HOUR, DESTINATION_LAT, DESTINATION_LONG) %&gt;%\n  summarise(`TRIPS GENERATED` = sum(`TOTAL_TRIPS`)) %&gt;%\n  ungroup() %&gt;%\n  st_as_sf(coords = c(\"DESTINATION_LAT\", \"DESTINATION_LONG\"),\n           crs=4326)\n\n\n#write_rds(jan_trip_generation_dest, \"data/rds/jan_trip_generation_dest.rds\")\n\n\nmerged_bus_nov &lt;- read_rds(\"data/rds/merged_bus_nov.rds\")\nwrite.csv(merged_bus_nov, file = \"data/merged_bus_nov.csv\", row.names = FALSE)\n\n\nmerged_bus_dec &lt;- read_rds(\"data/rds/merged_bus_dec.rds\")\nwrite.csv(merged_bus_dec, file = \"data/merged_bus_dec.csv\", row.names = FALSE)\n\n\nmerged_bus_jan &lt;- read_rds(\"data/rds/merged_bus_jan.rds\")\nwrite.csv(merged_bus_jan, file = \"data/merged_bus_jan.csv\", row.names = FALSE)\n\n\nbus_coords_subzone &lt;- read_rds(\"data/rds/bus_coords_subzone.rds\")\nwrite.csv(bus_coords_subzone, file = \"data/bus_coords_subzone.csv\", row.names = FALSE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/data/geospatial/Liesure&Recreation.html",
    "href": "Take-home_Ex/Take-home_Ex03/data/geospatial/Liesure&Recreation.html",
    "title": "IS415 - GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC â€˜http://mrcc.com/qgis.dtdâ€™ â€˜SYSTEMâ€™&gt;     dataset\n\n\n       GEOGCRS[â€œWGS 84â€,ENSEMBLE[â€œWorld Geodetic System 1984 ensembleâ€,MEMBER[â€œWorld Geodetic System 1984 (Transit)â€],MEMBER[â€œWorld Geodetic System 1984 (G730)â€],MEMBER[â€œWorld Geodetic System 1984 (G873)â€],MEMBER[â€œWorld Geodetic System 1984 (G1150)â€],MEMBER[â€œWorld Geodetic System 1984 (G1674)â€],MEMBER[â€œWorld Geodetic System 1984 (G1762)â€],MEMBER[â€œWorld Geodetic System 1984 (G2139)â€],ELLIPSOID[â€œWGS 84â€,6378137,298.257223563,LENGTHUNIT[â€œmetreâ€,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[â€œGreenwichâ€,0,ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],CS[ellipsoidal,2],AXIS[â€œgeodetic latitude (Lat)â€,north,ORDER[1],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],AXIS[â€œgeodetic longitude (Lon)â€,east,ORDER[2],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],USAGE[SCOPE[â€œHorizontal component of 3D system.â€],AREA[â€œWorld.â€],BBOX[-90,-180,90,180]],ID[â€œEPSGâ€,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/data/geospatial/F&B.html",
    "href": "Take-home_Ex/Take-home_Ex03/data/geospatial/F&B.html",
    "title": "IS415 - GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC â€˜http://mrcc.com/qgis.dtdâ€™ â€˜SYSTEMâ€™&gt;     dataset\n\n\n       GEOGCRS[â€œWGS 84â€,ENSEMBLE[â€œWorld Geodetic System 1984 ensembleâ€,MEMBER[â€œWorld Geodetic System 1984 (Transit)â€],MEMBER[â€œWorld Geodetic System 1984 (G730)â€],MEMBER[â€œWorld Geodetic System 1984 (G873)â€],MEMBER[â€œWorld Geodetic System 1984 (G1150)â€],MEMBER[â€œWorld Geodetic System 1984 (G1674)â€],MEMBER[â€œWorld Geodetic System 1984 (G1762)â€],MEMBER[â€œWorld Geodetic System 1984 (G2139)â€],ELLIPSOID[â€œWGS 84â€,6378137,298.257223563,LENGTHUNIT[â€œmetreâ€,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[â€œGreenwichâ€,0,ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],CS[ellipsoidal,2],AXIS[â€œgeodetic latitude (Lat)â€,north,ORDER[1],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],AXIS[â€œgeodetic longitude (Lon)â€,east,ORDER[2],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],USAGE[SCOPE[â€œHorizontal component of 3D system.â€],AREA[â€œWorld.â€],BBOX[-90,-180,90,180]],ID[â€œEPSGâ€,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/data/geospatial/Business.html",
    "href": "Take-home_Ex/Take-home_Ex03/data/geospatial/Business.html",
    "title": "IS415 - GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC â€˜http://mrcc.com/qgis.dtdâ€™ â€˜SYSTEMâ€™&gt;     dataset\n\n\n       GEOGCRS[â€œWGS 84â€,ENSEMBLE[â€œWorld Geodetic System 1984 ensembleâ€,MEMBER[â€œWorld Geodetic System 1984 (Transit)â€],MEMBER[â€œWorld Geodetic System 1984 (G730)â€],MEMBER[â€œWorld Geodetic System 1984 (G873)â€],MEMBER[â€œWorld Geodetic System 1984 (G1150)â€],MEMBER[â€œWorld Geodetic System 1984 (G1674)â€],MEMBER[â€œWorld Geodetic System 1984 (G1762)â€],MEMBER[â€œWorld Geodetic System 1984 (G2139)â€],ELLIPSOID[â€œWGS 84â€,6378137,298.257223563,LENGTHUNIT[â€œmetreâ€,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[â€œGreenwichâ€,0,ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],CS[ellipsoidal,2],AXIS[â€œgeodetic latitude (Lat)â€,north,ORDER[1],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],AXIS[â€œgeodetic longitude (Lon)â€,east,ORDER[2],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],USAGE[SCOPE[â€œHorizontal component of 3D system.â€],AREA[â€œWorld.â€],BBOX[-90,-180,90,180]],ID[â€œEPSGâ€,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "1.1 Setting the scene",
    "text": "1.1 Setting the scene\nUnderstanding how people move around in a city is like figuring out its heartbeatâ€”it shows us the rhythms that shape our urban lives. Thanks to smartphones and technology, we now have a bunch of data about how people move. When we use smart analysis tools like GIS, we can unlock valuable insights that help us plan cities better.\nIn 2020, GRAB shared a set of data called Grab Posisi, all about how people move around in Singapore. This kind of information isnâ€™t just interesting; itâ€™s super helpful for businesses, people who make decisions about the city, and those who plan how cities work. Itâ€™s like having a dynamic picture of how people move, helping us create cities that work well for everyone."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "1.2 Objectives",
    "text": "1.2 Objectives\nThe objectives of this take-home exercise are to:\n\nApply geospatial analytics to address societal challenges\nUse spatial point patterns analysis methods to explore Grab hailing services distribution in Singapore\nOrganise geospatial data into sf tibble data.frames using sf and tidyverse functions\nFocus on Grab taxi location points, road layer within Singapore, and Singapore coastal boundary layer\nGenerate traditional Kernel Density Estimation layers\nCreate Network Kernel Density Estimation (NKDE)\nUtilise tmap functions to display kernel density layers on OSM\nDescribe spatial patterns revealed by the kernel density maps\n\nBy this exercise, I will:\n\nEnhance my understanding of geospatial analytics applications\nDevelop proficiency in spatial point patterns analysis\nGain hands-on experience in dealing with geospatial data\nExplore Grab hailing services distribution patterns in Singapore\nGenerate and interpret Kernel Density Estimation layers\nUnderstand the nuances of Network Kernel Density Estimation (NKDE)\nLearn about the visualisation of spatial patterns using tmap functions on OSM"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#getting-started",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "2 Getting Started",
    "text": "2 Getting Started"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-acquisition",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-acquisition",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "2.1 Data Acquisition",
    "text": "2.1 Data Acquisition\nThe study will utilise the following datasets to explore spatial point patterns analysis methods and reveal the geographical and spatio-temporal distribution of Grab hailing services locations in Singapore.\n\n\n\nDataset Name\nType\nSource\nPath\n\n\n\n\nGrab-Posisi\nAspatial (.parquet)\nhttps://engineering.grab.com/grab-posisi\ndata/aspatial/grabPosisi\n\n\nMaster Plan 2019 Subzone Boundary (No Sea)\nGeospatial (.shp)\nhttps://beta.data.gov.sg/collections/2104/view\ndata/geospatial/MPSZ-2019\n\n\nOpen Street Map Road Data\nGeospatial (.shp)\nhttps://download.geofabrik.de/asia/malaysia-singapore-brunei.html\ndata/geospatial/OSM/gis_osm_roads_free_1"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-relevant-r-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-relevant-r-packages",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "2.2 Importing Relevant R Packages",
    "text": "2.2 Importing Relevant R Packages\nThe R packages used in this project are:\n\narrow: for reading and writing Parquet files\ndplyr: for data manipulation\nlubridate: for working with date-time data\nmaptools: set of tools for reading and manipulating spatial data formats, such as shapefiles\nraster: reads, writes, manipulates, analyses, and models gridded spatial data\nrgdal: from CRAN, enables users to import, export, and manipulate spatial data within the R environment\nRcolorBrewer: package providing color schemes for maps and other visualizations\nrmapshaper: a package for simplifying and modifying geographic shapes in R\nsf: for importing, managing, and processing geospatial data\nspNetwork: to perform spatial analysis for NKDE\nspatstat: for performing spatial point patterns analysis\ntidyverse: a family of other R packages for performing data science tasks such as importing, wrangling, and visualizing data\ntmap: creating static and interactive maps\nggplot2: used for data visualization\nplotly: interactive graphing library for R\n\nPacman assists us by helping us load R packages that we require.\n\n pacman::p_load(arrow, dplyr, lubridate, maptools, raster, rgdal, RColorBrewer, rmapshaper, sf, sp, spNetwork, spatstat, tidyverse, tmap, ggplot2, plotly)\n\n#update.packages(ask = FALSE, dependencies = TRUE)\n## install.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-geospatial-datasets",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-geospatial-datasets",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "2.3 Importing Geospatial Datasets",
    "text": "2.3 Importing Geospatial Datasets\n\n2.3.1 Master Plan 2019 Subzone Boundary (No Sea)\nFor shapefile format, two arguments are required:Â dsnÂ to define the data path, andÂ layerÂ to provide the shapefile name.Â \n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MPSZ-2019\") %&gt;%\n    st_transform(crs = 3414)\n\n\n\n\n\n\n\nImportant\n\n\n\nProject Transformation\nGiven that our dataset corresponds to the geographical boundaries of Singapore, it is necessary to specify the appropriate CRS for accurate spatial analysis. To achieve this, the st_transform() function is used to convert the CRS of mpsz_sf to SVY21 (EPSG: 3414)\n\n\n\n\n2.3.2 Coastal Outline\nIn order to create a costal outline of singapore, we will use the st_union function to consolidate all subzone boundaries from mpsz_sf into a single polygon.\n\noutline = mpsz_sf %&gt;% st_union()\nplot(outline)\n\n\n\n2.3.2.1 Extracting Outer Islands\nAs seen in the figure above, the coastal outline includes outer islands where Grab service is unavailable. Through the code chunk below, we use the subset function to select subzones from the mpsz_sf dataset to exclude. These excluded rows of data are stored in new dataframes.\n\nsemakau &lt;- subset(mpsz_sf,mpsz_sf$SUBZONE_N == \"SEMAKAU\") #western island\nsudong &lt;- subset(mpsz_sf, mpsz_sf$SUBZONE_N == \"SUDONG\") #western island\nbukom &lt;- subset(mpsz_sf, mpsz_sf$SUBZONE_N ==  \"JURONG ISLAND AND BUKOM\")\nnorth &lt;- subset(mpsz_sf, mpsz_sf$SUBZONE_N == \"NORTH-EASTERN ISLANDS\")\nsouth &lt;- subset(mpsz_sf, mpsz_sf$SUBZONE_N == \"SOUTHERN GROUP\")\n\nWe combine the newly created dataframes using the bind_rows function and store the data in another dataframe called outer.\n\nouter &lt;- dplyr::bind_rows(list(semakau,sudong,bukom,north,south))\n\n\n\n2.3.2.2 Rendering a Coastal Boundary Excluding Outer Islands\nWe use the st_union function again to merge the geometries of mpsz_sf and outer, and the st_difference function to eliminate the overlap between the two layers. This results in a coastal boundary, sg_sf, which excludes the outer islands.\n\nsg_sf &lt;- st_difference(st_union(mpsz_sf), st_union(outer))\nplot(sg_sf)\n\n\n\n\n\n\n\nTip\n\n\n\nâœ… Task Complete! We have obtained the coastal boundary layer of Singapore, excluding the outer islands.\n\n\n\n#write_rds(sg_sf, \"data/rds/sg_sf.rds\")\nsg_sf &lt;- read_rds(\"data/rds/sg_sf.rds\")\n\n\n\n2.3.3 Open Street Map Road Data\nLetâ€™s import the road data obtained from OSM.\n\nallroads = st_read(dsn = \"data/geospatial/OSM\", \n                         layer = \"gis_osm_roads_free_1\")  %&gt;% st_transform(crs = 3414)\n\n\n\n\n\n\n\nImportant\n\n\n\nProject Transformation\nGiven that our dataset corresponds to the geographical boundaries of Singapore, itâ€™s necessary to specify the appropriate CRS for accurate spatial analysis. To achieve this, the st_transform() function is used to convert the CRS of allroads to SVY21 (EPSG: 3414)\n\n\nThis dataset encompasses road networks spanning Singapore, Malaysia, and Brunei. To narrow our focus, we will extract roads exclusively within the Singapore boundary using the st_intersection function to check the intersection between sg_sf and allroads.\n\nsg_roads_all &lt;- st_intersection(allroads,sg_sf)\n\n\n#write_rds(sg_roads_all, \"data/rds/sg_roads_all.rds\")\nsg_roads_all &lt;- read_rds(\"data/rds/sg_roads_all.rds\")\n\nThe next step involves examining the various road types within the road network.\n\nunique(sg_roads_all$fclass)\n\nGiven our focus on Grab services, which primarily operate on roads excluding expressways (it is not possible for Grab to pick-up or drop off passengers along expressways), we will extract the relevant road types from the road network. To determine which roads are applicable, we can look at the OSM fclass. The image below provides descriptions for each road type, and for our analysis, we will focus on the most relevant types: primary, residential, tertiary, service, secondary, primary_link, secondary_link, and tertiary_link\n\nWe store the selected road types in a dataframe called sg_roads_filtered.\n\nsg_roads_filtered &lt;- c(\"primary\", \"residential\", \"tertiary\", \"service\", \"secondary\", \"primary_link\", \"secondary_link\", \"tertiary_link\")\n\n\nsg_roads &lt;- sg_roads_all[sg_roads_all$fclass %in% sg_roads_filtered, ]\n\nunique(sg_roads$fclass)\n\nWe will now visualise the selected road types within the boundaries of Singapore using tmap.\n\nroad_type_palette &lt;- brewer.pal(12, \"Set3\")\ntmap_mode('view')\ntm_shape(sg_sf) + \n  tm_borders(lwd = 2, col = 'grey') +\n  tm_shape(sg_roads) + \n  tm_lines(col = \"fclass\", palette = road_type_palette)\n  tm_layout(frame = FALSE, main.title = \"Types of Road Networks in Singapore\")\n\n\n\n\n\n\n\nTip\n\n\n\nâœ… Task Complete! We have extracted the road layer within Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-aspatial-datasets",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-aspatial-datasets",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "2.4 Importing Aspatial Datasets",
    "text": "2.4 Importing Aspatial Datasets\n\n2.4.1 Grab-Posisi\nGrab-Posisi, is a GPS trajectory dataset. Each trajectory is serialised in a file in Apache Parquet format.\nWe will use the read_parquet function from the arrow package, to read Parquet files.\n\ngrab0 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00000.parquet\", as_data_frame = TRUE)\ngrab1 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00001.parquet\", as_data_frame = TRUE)\ngrab2 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00002.parquet\", as_data_frame = TRUE)\ngrab3 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00003.parquet\", as_data_frame = TRUE)\ngrab4 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00004.parquet\", as_data_frame = TRUE)\ngrab5 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00005.parquet\", as_data_frame = TRUE)\ngrab6 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00006.parquet\", as_data_frame = TRUE)\ngrab7 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00007.parquet\", as_data_frame = TRUE)\ngrab8 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00008.parquet\", as_data_frame = TRUE)\ngrab9 &lt;- read_parquet(\"data/aspatial/GrabPosisi/part-00009.parquet\", as_data_frame = TRUE)\n\nThen we join all the read files into one dataframe.\n\ngrab &lt;- bind_rows(grab0,grab1, grab2,grab3,grab4,grab5,grab6,grab7,grab8,grab9) \n\n\nhead(grab)\n\nThe head function reveals that there are 9 columns in the dataframe.\nThe field pingtimestamp is not in proper date-time format. It is stored as an int value. The following code chunk converts the data type of pingtimestamp from int to date-time format.\n\ngrab$pingtimestamp &lt;- as_datetime(grab$pingtimestamp)\n\n\n\n2.4.1.2 Converting Aspatial Data Frame into a Simple Feature Data Frame\nWe will proceed to convert the grab dataset, currently in an aspatial data frame, into an sf tibble dataframe.\n\ngrab_sf &lt;- st_as_sf(grab, \n                       coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\n\n# write_rds(grab_sf, \"data/rds/grab_sf.rds\")\ngrab_sf &lt;- read_rds(\"data/rds/grab_sf.rds\")\n\n\n\n\n\n\n\nImportant\n\n\n\nProject Transformation\nAssuming the dataset is initially in the WGS84 Geographic Coordinate System, as indicated by the latitude/longitude fields, we need to define the suitable CRS for spatial analysis within Singapore. The st_transform() function is utilised to convert the CRS of the grab dataset to SVY21 (EPSG: 3414).\n\n\nThis gives us the new simple feature data frame, grab_sf"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "2.5 Data Wrangling",
    "text": "2.5 Data Wrangling\n\n2.5.1 Extracting Grab Trips Starting Locations\nWe will extract trip starting point for all unqiue trajectories and store them to a new df named grab_origin. To isolate the origin locations, we use the following methodology:\n\nGrouping by Trajectory ID:\n\nThe dataset is grouped by the unique trajectory identifier (trj_id).\n\nArranging by Timestamp:\n\nWithin each trajectory group, records are arranged in ascending order based on the timestamp (pingtimestamp).\n\nFiltering for the First Row:\n\nBy selecting the first row within each grouped trajectory (row_number() == 1), we identify the earliest recorded location for each trip. This is indicative of the tripâ€™s starting point.\n\nAdding Temporal Information:\n\nAdditional temporal context is provided by introducing new columns:\n\nweekday: Day of the week based on the timestamp\nstart_hr: Starting hour of the trip\nday: Day of the month when the trip started\n\n\n\n\ngrab_origin &lt;- grab_sf %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(pingtimestamp) %&gt;%\n  filter(row_number()==1) %&gt;% #after sorting by timestamp, first row gives origin location \n  mutate(weekday = wday(pingtimestamp, #define workday\n                        label = TRUE,\n                        abbr = TRUE), #Monday = MON \n        start_hr = factor(hour(pingtimestamp)),\n        day = factor(mday(pingtimestamp))) #to change to ordinal scale\n\n\n#write_rds(grab_origin, \"data/rds/grab_origin.rds\")\ngrab_origin &lt;- read_rds(\"data/rds/grab_origin.rds\")\n\n\n\n\n\n\n\nTip\n\n\n\nâœ… Task Complete! We have retrieved the origin location coordinates for Grab services.\n\n\n\n\n2.5.2 Extracting Grab Trips Ending Locations\nWe will extract trip ending point for all unique trajectories and store them to a new df named grab_dest. We employ a similar methodology to extracting a trips origin location. Except here, within each trajectory group, records are arranged in descending order based on the timestamp (pingtimestamp). By selecting the first row within each grouped trajectory (row_number() == 1), we identify the latest recorded location for each trip. This corresponds to the tripâ€™s ending point.\n\ngrab_dest &lt;- grab_sf %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(desc(pingtimestamp)) %&gt;% #function from dplyr\n  filter(row_number()==1) %&gt;% #first row after arranging in desc order gives dest  \n  mutate(weekday = wday(pingtimestamp, #define workday\n                        label = TRUE,\n                        abbr = TRUE), #Monday = MON \n        end_hr = factor(hour(pingtimestamp)),\n        day = factor(mday(pingtimestamp))) #to change to ordinal scale\n\n\n#write_rds(grab_dest, \"data/rds/grab_dest.rds\")\ngrab_dest &lt;- read_rds(\"data/rds/grab_dest.rds\")\n\n\n\n\n\n\n\nTip\n\n\n\nâœ… Task Complete! We have retrieved the destination location coordinates for Grab services.\n\n\n\n\n2.5.3 Converting Simple Features to Planar Point Pattern Objects\nTo perform spatial point pattern analysis, firstly, weâ€™ll need to convert the simple features objects (grab_orign and grab_dest) into Spatial* classes. For this we use as.ppp from spatstat package. The st_coordinates function extracts the coordiates from our sf objects and st_bbox will extract the minimum and maximum coordinates of the object along each axis.\n\ngrab_origin_ppp &lt;- as.ppp(st_coordinates(grab_origin), st_bbox(grab_origin))\n\npar(mar = c(1,1,1,1))\nplot(grab_origin_ppp, main = \"Grab Origin Points as PPP Objects\")\n\n\ngrab_dest_ppp &lt;- as.ppp(st_coordinates(grab_dest), st_bbox(grab_dest))\n\npar(mar = c(1,1,1,1))\nplot(grab_dest_ppp, main = \"Grab Destination Points as PPP Objects\")\n\n\n\n\n\n\n\nTip\n\n\n\nIt is not neccessary to change sg_sf into a ppp object as it will be converted to owin instead.\n\n\n\n\n2.5.4 Check for Duplicates and Handle Data Errors\nLetâ€™s have a look at the ppp objects we have created to make sure that there is no duplicates or errors in our data.\n\nsummary(grab_origin_ppp)\nsummary(grab_dest_ppp)\n\n\n\n\n\n\n\nNote\n\n\n\ngrab_origin_ppp and grab_dest_ppp objects have no duplicated points, but just to be sure, we check again using the any(duplicated() function.\n\n\n\nany(duplicated(grab_origin_ppp)) \nany(duplicated(grab_dest_ppp)) \n\nThe output is false for both objects so we move on to the next step.\n\n\n2.5.5 Introducing OWIN\nWhen analysing spatial point patterns, weâ€™ll confine our analysis within a certain geographical area - such as the Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\n\n\n2.5.5.1 Creating OWIN Object\nTo create a two dimensional observation window using sg_sf coastal boundary we created earlier, we use the as.owin function.\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n2.5.5.2 Combining Point Events and OWIN Object\nNow, weâ€™ll extract the relevant point events that are located within Singapore.\n\n\n2.5.5.2.1 Origin Points in OWIN Object\n\ngrab_origin_ppp_sg &lt;- grab_origin_ppp[sg_owin]\npar(mar = c(1,1,1,1))\nplot(grab_origin_ppp_sg, main = '[OWIN] Grab Origin Points' )\n\n\n\n2.5.5.2.1 Destination Points in OWIN Object\n\ngrab_dest_ppp_sg &lt;- grab_dest_ppp[sg_owin]\npar(mar = c(1,1,1,1))\nplot(grab_dest_ppp_sg, main = '[OWIN] Grab Destination Points' )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "3.0 Exploratory Data Analysis",
    "text": "3.0 Exploratory Data Analysis\nTo better understand the spatial data, we employ a series of exploratory techniques.\n\n3.1 Spatial Relationship between Origin and Destination Points\nThe map below shows the geographical distribution of origin and destination points. By overlaying both sets of points, we can observe areas where origin and destination locations overlap. These overlapping areas indicate regions with bidirectional travel.\n\ncombined_map &lt;- ggplot() +\n  geom_sf(data = grab_origin, aes(color = \"Origin\"), alpha = 0.7) +\n  geom_sf(data = grab_dest, aes(color = \"Destination\"), alpha = 0.7) +\n  ggtitle(\"Spatial Relationship Between Origin and Destination Locations\") +\n  labs(color = \"Location Type\") +\n  scale_color_manual(values = c(\"Origin\" = \"blue\", \"Destination\" = \"red\"), \n                     name = \"Location Type\", \n                     labels = c(\"Origin\", \"Destination\")) +\n  theme_minimal()\n\nprint(combined_map)\n\n\n\n3.2 Spatio-Temporal Visualisations\nSpatio-temporal visualisations show us a view of how data evolves over both space and time. These visualisations are particularly useful for analysing patterns, trends, and relationships within datasets.\n\n\n3.2.1 Frequency of Trip by Hour\nLetâ€™s create interactive plots to provide an insightful representation of the distribution of origin/destination locations and emphasise the specific hours that stand out in terms of pickup/drop-off frequency.\n\n\n3.2.1.1 Origin or Pickup Frequency\nFor creating a bar plot with ggplot, the pickup hours are first converted to numeric values for analysis. TThe x-axis represents the pickup hours, and the y-axis represents the count of origin locations. To highlight the hours with the highest count with a visual indication, we add a red dashed vertical line on the plot. The ggplot object is then converted into an interactive plot using ggplotly, allowing users to hover over bars for detailed information.\n\ngrab_origin$start_hr &lt;- as.numeric(grab_origin$start_hr)\norg&lt;- ggplot(data = grab_origin, aes(x = start_hr)) +\n  geom_bar() +\n  labs(title = \"Distribution of Origin Locations by Pickup Hour\",\n       x = \"Pickup Hour\",\n       y = \"Count\") +\n  scale_x_continuous(breaks = seq(0, 24, by = 1)) +\n  theme_minimal()\nmax_hour &lt;- which.max(table(grab_origin$start_hr))\norg &lt;- org + geom_vline(xintercept = max_hour, linetype = \"dashed\", color = \"red\")\n\norg &lt;- ggplotly(org)\norg\n\nThe chart above indicates that most pickups occur at 2-3pm, a potential reason could include:\n\nAfter-School Activities: this time period may coincide with school release times and after-school activities. Parents might be picking up children or transporting them to various activities.\n\n\n\n3.2.1.2 Destination or Drop-off Frequency\nFor creating a bar plot with ggplot, the drop-off hours are first converted to numeric values for analysis. TThe x-axis represents the drop-off hours, and the y-axis represents the count of destination locations. To highlight the hours with the highest count with a visual indication, we add a red dashed vertical line on the plot. The ggplot object is then converted into an interactive plot using ggplotly, allowing users to hover over bars for detailed information.\n\ngrab_dest$end_hr &lt;- as.numeric(grab_dest$end_hr)\ndest&lt;- ggplot(data = grab_dest, aes(x = end_hr)) +\n  geom_bar() +\n  labs(title = \"Distribution of Destinatioon Locations by Drop-off Hour\",\n       x = \"Drop-off Hour\",\n       y = \"Count\") +\n  scale_x_continuous(breaks = seq(0, 24, by = 1)) +\n  theme_minimal()\nmax_hour &lt;- which.max(table(grab_dest$end_hr))\ndest &lt;- dest + geom_vline(xintercept = max_hour, linetype = \"dashed\", color = \"red\")\n\ndest &lt;- ggplotly(dest)\ndest\n\nThe chart above indicates that most drop-offs occur at 2pm, a potential reason could include:\n\nLunchtime Rush: 2pm is often around the time people finish their lunch breaks. This could result in increased travel demand as people return to work or resume their activities.\n\n\n\n3.2.2 Frequency of Trip by Day of Week\nLetâ€™s create a bar chart to explore the frequency of origins/destinations across different days and identify any noteworthy patterns.\n\n\n3.2.2.1 Origin or Pickup Frequency by Days\nThe code uses ggplot to create a bar plot, where each bar represents the frequency of pickups on a specific day. This code produces a informative visualisation to explore patterns in pickup frequency throughout the week.\n\norigin_day &lt;- ggplot(data = grab_origin, aes(x = weekday))  +\n              geom_bar(fill = \"#4C78A8\", color = \"#4C78A8\", alpha = 0.8) +\n              labs(title = \"Frequency of Pickup by Day of Week\",\n                   x = \"Day\",\n                   y = \"Count\") +\n              theme_minimal()\norigin_day &lt;- ggplotly(origin_day)\norigin_day\n\n\nThe distribution of trips across days appears generally uniform, with a subtle increase observed on Wednesdays.\n\n\n\n3.2.2.2 Destination or Drop-off Frequency by Days\nThe code uses ggplot to create a bar plot, where each bar represents the frequency of drop-offs on a specific day. This code produces a informative visualisation to explore patterns in drop-off frequency throughout the week.\n\ndest_day &lt;- ggplot(data = grab_dest, aes(x = weekday))  +\n              geom_bar(fill = \"#FF0000\", color = \"#FF0000\", alpha = 0.8) +\n              labs(title = \"Frequency of Drop-off by Day of Week\",\n                   x = \"Day\",\n                   y = \"Count\") +\n              theme_minimal()\ndest_day &lt;- ggplotly(dest_day)\ndest_day\n\n\nIf we plot by destination, we see the same result. This is expected, considering that each tripâ€™s origin corresponds to a destination."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#first-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#first-order-spatial-point-patterns-analysis",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "4.0 First-Order Spatial Point Patterns Analysis",
    "text": "4.0 First-Order Spatial Point Patterns Analysis\nFirst-order spatial point pattern analysis focuses on the distribution of individual points in a given spatial domain. It involves examining the basic characteristics and properties of the point pattern itself, without considering the interactions or relationship between points.\n\n4.1 Rescale grab_original_ppp_sg and grab_dest_ppp_sg\nFor further analysis, it is necessary to convert our data to kilometers, and we can achieve this by utilising the rescale function on grab_original_ppp_sg and grab_dest_ppp_sg which are in metres.\n\n# | eval: false\ngrab_origin_ppp_sg_km &lt;- rescale(grab_origin_ppp_sg, 1000, 'km')\ngrab_dest_ppp_sg_km &lt;- rescale(grab_dest_ppp_sg, 1000, 'km')\n\n\n#write_rds(grab_origin_ppp_sg_km, \"data/rds/grab_origin_ppp_sg_km.rds\")\ngrab_origin_ppp_sg_km &lt;- read_rds(\"data/rds/grab_origin_ppp_sg_km.rds\")\n\n\n#write_rds(grab_dest_ppp_sg_km, \"data/rds/grab_dest_ppp_sg_km.rds\")\ngrab_dest_ppp_sg_km &lt;- read_rds(\"data/rds/grab_dest_ppp_sg_km.rds\")\n\n\n\n4.2 Kernel Density Estimation\nKernel Density Estimation (KDE) is a technique used in spatial point pattern analysis to estimate the density of events across a continuous space based on a set of observed point locations. It is particularly when we have a set of spatial points and want to visualise the spatial distribution of these points in a smoother and more continuous way.\nThe are different approaches for selecting the bandwidth or smoothing parameter of the kernel.\n\nautomatic bandwidth method\nfixed bandwidth method\n\n\n\n4.2.1 Automatic bandwidth method\nHere the bandwidth is determined automatically by the algorithm based on some optimisation criterion.\nThere are several spatstat functions that we can use for automatic bandwidth selection.\nThe densityÂ function allows us to compute a kernel density for a given set of point events.\nFirst, we use the bw.diggle() method.\n\nbw.diggle() Cross Validated Bandwidth Selection for Kernel Density\n\n\nkde_grab_origin_sg_bw &lt;- density(grab_origin_ppp_sg_km,\n                                   sigma=bw.diggle,\n                                   edge=TRUE,\n                                   kernel=\"gaussian\")\n\n\npar(mar = c(1,1,1,1))\nplot(kde_grab_origin_sg_bw,main = \"KDE Automatic Bandwidth for Origin Points\")\n\n\nkde_grab_dest_sg_bw &lt;- density(grab_dest_ppp_sg_km,\n                                   sigma=bw.diggle,\n                                   edge=TRUE,\n                                   kernel=\"gaussian\")\nkde_grab_dest_sg_bw\n\n\npar(mar = c(1,1,1,1))\nplot(kde_grab_dest_sg_bw,main = \"KDE Automatic Bandwidth for Destination Points\")\n\n\n\n4.2.1.1 Other Bandwidth Selection Methods\nAdditionally we can choose from a series of options for â€˜kernelâ€™ which is the smoothing parameter that we will explore later. Letâ€™s explore the other methods for automatic bandwidth selection and retrieve sigma value. The sigma value tells us the amount of smoothing applied when estimating the kernel density.\n\nbw.diggle() Cross Validated Bandwidth Selection for Kernel Density\n\n\nbw_diggle &lt;- bw.diggle(grab_origin_ppp_sg_km)\nbw_diggle\n\n\nbw.CvL() Cronie and Van Lieshoutâ€™s Criterion for Bandwidth Selection for Kernel Density\n\n\nbw_CvL &lt;- bw.CvL(grab_origin_ppp_sg_km)\nbw_CvL\n\n\nbw.scott() Scottâ€™s Rule for Bandwidth Selection for Kernel Density\n\n\nbw_scott &lt;- bw.scott(grab_origin_ppp_sg_km)\nbw_scott\n\n\nbw.ppl() Likelihood Cross Validation Bandwidth Selection for Kernel Density\n\n\nbw_ppl &lt;- bw.ppl(grab_origin_ppp_sg_km)\nbw_ppl\n\nLetâ€™s plot to compare the output of each method, so that we can see the distinct differences in KDE layers .\n\nkde_diggle &lt;- density(grab_origin_ppp_sg_km, bw_diggle)\nkde_CvL &lt;- density(grab_origin_ppp_sg_km, bw_CvL)\nkde_scott &lt;- density(grab_origin_ppp_sg_km, bw_scott)\nkde_ppl &lt;- density(grab_origin_ppp_sg_km, bw_ppl)\n\npar(mfrow = c(2,2), mar = c(1,1,1,1))\nplot(kde_diggle,main = \"KDE diggle\")\nplot(kde_CvL,main = \"KDE CvL\")\nplot(kde_scott,main = \"KDE Scott\")\nplot(kde_ppl,main = \"KDE ppl\")\n\n\nFrom first glance, it looks as though KDE Scott shows the best resuts with the clearest peaks.\nBut in order to pick the most suitable method for our analysis, we need to compare the distribution of KDE values. We can do so simply by visualising the distribution using histograms. Letâ€™s check again KDE Scott shows the most ideal result.\n\n\npar(mfrow = c(2,2),mar = c(3,3,3,3))\nhist(kde_diggle,main = \"KDE diggle\")\nabline(v=50, \n       col=\"red\")\nhist(kde_CvL,main = \"KDE CvL\")\nabline(v=50, \n       col=\"red\")\nhist(kde_scott,main = \"KDE Scott\")\nabline(v=50, \n       col=\"red\")\nhist(kde_ppl,main = \"KDE ppl\")\nabline(v=50, \n       col=\"red\")\n\n\n\n4.2.1.2 Choosing the Most Appropriate KDE Selection Method\n\nLooking at the histograms, the one for bw_scott() shows that it has a broad spread as compared to the others and does not peak which means there is an even distribution of points across all bins. Therefore we will pick bw_scott().\n\n\n\n4.2.2 Fixed Bandwidth Selection\nHere, we manually specify a fixed bandwidth value for the KDE layer. This allows us to control the level of smoothing applied to the point pattern. We will plot using bw_scott()as identified previously as the most suitable method.\n\nfixed_bw_scott &lt;- bw.scott(grab_origin_ppp_sg_km)\nfixed_bw_scott\n\nThe values returned are 1.59 and 0.94 for sigma.x and sigma.y respectively.\nThen, we plot to visualise the fixed bandwidth using bw_scott\n\nkde_fixed_bw_scott &lt;- density(grab_origin_ppp_sg_km, fixed_bw_scott)\npar(mar = c(1,1,1,1))\nplot(kde_fixed_bw_scott, main ='Scott Method Fixed Bandwidth KDE for Origin Points')\n\n\n\n4.2.3 Different Kernel Function Selection Methods for Fixed Bandwidth\nThe default kernel inÂ density.ppp()Â is theÂ gaussian. There are other options such as epanechnikov, quartic and disc.\nLetâ€™s explore the different kernel function selection methods.\n\nkde_fixed_bw_scott_gaussian &lt;- density(grab_origin_ppp_sg_km, \n                          sigma=fixed_bw_scott, \n                          edge=TRUE, \n                          kernel=\"gaussian\")\n\n\nkde_fixed_bw_scott_epanechnikov &lt;- density(grab_origin_ppp_sg_km, \n                          sigma=fixed_bw_scott, \n                          edge=TRUE, \n                          kernel=\"epanechnikov\")\n   \nkde_fixed_bw_scott_quartic &lt;- density(grab_origin_ppp_sg_km, \n                          sigma=fixed_bw_scott, \n                          edge=TRUE, \n                          kernel=\"quartic\")\n       \n   \nkde_fixed_scott_disc &lt;- density(grab_origin_ppp_sg_km, \n                          sigma=fixed_bw_scott, \n                          edge=TRUE, \n                          kernel=\"disc\")\n\nLetâ€™s visualise the different kernel methods.\n\npar(mfrow = c(2,2), mar = c(2,2,2,2))\nplot(kde_fixed_bw_scott_gaussian, main=\"Gaussian\")\nplot(kde_fixed_bw_scott_epanechnikov, main=\"Epanechnikov\")\nplot(kde_fixed_bw_scott_quartic, main=\"Quartic\")\nplot(kde_fixed_scott_disc,main=\"Disc\")\n\nThere are subtle differences in the smoothness and dispersion among the four plots, but they collectively show the same pattern in the end.\n\n\n4.2.3 KDE Layers with Spatially Adaptive Bandwidth\nHere, we use the most common adaptive bandwidth method called Adaptive Kernel Density Estimate.\n\nkde_adaptive &lt;- adaptive.density(grab_origin_ppp_sg_km, method=\"kernel\")\n\n\n\n4.2.4 Comparing Fixed and Adaptive Bandwidth\nLetâ€™s do a side-by-side comparision of fixed bandwidth and adaptive bandwidth method .\n\npar(mfrow=c(1,2), mar = c(3,3,3,3))\nplot(kde_fixed_bw_scott_gaussian, main = \"Fixed bandwidth\")\nplot(kde_adaptive, main = \"Adaptive bandwidth\")\n\n\nThe fixed bandwidth method makes it easier to identify areas of higher origin point clusters\n\n\n\n4.2.5 Interactive KDE Maps\nNow letâ€™s plot interactive KDE maps to have a closer look.\n\n\n4.2.5.1 Converting KDE Output into Grid Object into RasterLayer Object\nWe need to convert our KDE output into grid objects for mapping purposes, here we use the raster() function.\n\nkde_fixed_bw_scott_raster &lt;- raster(kde_fixed_bw_scott)\nkde_adaptive_kernel_raster &lt;- raster(kde_adaptive)\n\nThen we perform project transformation.\n\nprojection(kde_fixed_bw_scott_raster) &lt;- CRS(\"+init=EPSG:3414 +units=km\")\nprojection(kde_adaptive_kernel_raster) &lt;- CRS(\"+init=EPSG:3414 +units=km\")\n\n\n\n4.2.5.2 Kernel Density Maps on OpenStreetMap\nFinally, we can visualise our Kernel Density Maps on OpenStreetMap\n\ntmap_mode('view')\nkde_fixed_bw_scott_map &lt;- tm_basemap(\"OpenStreetMap\") +\n  tm_view(set.zoom.limits=c(10, 15)) +\n  tm_shape(kde_fixed_bw_scott_raster) +\n  tm_raster(alpha = 0.65, title = \"KDE_Fixed_Scott\", palette = brewer.pal(12, \"Set3\")) +\n  tm_shape(mpsz_sf)+\n  tm_polygons(alpha=0.1, id=\"PLN_AREA_N\")+\n  tmap_options(check.and.fix = TRUE)+\n  tm_layout(title = \"Scott Method Fixed Bandwidth KDE for Origin Points\")\ntmap_leaflet(kde_fixed_bw_scott_map)\n\n\ntmap_mode('view')\nkde_adaptive_kernel_map &lt;- tm_basemap(\"OpenStreetMap\") +\n  tm_view(set.zoom.limits=c(10, 15)) +\n  tm_shape(kde_adaptive_kernel_raster) +\n  tm_raster(alpha = 0.65, title = \"KDE_Adaptive_Kernel\", palette = brewer.pal(12, \"Set3\")) +\n  tm_shape(mpsz_sf)+\n  tm_polygons(alpha=0.1, id=\"PLN_AREA_N\")+\n  tmap_options(check.and.fix = TRUE)+\n  tm_layout(title = \"Adaptive Bandwidth KDE for Origin Points\")\ntmap_leaflet(kde_adaptive_kernel_map)\n\n\n\n4.2.6 Kernel Density Map Analysis\nLetâ€™s begin by extracting insights from the fixed bandwidth map, where itâ€™s notably easier to identify the high-density pickup areas represented by yellow clusters. A prominent cluster emerges in the central-south region, encompassing stations such as Newton, Orchard, Downtown East, and Rochor. These areas exhibit increased demand for Grab pickups, potentially influenced by their status as tourist attractions. The tendency for individuals to explore these locales and then opt for Grab as their origin point prompts questions about the efficacy of public transport planning in encouraging more sustainable transportation choices.\nAdditionally, a big cluster forms at Changi Airport, which is quite understandable. Travelers landing in Singapore, often fatigued and burdened with luggage, may prefer the convenience of Grab over public transportation for their journey home.\nBeyond these, smaller yet discernible clusters show up in various residential zones. Referencing the adaptive bandwidth map for precise locations, we observe clusters in the north (Choa Chu Kang, Bukit Panjang), west (Jurong West, Jurong East), east (Tampines, Pasir Ris), and north-east (Woodlands, Sembawang, Yishun). This prompts further inquiries into the connectivity of these regions to public transport networks and the factors influencing residents to choose Grab over alternative transportation modes.\nIn essence, these spatial patterns raise intriguing questions about the accessibility and appeal of public transportation in these specific areas.\n\n\n4.2.7 Extract Planning Areas\nFrom the array of residential clusters pinpointed in the previous section, we will focus on four specific stations, each corresponding to distinct geographical regions: north, east, west, and north-east.\n\nNorth: Choa Chu Kang\nWest: Jurong East\nEast: Tampines\nNorth-East: Woodlands\n\nLetâ€™s extract out these study areas from mpsz_sf using filter and store it in new objects.\n\nje = mpsz_sf%&gt;%\n  filter(PLN_AREA_N == \"JURONG EAST\")\ntm = mpsz_sf%&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck = mpsz_sf%&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\nwd = mpsz_sf%&gt;%\n  filter(PLN_AREA_N == \"WOODLANDS\")\n\n\n\n4.2.7.1 Plotting Target Planning Areas\n\npar(mfrow=c(2,2))\nplot(st_geometry(je), main = \"Jurong East\")\nplot(st_geometry(tm), main = \"Tampines\")\nplot(st_geometry(ck), main = \"Choa Chu Kang\")\nplot(st_geometry(wd), main = \"Woodlands\")\n\nNext, we will create owin objects to represent the observation windows for respective planning area.\n\nje_owin = as.owin(je)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\nwd_owin = as.owin(wd)\n\norigin_je_ppp = grab_origin_ppp_sg[je_owin]\norigin_tm_ppp = grab_origin_ppp_sg[tm_owin]\norigin_ck_ppp = grab_origin_ppp_sg[ck_owin]\norigin_wd_ppp = grab_origin_ppp_sg[wd_owin]\n\n\n4.2.7.2 KDE Fixed-Bandwidth for Target Planning Areas\n\nje_kde_scott &lt;- density(origin_je_ppp, sigma=bw.scott, main=\"Jurong East\")\ntm_kde_scott &lt;- density(origin_tm_ppp, sigma=bw.scott, main=\"Tampines\")\nck_kde_scott &lt;- density(origin_ck_ppp, sigma=bw.scott, main=\"Choa Chu Kang\")\nwd_kde_scott &lt;- density(origin_wd_ppp, sigma=bw.scott, main=\"Woodlands\")\n\n\npar(mfrow = c(2,2))\nplot(je_kde_scott,main = \"KDE Jurong East\")\nplot(tm_kde_scott,main = \"KDE Tampines\")\nplot(ck_kde_scott,main = \"KDE Choa Chu Kang\")\nplot(wd_kde_scott,main = \"KDE Woodlands\")\n\nNow, identifying clusters within each planning area is easily achievable. However, pinpointing the exact locations of these clusters requires the incorporation of road networks for each planning area. To achieve this precision, we will leverage a more advanced KDE technique known as Network Kernel Density Estimation (NKDE) in the upcoming sections. This approach will provide deeper insights into the specific roads or areas within each planning area that host these clusters.\n\n\n\n4.2.8 Nearest Neighbour Analysis\nNearest Neighbor Analysis helps assess whether the observed spatial pattern is clustered, dispersed, or random.\nHere we will be using the Clark-Evans Test of Aggregation.\n\n\n4.2.8.1 Clark-Evans Test of Aggregation\nHere, we will perform the Clark-Evans test of aggregation for a spatial point pattern by usingÂ clarkevans.test()Â ofÂ statspat.\n\n\n4.2.8.1.1 Origin Points in Jurong East\nThe test hypotheses are:\n\nH0 = The distribution of origin points in Jurong East are randomly distributed\nH1= The distribution of origin points in Jurong East are not randomly distributed\n\nThe 95% confident interval will be used.\n\nclarkevans.test(origin_je_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\nWe can conclude that the distribution of origin points in Jurong East is not randomly distributed\n\n\n4.2.8.1.2 Origin Points in Tampines\nThe test hypotheses are:\n\nH0 = The distribution of origin points in Tampines are randomly distributed\nH1= The distribution of origin points in Tampines are not randomly distributed\n\nThe 95% confidence interval will be used.\n\nclarkevans.test(origin_tm_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\nWe can conclude that the distribution of origin points in Tampines is not randomly distributed\n\n\n4.2.8.1.3 Origin Points in Choa Chu Kang\nThe test hypotheses are:\n\nH0 = The distribution of origin points in Choa Chu Kang are randomly distributed\nH1= The distribution of origin points in Choa Chu Kang are not randomly distributed\n\nThe 95% confidence interval will be used.\n\nclarkevans.test(origin_ck_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\nWe can conclude that the distribution of origin points in Choa Chu Kang is not randomly distributed\n\n\n4.2.8.1.4 Origin Points in Woodlands\nThe test hypotheses are:\n\nH0 = The distribution of origin points in Woodlands are randomly distributed\nH1= The distribution of origin points in Woodlands are not randomly distributed\n\nThe 95% confidence interval will be used.\n\nclarkevans.test(origin_wd_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\nWe can conclude that the distribution of origin points in Woodlands is not randomly distributed"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-constrained-kernel-density-estimation-nkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-constrained-kernel-density-estimation-nkde",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "5.0 Network Constrained Kernel Density Estimation (NKDE)",
    "text": "5.0 Network Constrained Kernel Density Estimation (NKDE)\nNetwork Kernel Density Estimation (NKDE) is an advanced technique that builds upon the traditional KDE method.\nWe employ NKDE because the distribution of origin points in our planning areas is not randomly distributed; it is significantly influenced by network structures. NKDE allows us to incorporate this network context, providing a more accurate representation of spatial patterns, particularly along roadways. By considering the connectivity and pathways of the network, NKDE enhances our ability to capture the nuanced distribution of clusters within each planning area, leading to more insightful and precise spatial analysis results\nThe main difference between the KDE and NKDE is that KDE treats space as a continuous field, and overlooks the underlying network structure, such as roads. NKDE takes into account the network structure, and recognises that spatial relationships may be constrained by the existing road infrastructure. Therefore, NKDE offers better localization of clusters by considering the connectivity and pathways of the network.\nHere, we will use spNetwork to create NKDE maps for each of our planning areas and explore what insights we can yield from each."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extract-origin-points-and-road-network-of-our-study-areas",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extract-origin-points-and-road-network-of-our-study-areas",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "5.1 Extract origin points and road network of our study areas",
    "text": "5.1 Extract origin points and road network of our study areas\nFirstly we need to extract the road networks within each of our study area by using st_intersection. We also use st_union to combine all the geometries of each object into a single geometry.\n\nje_roads = st_intersection(sg_roads,st_union(je))\ntm_roads = st_intersection(sg_roads,st_union(tm))\nck_roads = st_intersection(sg_roads,st_union(ck))\nwd_roads = st_intersection(sg_roads,st_union(wd))\n\nAfter that, we will use st_intersection again to find the origin spots that intersect with our planning areas.\n\nje_origin = st_intersection(grab_origin,st_union(je))\ntm_origin = st_intersection(grab_origin,st_union(tm))\nck_origin = st_intersection(grab_origin,st_union(ck))\nwd_origin = st_intersection(grab_origin,st_union(wd))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#lixels",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#lixels",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "5.2 Lixels",
    "text": "5.2 Lixels\nEach network edge is divided into lixels which represent the lines of the network. To get the lixels of each planning area we use the st_cast function first to convert the geometry types of the features in our object to LINESTRING.\n\nje_roads &lt;- st_cast(je_roads, \"LINESTRING\")\ntm_roads &lt;- st_cast(tm_roads, \"LINESTRING\")\nck_roads &lt;- st_cast(ck_roads, \"LINESTRING\")\nwd_roads &lt;- st_cast(wd_roads, \"LINESTRING\")\n\nAfter we have converted the geometry type of our planning areas, we use lixelize_lines to create lixels from a set of road lines represented by the planning area objects. The road lines are divided into lixels, each with a length of 750 units. mindist represents the minimum distance between lixels to ensure that resulting lixels are not too close to each other. If the length of the resulting lixel is less than the specified minimum distance, it is combined with the previous lixel.\n\nje_lixels &lt;- lixelize_lines(je_roads, \n                         750, \n                         mindist = 375)\n\ntm_lixels &lt;- lixelize_lines(tm_roads, \n                         750, \n                         mindist = 375)\n\nck_lixels &lt;- lixelize_lines(ck_roads, \n                         750, \n                         mindist = 375)\n\nwd_lixels &lt;- lixelize_lines(wd_roads, \n                         750, \n                         mindist = 375)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#line-center",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#line-center",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "5.3 Line Center",
    "text": "5.3 Line Center\nThen we extract the centers of the lixels using lines_center. These serve as the locations for intensity estimation.\n\nje_samples &lt;- lines_center(je_lixels)\ntm_samples &lt;- lines_center(tm_lixels)\nck_samples &lt;- lines_center(ck_lixels)\nwd_samples &lt;- lines_center(wd_lixels)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#using-simple-method-to-compute-nkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#using-simple-method-to-compute-nkde",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "5.4 Using Simple Method to Compute NKDE",
    "text": "5.4 Using Simple Method to Compute NKDE\nFinally we use the nkde function from spNetwork to get the NKDE. There are several parameters that we can define\n\nevents: the event associated with the analysis\nw: weight vector, creates a vector of ones with a length equal to the number of rows in the planning area data frame\nsamples: samples used for density estimation\nkernel_name: type of kernel to be used\nbw: determines the scale of influence for each point in the density estimation\ndiv: the method used to determine the bandwidth\nmethod: method used for density estimation\ndigits: number of significant digits displayed in the output\ntol: tolerance level for convergence in iterative algorithms\ngrid_shape: shape of the grid for calculating the density\nmax_depth: Maximum depth of the tree when building the spatial index\nagg: number of points aggregated into each grid cell\nsparse: whether to use sparse matrix representation for efficiency\nverbose: suppresses verbose output during the process\n\n\nje_density &lt;- nkde(je_roads, \n                  events = je_origin,\n                  w = rep(1,nrow(je_origin)),\n                  samples = je_samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\ntm_density &lt;- nkde(tm_roads, \n                  events = tm_origin,\n                  w = rep(1,nrow(tm_origin)),\n                  samples = tm_samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nck_density &lt;- nkde(ck_roads, \n                  events = ck_origin,\n                  w = rep(1,nrow(ck_origin)),\n                  samples = ck_samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nwd_density &lt;- nkde(wd_roads, \n                  events = wd_origin,\n                  w = rep(1,nrow(wd_origin)),\n                  samples = wd_samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nWe are also required to join the density values into the samples and lixels objects. The obtained densities will be scaled by the total number of origin points and we will multiply by 1000 for km measurement.\n\nje_samples$density &lt;- je_density*nrow(je_origin)*1000\nje_lixels$density &lt;- je_density*nrow(je_origin)*1000\n\ntm_samples$density &lt;- tm_density*nrow(tm_origin)*1000\ntm_lixels$density &lt;- tm_density*nrow(tm_origin)*1000\n\nck_samples$density &lt;- ck_density*nrow(ck_origin)*1000\nck_lixels$density &lt;- ck_density*nrow(ck_origin)*1000\n\nwd_samples$density &lt;- wd_density*nrow(wd_origin)*1000\nwd_lixels$density &lt;- wd_density*nrow(wd_origin)*1000"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plotting-maps-for-different-study-areas",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plotting-maps-for-different-study-areas",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "5.5 Plotting Maps for Different Study Areas",
    "text": "5.5 Plotting Maps for Different Study Areas\nLetâ€™s plot the NKDE map for each planning area.\n\n5.5.1 Jurong East\n\ntmap_mode('view')\nje_density_map &lt;- tm_basemap(\"OpenStreetMap\") +\ntm_shape(je_lixels)+\n  tm_lines(col =\"density\", lwd = 3, palette = brewer.pal(12, \"Set3\"))+\ntm_shape(je_origin)+\n  tm_dots(size=0.05)+\n  tm_layout(title = \"Jurong East NKDE\")\ntmap_leaflet(je_density_map)\n\n\n\n\n\n\n\nNote\n\n\n\nAnalysis\nIn Jurong East, notable clusters of taxi pick-up points have been observed around Yuhua Place, Yuhua Senior Activity Center, New Jurong Polyclinic, and the nursing home vicinity. Additionally, clusters are prevalent near Parc Oasis, Singtel, Zai Shun Seafood, in proximity to Toh Guan, Westgate, Shen Hong Temple, Jurong East Interchange, IMM, Yuhua Primary School, and Crest Secondary School.\nThis clustering phenomenon may be attributed to\n\nCommercial Hubs: Areas like Westgate and IMM are major commercial centers, attracting a higher demand for Grab services. For example, people may book Grab to pick them up after they finish shopping in these areas.\nHealthcare Facilities: Proximity to healthcare facilities such as the New Jurong Polyclinic and nursing homes may lead to increased transportation needs. For example, patients or visitors might utilise Grab for convenient travel from medical appointments, contributing to the clustering effect around healthcare establishments.\nEducational Institutions: The presence of schools like Yuhua Primary School and Crest Secondary School could contribute to higher Grab demand during school-related activities. For example, parents may pick up their children after school and book Grab to their residence.\nTransportation Hubs: Jurong East Interchange serves as a transportation hub, leading to concentrated Grab activity in the area. Commuters arriving at or departing from the interchange might prefer Grab for last-mile connectivity, resulting in a clustering effect around this transportation hub.\nRecreational Areas: Clusters around Parc Oasis and Yuhua Senior Activity Center may be influenced by recreational and leisure activities. Caregivers visiting seniors at the Senior Activity Center may book Grab from there to their homes.\nCultural and Religious Centers: Locations like Shen Hong Temple may attract Grab pick-ups during events or gatherings. Attendees of cultural or religious events may use Grab for transportation from these centers.\nResidential Areas: Proximity to residential areas like Yuhua Place may result in frequent Grab pickup requests for residents. Residents in these areas might regularly utilise Grab for daily commuting or transportation needs.\nCulinary Hotspots: Clusters around Zai Shun Seafood restaurant may be influenced by popular dining establishments, drawing people to the area and making them book Grab from there to their journey back.\n\n\n\n\n\n5.5.2 Tampines\n\ntmap_mode('view')\ntm_density_map &lt;- tm_basemap(\"OpenStreetMap\") +\ntm_shape(tm_lixels)+\n  tm_lines(col =\"density\", lwd = 3, palette = brewer.pal(12, \"Set3\"))+\ntm_shape(tm_origin)+\n  tm_dots(size=0.05)+\n  tm_layout(title = \"Tampines NKDE\")\ntmap_leaflet(tm_density_map)\n\n\n\n\n\n\n\nNote\n\n\n\nAnalysis\nIn Tampines, clusters of Grab pick-up points are notable around Our Tampines Hub, Tanah Merah Country Club, opposite Tampines Neighbourhood Police Center, opposite Ngee Ann Secondary School, Tampines East, Laguna Country Club, and East Coast Park.\nThis clustering phenomenon may be attributed to\nRecreational Clubs: Areas like Tanah Merah Country Club and Laguna Country Club may contribute to clusters of Grab pick-up points. Individuals visiting these recreational clubs for leisure activities may opt for Grab services for their journey back from here for convenience.\nPolice Center: The area opposite Tampines Neighbourhood Police Center may attract Grab pick-ups due visitors requiring transportation from the area.\nCommunity and Recreational Center: Our Tampines Hub is a central community and recreational center, leading to higher demand for Grab services. People utilising the various facilities may book Grab for their journeys back.\nEducational Institutions: The area opposite Ngee Ann Secondary School could contribute to higher Grab demand during school-related activities. For example, parents may pick up their children after school and book Grab to their residence.\nResidential Areas: Tampines East, being a residential area, may result in frequent Grab pickup requests for residents. Residents in these areas might regularly utilise Grab for daily commuting or transportation needs.\nRecreational Destination: East Coast Park, a popular recreational area, may attract individuals for outdoor activities. Visitors to the park may choose to book Grab for their journey back home, contributing to the clustering effect.\n\n\n\n\n5.5.3 Choa Chu Kang\n\ntmap_mode('view')\nck_density_map &lt;- tm_basemap(\"OpenStreetMap\") +\ntm_shape(ck_lixels)+\n  tm_lines(col =\"density\", lwd = 3, palette = brewer.pal(12, \"Set3\"))+\ntm_shape(ck_origin)+\n  tm_dots(size=0.05)+\n  tm_layout(title = \"Choa Chu Kang NKDE\")\ntmap_leaflet(ck_density_map)\n\n\n\n\n\n\n\nNote\n\n\n\nAnalysis\nIn Choa Chu Kang, clusters of Grab pick-up points can be seen around Inn See Temple, Choa Chu Kang Interchange, SAFRA@CCK, Gain City, Lot One, Keat Hong Colours, Phoenix Station, Bukit Panjang Post Office, Yew Mei Condominium, MWS Nursing Home, and Yew Tee Point.\nThis clustering phenomenon may be attributed to\n\nCultural and Religious Centers: Inn See Templeâ€™s vicinity may attract Grab pick-ups during religious events, contributing to the observed cluster.\nTransportation Hub: Choa Chu Kang Interchange serves as a transportation hub, leading to concentrated Grab activity in the area. Commuters arriving at or departing from the interchange might prefer Grab for last-mile connectivity, resulting in a clustering effect around this transportation hub.\nRecreational Facility: The presence of SAFRA@CCK could contribute to increased Grab pickup activity, especially after events and recreational activities hosted at the facility.\nShopping Centers: Yew Tee Point, Gain City and Lot One, being prominent shopping destinations, may experience a higher level of Grab pick-up points as shoppers prefer convenient transportation after their shopping sprees.\nResidential Areas: Clusters around Keat Hong Colours, and Yew Mei Condominium may be attributed to the residential nature of these areas, with residents relying on Grab for commuting needs.\nPostal Area: Bukit Panjang Post Office may attract Grab pick-ups, for individuals who have completed their postal services or nearby activities.\nHealthcare: Presence of MWS Nursing Home may lead to increased transportation needs. Caregivers visiting seniors at the nursing home may book Grab from there to their homes.\n\n\n\n\n\n5.5.4 Woodlands\n\ntmap_mode('view')\nwd_density_map &lt;- tm_basemap(\"OpenStreetMap\") +\ntm_shape(wd_lixels)+\n  tm_lines(col =\"density\", lwd = 3, palette = brewer.pal(12, \"Set3\"))+\ntm_shape(wd_origin)+\n  tm_dots(size=0.05)+\n  tm_layout(title = \"Woodlands NKDE\")\ntmap_leaflet(wd_density_map)\n\n\n\n\n\n\n\nNote\n\n\n\nIn Woodlands, distinct clusters of taxi pick-up points have been identified around Innova Junior College, Singapore Sports School, Civic Centre, STELLAR@TE2, Singapore Turf Club, Old Woodlands Town Centre, Masjid An Nur, Woodlands Cinema, Greenwood Primary School, and Mega@Woodlands.\nThis clustering phenomenon may be attributed to\n\nEducational Institutions: Clusters around Innova Junior College and Singapore Sports School could be attributed to the presence of these educational institutions. Students, staff, and visitors may opt for Grab for convenient transportation from these locations.\nCivic and Community Center: Civic Centre, being a civic and community hub, may experience higher demand for Grab pickup services.\nCommercial Hub: STELLAR@TE2â€™s may have individuals possibly relying on Grab for commuting on their journey back from here.\nSports and Recreation: The presence of Singapore Turf Club may contribute to the clustering effect, with people choosing Grab for transportation from sports and recreational activities.\nCommercial and Residential Hub: Old Woodlands Town Centreâ€™s central location may attract Grab pick-ups from both commercial and residential areas.\nReligious Center: Masjid An Nurâ€™s may witness increased Grab activity during religious events.\nEntertainment Venue: Woodlands Cinemaâ€™s indicates a potential concentration of Grab pick-up points, especially after movie screenings, as patrons opt for Grab for their journey home.\nEducational Facility: Greenwood Primary Schoolâ€™s location could contribute to higher Grab demand during school-related activities. For example, parents may pick up their children after school and book Grab to their residence."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusion",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "6.0 Conclusion",
    "text": "6.0 Conclusion\nThrough this take-home exercise, we delved into Spatial Point Patterns Analysis to unravel the geographical distribution of Grab Hailing Services in Singapore. Our analyses provided valuable insights, unveiling patterns such as the peak day and time for Grab pick-ups, the specific locations where these pickups occur, hotspots, and the particular roads that witness heightened activity. This information serves as a strategic tool for better planning and decision-making.\nFor instance, we can leverage these findings to enhance public transport accessibility. Understanding the road networks with the highest Grab pick-up activity allows us to identify areas where improved public transportation services could be implemented. This strategic planning aims to encourage people to opt for public transport, contributing to even pollution reduction by minimising car usage.\nIn our future endeavors, we can expand our exploration by delving into temporal Network Kernel Density Estimation (NKDE). This advanced analysis will enable us to scrutinise the intricate relationship between time and Grab Hailing Services. By identifying popular pick-up points during specific time intervals, we can propose strategic interventions, such as increasing the number of buses, adjusting bus frequencies, or implementing targeted measures to enhance transportation infrastructure in those areas. This forward-looking approach ensures a nuanced understanding of temporal patterns and facilitates more informed decisions for optimizing transportation services in Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#references",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#references",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore [DATA PREPARATION]",
    "section": "7.0 References",
    "text": "7.0 References\n\nKam, T. S. (2022). R for Geospatial Data Science and Analytics. Retrieved from https://r4gdsa.netlify.app.\nGimond (2023). Chapter 11 Point Pattern Analysis. Retrieved from https://mgimond.github.io/Spatial/index.html.\nRey, S.J., Arribas-Bel, D., & Wolf, L.J. (2023). Point Pattern Analysis. In: Geographic Data Science with python. CRC Press.\nMoraga, P. Spatial Statistics for Data Science: Theory and Practice with R. Retrieved from https://www.paulamoraga.com/book-spatial/spatial-point-patterns.html."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/MPSZ-2019.html",
    "title": "IS415 - GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC â€˜http://mrcc.com/qgis.dtdâ€™ â€˜SYSTEMâ€™&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/data/geospatial/TAINAN_VILLAGE.html",
    "href": "Take-home_Ex/Take-home_Ex02/data/geospatial/TAINAN_VILLAGE.html",
    "title": "IS415 - GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC â€˜http://mrcc.com/qgis.dtdâ€™ â€˜SYSTEMâ€™&gt;     dataset\n\n\n       GEOGCRS[â€œTWD97â€,DATUM[â€œTaiwan Datum 1997â€,ELLIPSOID[â€œGRS 1980â€,6378137,298.257222101,LENGTHUNIT[â€œmetreâ€,1]]],PRIMEM[â€œGreenwichâ€,0,ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],CS[ellipsoidal,2],AXIS[â€œgeodetic latitude (Lat)â€,north,ORDER[1],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],AXIS[â€œgeodetic longitude (Lon)â€,east,ORDER[2],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],USAGE[SCOPE[â€œHorizontal component of 3D system.â€],AREA[â€œTaiwan, Republic of China - onshore and offshore - Taiwan Island, Penghu (Pescadores) Islands.â€],BBOX[17.36,114.32,26.96,123.61]],ID[â€œEPSGâ€,3824]] +proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs 27230 3824 EPSG:3824 TWD97 longlat EPSG:7019 true"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/data/geospatial/entertn.html",
    "href": "Take-home_Ex/Take-home_Ex03/data/geospatial/entertn.html",
    "title": "IS415 - GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC â€˜http://mrcc.com/qgis.dtdâ€™ â€˜SYSTEMâ€™&gt;     dataset\n\n\n       GEOGCRS[â€œWGS 84â€,ENSEMBLE[â€œWorld Geodetic System 1984 ensembleâ€,MEMBER[â€œWorld Geodetic System 1984 (Transit)â€],MEMBER[â€œWorld Geodetic System 1984 (G730)â€],MEMBER[â€œWorld Geodetic System 1984 (G873)â€],MEMBER[â€œWorld Geodetic System 1984 (G1150)â€],MEMBER[â€œWorld Geodetic System 1984 (G1674)â€],MEMBER[â€œWorld Geodetic System 1984 (G1762)â€],MEMBER[â€œWorld Geodetic System 1984 (G2139)â€],ELLIPSOID[â€œWGS 84â€,6378137,298.257223563,LENGTHUNIT[â€œmetreâ€,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[â€œGreenwichâ€,0,ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],CS[ellipsoidal,2],AXIS[â€œgeodetic latitude (Lat)â€,north,ORDER[1],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],AXIS[â€œgeodetic longitude (Lon)â€,east,ORDER[2],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],USAGE[SCOPE[â€œHorizontal component of 3D system.â€],AREA[â€œWorld.â€],BBOX[-90,-180,90,180]],ID[â€œEPSGâ€,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/data/geospatial/FinServ.html",
    "href": "Take-home_Ex/Take-home_Ex03/data/geospatial/FinServ.html",
    "title": "IS415 - GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC â€˜http://mrcc.com/qgis.dtdâ€™ â€˜SYSTEMâ€™&gt;     dataset\n\n\n       GEOGCRS[â€œWGS 84â€,ENSEMBLE[â€œWorld Geodetic System 1984 ensembleâ€,MEMBER[â€œWorld Geodetic System 1984 (Transit)â€],MEMBER[â€œWorld Geodetic System 1984 (G730)â€],MEMBER[â€œWorld Geodetic System 1984 (G873)â€],MEMBER[â€œWorld Geodetic System 1984 (G1150)â€],MEMBER[â€œWorld Geodetic System 1984 (G1674)â€],MEMBER[â€œWorld Geodetic System 1984 (G1762)â€],MEMBER[â€œWorld Geodetic System 1984 (G2139)â€],ELLIPSOID[â€œWGS 84â€,6378137,298.257223563,LENGTHUNIT[â€œmetreâ€,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[â€œGreenwichâ€,0,ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],CS[ellipsoidal,2],AXIS[â€œgeodetic latitude (Lat)â€,north,ORDER[1],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],AXIS[â€œgeodetic longitude (Lon)â€,east,ORDER[2],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],USAGE[SCOPE[â€œHorizontal component of 3D system.â€],AREA[â€œWorld.â€],BBOX[-90,-180,90,180]],ID[â€œEPSGâ€,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/data/geospatial/Retails.html",
    "href": "Take-home_Ex/Take-home_Ex03/data/geospatial/Retails.html",
    "title": "IS415 - GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC â€˜http://mrcc.com/qgis.dtdâ€™ â€˜SYSTEMâ€™&gt;     dataset\n\n\n       GEOGCRS[â€œWGS 84â€,ENSEMBLE[â€œWorld Geodetic System 1984 ensembleâ€,MEMBER[â€œWorld Geodetic System 1984 (Transit)â€],MEMBER[â€œWorld Geodetic System 1984 (G730)â€],MEMBER[â€œWorld Geodetic System 1984 (G873)â€],MEMBER[â€œWorld Geodetic System 1984 (G1150)â€],MEMBER[â€œWorld Geodetic System 1984 (G1674)â€],MEMBER[â€œWorld Geodetic System 1984 (G1762)â€],MEMBER[â€œWorld Geodetic System 1984 (G2139)â€],ELLIPSOID[â€œWGS 84â€,6378137,298.257223563,LENGTHUNIT[â€œmetreâ€,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[â€œGreenwichâ€,0,ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],CS[ellipsoidal,2],AXIS[â€œgeodetic latitude (Lat)â€,north,ORDER[1],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],AXIS[â€œgeodetic longitude (Lon)â€,east,ORDER[2],ANGLEUNIT[â€œdegreeâ€,0.0174532925199433]],USAGE[SCOPE[â€œHorizontal component of 3D system.â€],AREA[â€œWorld.â€],BBOX[-90,-180,90,180]],ID[â€œEPSGâ€,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "title": "In-class Exercise 9:Geographically Weighted Predictive Models",
    "section": "",
    "text": "pacman::p_load(sf, spdep, GWmodel, SpatialML, \n              tmap, Metrics,  tidymodels, tidyverse, gtsummary, rpart, rpart.plot, ggstatsplot, performance,)\n\nrpart and rpart.plot is for recursive functioning purposes\n\nrs_sf &lt;- read_rds(\"data/rds/HDB_resale.rds\")\n\n\nset.seed(1234)\nresale_split &lt;- initial_split(rs_sf, \n                              prop = 5/10,)\ntrain_sf &lt;- training(resale_split)\ntest_sf &lt;- testing(resale_split)\n\n\ntrain_sf &lt;- train_sf %&gt;%\n  st_drop_geometry() %&gt;%\n  as.data.frame()\n\ntest_df &lt;- test_sf %&gt;%\n  st_drop_geometry() %&gt;%\n  as.data.frame()\n\n\nrs_sf1 &lt;- rs_sf %&gt;%\n  st_drop_geometry()\nggcorrmat(rs_sf1[,2:17])\n\n^ to apply statistical learning methods but not crucial for machine learning\n\ntrain_df &lt;- train_df %&gt;%\n  select(-c(PROX_CHAS))\n\ntrain_sf &lt;- train_sf %&gt;%\n  select(-c(PROX_CHAS))\n\ntest_df &lt;- tset_df %&gt;%\n  select(-c(PROX_CHAS))\n\ntest_sf &lt;- test_sf %&gt;%\n  select(-c(PROX_CHAS))\n\nâ€˜-â€™ to exclude the column from selection\n\nrs_mlr &lt;- lm(formula = RESALE_PRICE~\n                  FLOOR_AREA_SQM +\n                  STOREY_ORDER + \n                  REMAINING_LEASE_MTHS +\n                  PROX_CBD + \n                  PROX_ELDERLYCARE +\n                  PROX_HAWKER +\n                  PROX_MRT +\n                  PROX_PARK +\n                  PROC_GOOD_PRISCH +\n                  PROX_MALL + \n                  PROX_SUPERMARKET +\n                  WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE +\n                  WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_df)\n\nproximity to CHAS is removed\n\ncoords &lt;- st_coordinates(rs_sf)\ncoords_train &lt;- st_coordinates(train_sf)\ncoords_test &lt;- st_coordinates(test_sf)\n\n\nset.seed(1234)\nrs_rp &lt;- rpart(formula = RESALE_PRICE~\n                FLOOR_AREA_SQM +\n                  STOREY_ORDER + \n                  REMAINING_LEASE_MTHS +\n                  PROX_CBD + \n                  PROX_ELDERLYCARE +\n                  PROX_HAWKER +\n                  PROX_MRT +\n                  PROX_PARK +\n                  PROC_GOOD_PRISCH +\n                  PROX_MALL + \n                  PROX_SUPERMARKET +\n                  WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE +\n                  WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_df)\nrs_rp\n\nproximity to CHAS is removed\n\nrpart.plot(rs_rp)\n\n\nset.seed(1234)\nrs_rf &lt;- ranger(formula = RESALE_PRICE~\n                  FLOOR_AREA_SQM +\n                  STOREY_ORDER + \n                  REMAINING_LEASE_MTHS +\n                  PROX_CBD + \n                  PROX_ELDERLYCARE +\n                  PROX_HAWKER +\n                  PROX_MRT +\n                  PROX_PARK +\n                  PROC_GOOD_PRISCH +\n                  PROX_MALL + \n                  PROX_SUPERMARKET +\n                  WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE +\n                  WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_df,\n                importance= \"impurity\")\nrs_rf\n\nranger package is usually used in geospatial machine learning\nimportance is used to define what variables contribute to classification\n\nvi &lt;- as.data.frame(rs_rf$variable.importance)\n\n\nvi &lt;- as.data.frame(rs_sf$variable,importance)\nvi$variables &lt;-rownames (vi)\nvi &lt;- vi %&gt;%\n  rename(vi = \"rs_rf$variable,importance\")\n\n\nggplot(data =vi,\n       aes(x=vi,\n           y = reorder(variables, vi))) +\n  geom_bar(stat=\"identity\")\n\nbw.min and bw.max can reduce computational time\n\ngrf_pred &lt;-read_rds(\"data/models/grf_pred.rds\")\ngrf_pred_df &lt;- as.data.frame(grf_pred)\n\n\ngrf_pred &lt;- predict.grf(rs_grf,\n                        test_df,\n                        x.var.name=\"X\",\n                        y.var.name=\"Y\",\n                        )\n\n\ntest_pred &lt;- test_df %&gt;%\n  select(RESALE_PRICE) %&gt;%\n  cbind(grf_pred_df)\n\n\nrf_pred &lt;- predict(rs_rf, test_df)\n\n\nrf_pred_df &lt;- as.data.frame (rf_pred$predictions)%&gt;%\n  rename(rf_pred = \"rf_pred$predictions\")\n\n\ntest_pred &lt;-cbind(test_pred,\n                  rf_pred_df)\n\n\nmlr_pred &lt;- predict(rs_mlr, test_df)\n\n\nmlr_pred_df &lt;- as.data.frame (mlr_pred)%&gt;%\n  rename(mlr_pred = \"mlr_pred\")\n\n\ntest_pred &lt;-cbind(test_pred,\n                  mlr_pred_df)\n\nusing yardstick to compare model comparison\n\nyardstick::rmse(test_pred,\n                RESALE_PRICE,\n                mlr_pred)\n\n\nmc &lt;- test_pred %&gt;%\n  oivot_longer(cols =c(2:4),\n               names_to =\"models\",\n               values_to =\"predicted\")\n\n\nggplot(data = test_data_p,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()"
  }
]