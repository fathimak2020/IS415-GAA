{
  "hash": "1f8188e4929e10a7616387053caabebc",
  "result": {
    "markdown": "---\ntitle: \"Take-home Exercise 1a [DATA PREPARATION]: Application of Spatial Point Patterns Analysis to Discover the Geographical Distribution of Grab Hailing Services in Singapore\"\nexecute: \n  warning: false\n  eval: true\n  freeze: true\ndate: \"2024-02-14\"\n---\n\n\n## 1 Overview\n\n## 1.1 Setting the scene\n\nUnderstanding how people move around in a city is like figuring out its heartbeat—it shows us the rhythms that shape our urban lives. Thanks to smartphones and technology, we now have a bunch of data about how people move. When we use smart analysis tools like GIS, we can unlock valuable insights that help us plan cities better.\n\nIn 2020, GRAB shared a set of data called Grab Posisi, all about how people move around in Singapore. This kind of information isn't just interesting; it's super helpful for businesses, people who make decisions about the city, and those who plan how cities work. It's like having a dynamic picture of how people move, helping us create cities that work well for everyone.\n\n## 1.2 Objectives\n\nThe objectives of this take-home exercise are to:\n\n-   Apply geospatial analytics to address societal challenges\n\n-   Use spatial point patterns analysis methods to explore Grab hailing services distribution in Singapore\n\n-   Organise geospatial data into sf tibble data.frames using `sf` and `tidyverse` functions\n\n-   Focus on Grab taxi location points, road layer within Singapore, and Singapore coastal boundary layer\n\n-   Generate traditional Kernel Density Estimation layers\n\n-   Create Network Kernel Density Estimation (NKDE)\n\n-   Utilise `tmap` functions to display kernel density layers on OSM\n\n-   Describe spatial patterns revealed by the kernel density maps\n\nBy this exercise, I will:\n\n-   Enhance my understanding of geospatial analytics applications\n\n-   Develop proficiency in spatial point patterns analysis\n\n-   Gain hands-on experience in dealing with geospatial data\n\n-   Explore Grab hailing services distribution patterns in Singapore\n\n-   Generate and interpret Kernel Density Estimation layers\n\n-   Understand the nuances of Network Kernel Density Estimation (NKDE)\n\n-   Learn about the visualisation of spatial patterns using `tmap` functions on OSM\n\n## 2 Getting Started\n\n## 2.1 Data Acquisition\n\nThe study will utilise the following datasets to explore spatial point patterns analysis methods and reveal the geographical and spatio-temporal distribution of Grab hailing services locations in Singapore.\n\n| Dataset Name                               | Type                | Source                                                              | Path                                     |\n|-----------------|-----------------|-----------------------|-----------------|\n| Grab-Posisi                                | Aspatial (.parquet) | <https://engineering.grab.com/grab-posisi>                          | data/aspatial/grabPosisi                 |\n| Master Plan 2019 Subzone Boundary (No Sea) | Geospatial (.shp)   | <https://beta.data.gov.sg/collections/2104/view>                    | data/geospatial/MPSZ-2019                |\n| Open Street Map Road Data                  | Geospatial (.shp)   | <https://download.geofabrik.de/asia/malaysia-singapore-brunei.html> | data/geospatial/OSM/gis_osm_roads_free_1 |\n\n## **2.2 Importing Relevant R Packages**\n\nThe R packages used in this project are:\n\n1.  `arrow`: for reading and writing Parquet files\n\n2.  `dplyr`: for data manipulation\n\n3.  `lubridate`: for working with date-time data\n\n4.  `maptools`: set of tools for reading and manipulating spatial data formats, such as shapefiles\n\n5.  `raster`: reads, writes, manipulates, analyses, and models gridded spatial data\n\n6.  `rgdal`: from CRAN, enables users to import, export, and manipulate spatial data within the R environment\n\n7.  `RcolorBrewer`: package providing color schemes for maps and other visualizations\n\n8.  `rmapshaper`: a package for simplifying and modifying geographic shapes in R\n\n9.  `sf`: for importing, managing, and processing geospatial data\n\n10. `spNetwork`: to perform spatial analysis for NKDE\n\n11. `spatstat`: for performing spatial point patterns analysis\n\n12. `tidyverse`: a family of other R packages for performing data science tasks such as importing, wrangling, and visualizing data\n\n13. `tmap`: creating static and interactive maps\n\n14. `ggplot2`: used for data visualization\n\n15. `plotly`: interactive graphing library for R\n\nPacman assists us by helping us load R packages that we require.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(arrow, dplyr, lubridate, maptools, raster, rgdal, RColorBrewer, rmapshaper, sf, sp, spNetwork, spatstat, tidyverse, tmap, ggplot2, plotly)\n\n#update.packages(ask = FALSE, dependencies = TRUE)\n## install.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n```\n:::\n\n\n## 2.3 Importing Geospatial Datasets\n\n### 2.3.1 Master Plan 2019 Subzone Boundary (No Sea)\n\nFor shapefile format, two arguments are required: `dsn` to define the data path, and `layer` to provide the shapefile name. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmpsz_sf <- st_read(dsn = \"data/geospatial\", \n                layer = \"MPSZ-2019\") %>%\n    st_transform(crs = 3414)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `MPSZ-2019' from data source \n  `C:\\fathimak2020\\IS415-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n```\n:::\n:::\n\n\n::: callout-important\n**Project Transformation**\n\nGiven that our dataset corresponds to the geographical boundaries of Singapore, it is necessary to specify the appropriate CRS for accurate spatial analysis. To achieve this, the **`st_transform()`** function is used to convert the CRS of `mpsz_sf` to SVY21 (EPSG: 3414)\n:::\n\n### 2.3.2 Coastal Outline\n\nIn order to create a costal outline of singapore, we will use the `st_union` function to consolidate all subzone boundaries from `mpsz_sf` into a single polygon.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noutline = mpsz_sf %>% st_union()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(outline)\n```\n:::\n\n\n```{}\n```\n\n![](images/image 1.png){fig-align=\"center\"}\n\n### 2.3.2.1 Extracting Outer Islands\n\nAs seen in the figure above, the coastal outline includes outer islands where Grab service is unavailable. Through the code chunk below, we use the `subset` function to select subzones from the `mpsz_sf` dataset to exclude. These excluded rows of data are stored in new dataframes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsemakau <- subset(mpsz_sf,mpsz_sf$SUBZONE_N == \"SEMAKAU\") #western island\nsudong <- subset(mpsz_sf, mpsz_sf$SUBZONE_N == \"SUDONG\") #western island\nbukom <- subset(mpsz_sf, mpsz_sf$SUBZONE_N ==  \"JURONG ISLAND AND BUKOM\")\nnorth <- subset(mpsz_sf, mpsz_sf$SUBZONE_N == \"NORTH-EASTERN ISLANDS\")\nsouth <- subset(mpsz_sf, mpsz_sf$SUBZONE_N == \"SOUTHERN GROUP\")\n```\n:::\n\n\nWe combine the newly created dataframes using the `bind_rows` function and store the data in another dataframe called `outer`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nouter <- dplyr::bind_rows(list(semakau,sudong,bukom,north,south))\n```\n:::\n\n\n### 2.3.2.2 Rendering a Coastal Boundary Excluding Outer Islands\n\nWe use the `st_union` function again to merge the geometries of `mpsz_sf` and `outer`, and the `st_difference` function to eliminate the overlap between the two layers. This results in a coastal boundary, `sg_sf`, which excludes the outer islands.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsg_sf <- st_difference(st_union(mpsz_sf), st_union(outer))\n```\n:::\n\n\n::: callout-tip\n✅ Task Complete! We have obtained the coastal boundary layer of Singapore, excluding the outer islands.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(sg_sf, \"data/rds/sg_sf.rds\")\nsg_sf <- read_rds(\"data/rds/sg_sf.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(sg_sf)\n```\n:::\n\n\n![](images/image 2.png){fig-align=\"center\"}\n\n::: callout-tip\nWe'll save the output in .rds file format to save loading time.\n:::\n\n### 2.3.3 Open Street Map Road Data\n\nLet's import the road data obtained from OSM.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nallroads = st_read(dsn = \"data/geospatial/OSM\", \n                         layer = \"gis_osm_roads_free_1\")  %>% st_transform(crs = 3414)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `gis_osm_roads_free_1' from data source \n  `C:\\fathimak2020\\IS415-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\geospatial\\OSM' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1759836 features and 10 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 99.66041 ymin: 0.8021131 xmax: 119.2601 ymax: 7.514393\nGeodetic CRS:  WGS 84\n```\n:::\n:::\n\n\n::: callout-important\n**Project Transformation**\n\nGiven that our dataset corresponds to the geographical boundaries of Singapore, it's necessary to specify the appropriate CRS for accurate spatial analysis. To achieve this, the **`st_transform()`** function is used to convert the CRS of `allroads` to SVY21 (EPSG: 3414)\n:::\n\nThis dataset encompasses road networks spanning Singapore, Malaysia, and Brunei. To narrow our focus, we will extract roads exclusively within the Singapore boundary using the `st_intersection` function to check the intersection between `sg_sf` and `allroads`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsg_roads_all <- st_intersection(allroads,sg_sf)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(sg_roads_all, \"data/rds/sg_roads_all.rds\")\nsg_roads_all <- read_rds(\"data/rds/sg_roads_all.rds\")\n```\n:::\n\n\n::: callout-tip\nWe'll save the output in .rds file format to save loading time.\n:::\n\nThe next step involves examining the various road types within the road network.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(sg_roads_all$fclass)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"primary\"        \"residential\"    \"tertiary\"       \"footway\"       \n [5] \"service\"        \"secondary\"      \"motorway\"       \"motorway_link\" \n [9] \"trunk\"          \"trunk_link\"     \"primary_link\"   \"pedestrian\"    \n[13] \"living_street\"  \"unclassified\"   \"steps\"          \"track_grade2\"  \n[17] \"track\"          \"secondary_link\" \"cycleway\"       \"path\"          \n[21] \"tertiary_link\"  \"track_grade1\"   \"track_grade3\"   \"unknown\"       \n[25] \"track_grade5\"   \"bridleway\"      \"track_grade4\"  \n```\n:::\n:::\n\n\nGiven our focus on Grab services, which primarily operate on roads excluding expressways (it is not possible for Grab to pick-up or drop off passengers along expressways), we will extract the relevant road types from the road network. To determine which roads are applicable, we can look at the OSM fclass. The image below provides descriptions for each road type, and for our analysis, we will focus on the most relevant types: primary, residential, tertiary, service, secondary, primary_link, secondary_link, and tertiary_link\n\n![](images/Screenshot%202024-02-01%20122342.png){width=\"425\"}\n\nWe store the selected road types in a dataframe called `sg_roads_filtered`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsg_roads_filtered <- c(\"primary\", \"residential\", \"tertiary\", \"service\", \"secondary\", \"primary_link\", \"secondary_link\", \"tertiary_link\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsg_roads <- sg_roads_all[sg_roads_all$fclass %in% sg_roads_filtered, ]\n\nunique(sg_roads$fclass)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"primary\"        \"residential\"    \"tertiary\"       \"service\"       \n[5] \"secondary\"      \"primary_link\"   \"secondary_link\" \"tertiary_link\" \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(sg_roads, \"data/rds/sg_roads.rds\")\n#sg_roads <- read_rds(\"data/rds/sg_roads.rds\")\n```\n:::\n\n\n::: callout-tip\nWe'll save the output in .rds file format to save loading time.\n:::\n\nWe will now visualise the selected road types within the boundaries of Singapore using `tmap`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroad_type_palette <- brewer.pal(12, \"Set3\")\ntmap_mode('plot')\ntm_shape(sg_sf) + \n  tm_borders(lwd = 2, col = 'grey') +\n  tm_shape(sg_roads) + \n  tm_lines(col = \"fclass\", palette = road_type_palette)\n  tm_layout(frame = FALSE, main.title = \"Types of Road Networks in Singapore\")\n```\n:::\n\n\n![](images/image 3.png){fig-align=\"center\"}\n\n::: callout-tip\n✅ Task Complete! We have extracted the road layer within Singapore.\n:::\n\n## 2.4 Importing Aspatial Datasets\n\n### 2.4.1 Grab-Posisi\n\nGrab-Posisi, is a GPS trajectory dataset. Each trajectory is serialised in a file in Apache Parquet format.\n\nWe will use the `read_parquet` function from the `arrow` package, to read Parquet files.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab0 <- read_parquet(\"data/aspatial/GrabPosisi/part-00000.parquet\", as_data_frame = TRUE)\ngrab1 <- read_parquet(\"data/aspatial/GrabPosisi/part-00001.parquet\", as_data_frame = TRUE)\ngrab2 <- read_parquet(\"data/aspatial/GrabPosisi/part-00002.parquet\", as_data_frame = TRUE)\ngrab3 <- read_parquet(\"data/aspatial/GrabPosisi/part-00003.parquet\", as_data_frame = TRUE)\ngrab4 <- read_parquet(\"data/aspatial/GrabPosisi/part-00004.parquet\", as_data_frame = TRUE)\ngrab5 <- read_parquet(\"data/aspatial/GrabPosisi/part-00005.parquet\", as_data_frame = TRUE)\ngrab6 <- read_parquet(\"data/aspatial/GrabPosisi/part-00006.parquet\", as_data_frame = TRUE)\ngrab7 <- read_parquet(\"data/aspatial/GrabPosisi/part-00007.parquet\", as_data_frame = TRUE)\ngrab8 <- read_parquet(\"data/aspatial/GrabPosisi/part-00008.parquet\", as_data_frame = TRUE)\ngrab9 <- read_parquet(\"data/aspatial/GrabPosisi/part-00009.parquet\", as_data_frame = TRUE)\n```\n:::\n\n\nThen we join all the read files into one dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab <- bind_rows(grab0,grab1, grab2,grab3,grab4,grab5,grab6,grab7,grab8,grab9) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(grab)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 9\n  trj_id driving_mode osname  pingtimestamp rawlat rawlng speed bearing accuracy\n  <chr>  <chr>        <chr>           <int>  <dbl>  <dbl> <dbl>   <int>    <dbl>\n1 70014  car          android    1554943236   1.34   104.  18.9     248      3.9\n2 73573  car          android    1555582623   1.32   104.  17.7      44      4  \n3 75567  car          android    1555141026   1.33   104.  14.0      34      3.9\n4 1410   car          android    1555731693   1.26   104.  13.0     181      4  \n5 4354   car          android    1555584497   1.28   104.  14.8      93      3.9\n6 32630  car          android    1555395258   1.30   104.  23.2      73      3.9\n```\n:::\n:::\n\n\nThe `head` function reveals that there are 9 columns in the dataframe.\n\nThe field `pingtimestamp` is not in proper date-time format. It is stored as an `int` value. The following code chunk converts the data type of `pingtimestamp` from `int` to `date-time` format.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab$pingtimestamp <- as_datetime(grab$pingtimestamp)\n```\n:::\n\n\n### 2.4.1.2 Converting Aspatial Data Frame into a Simple Feature Data Frame\n\nWe will proceed to convert the `grab` dataset, currently in an aspatial data frame, into an sf tibble dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab_sf <- st_as_sf(grab, \n                       coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# write_rds(grab_sf, \"data/rds/grab_sf.rds\")\ngrab_sf <- read_rds(\"data/rds/grab_sf.rds\")\n```\n:::\n\n\n::: callout-tip\nWe'll save the output in .rds file format to save loading time.\n:::\n\n::: callout-important\n**Project Transformation**\n\nAssuming the dataset is initially in the WGS84 Geographic Coordinate System, as indicated by the latitude/longitude fields, we need to define the suitable CRS for spatial analysis within Singapore. The `st_transform()` function is utilised to convert the CRS of the `grab` dataset to SVY21 (EPSG: 3414).\n:::\n\nThis gives us the new simple feature data frame, `grab_sf`\n\n## 2.5 Data Wrangling\n\n### 2.5.1 **Extracting Grab Trips Starting Locations**\n\nWe will extract trip starting point for all unqiue trajectories and store them to a new df named `grab_origin`. To isolate the origin locations, we use the following methodology:\n\n1.  **Grouping by Trajectory ID:**\n\n    -   The dataset is grouped by the unique trajectory identifier (**`trj_id`**).\n\n2.  **Arranging by Timestamp:**\n\n    -   Within each trajectory group, records are arranged in ascending order based on the timestamp (**`pingtimestamp`**).\n\n3.  **Filtering for the First Row:**\n\n    -   By selecting the first row within each grouped trajectory (**`row_number() == 1`**), we identify the earliest recorded location for each trip. This is indicative of the trip's starting point.\n\n4.  **Adding Temporal Information:**\n\n    -   Additional temporal context is provided by introducing new columns:\n\n        -   **`weekday`**: Day of the week based on the timestamp\n\n        -   **`start_hr`**: Starting hour of the trip\n\n        -   **`day`**: Day of the month when the trip started\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab_origin <- grab_sf %>%\n  group_by(trj_id) %>%\n  arrange(pingtimestamp) %>%\n  filter(row_number()==1) %>% #after sorting by timestamp, first row gives origin location \n  mutate(weekday = wday(pingtimestamp, #define workday\n                        label = TRUE,\n                        abbr = TRUE), #Monday = MON \n        start_hr = factor(hour(pingtimestamp)),\n        day = factor(mday(pingtimestamp))) #to change to ordinal scale\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(grab_origin, \"data/rds/grab_origin.rds\")\ngrab_origin <- read_rds(\"data/rds/grab_origin.rds\")\n```\n:::\n\n\n::: callout-tip\nWe'll save the output in .rds file format to save loading time.\n:::\n\n::: callout-tip\n✅ Task Complete! We have retrieved the origin location coordinates for Grab services.\n:::\n\n### 2.5.2 **Extracting Grab Trips Ending Locations**\n\nWe will extract trip ending point for all unique trajectories and store them to a new df named `grab_dest`. We employ a similar methodology to extracting a trips origin location. Except here, within each trajectory group, records are arranged in descending order based on the timestamp (**`pingtimestamp`**). By selecting the first row within each grouped trajectory (**`row_number() == 1`**), we identify the latest recorded location for each trip. This corresponds to the trip's ending point.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab_dest <- grab_sf %>%\n  group_by(trj_id) %>%\n  arrange(desc(pingtimestamp)) %>% #function from dplyr\n  filter(row_number()==1) %>% #first row after arranging in desc order gives dest  \n  mutate(weekday = wday(pingtimestamp, #define workday\n                        label = TRUE,\n                        abbr = TRUE), #Monday = MON \n        end_hr = factor(hour(pingtimestamp)),\n        day = factor(mday(pingtimestamp))) #to change to ordinal scale\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(grab_dest, \"data/rds/grab_dest.rds\")\ngrab_dest <- read_rds(\"data/rds/grab_dest.rds\")\n```\n:::\n\n\n::: callout-tip\nWe'll save the output in .rds file format to save loading time.\n:::\n\n::: callout-tip\n✅ Task Complete! We have retrieved the destination location coordinates for Grab services.\n:::\n\n### 2.5.3 Converting Simple Features to Planar Point Pattern Objects\n\nTo perform spatial point pattern analysis, firstly, we’ll need to convert the simple features objects (grab_orign and grab_dest) into Spatial\\* classes. For this we use `as.ppp` from spatstat package. The `st_coordinates` function extracts the coordiates from our sf objects and `st_bbox` will extract the minimum and maximum coordinates of the object along each axis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab_origin_ppp <- as.ppp(st_coordinates(grab_origin), st_bbox(grab_origin))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mar = c(1,1,1,1))\nplot(grab_origin_ppp, main = \"Grab Origin Points as PPP Objects\")\n```\n:::\n\n\n![](images/image 4.png){fig-align=\"center\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab_dest_ppp <- as.ppp(st_coordinates(grab_dest), st_bbox(grab_dest))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mar = c(1,1,1,1))\nplot(grab_dest_ppp, main = \"Grab Destination Points as PPP Objects\")\n```\n:::\n\n\n![](images/image 5.png){fig-align=\"center\"}\n\n::: callout-tip\nIt is not neccessary to change `sg_sf` into a ppp object as it will be converted to `owin` instead.\n:::\n\n### 2.5.4 Check for Duplicates and Handle Data Errors\n\nLet's have a look at the `ppp` objects we have created to make sure that there is no duplicates or errors in our data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(grab_origin_ppp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPlanar point pattern:  28000 points\nAverage intensity 2.473666e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [3628.24, 49845.23] x [25198.14, 49689.64] units\n                    (46220 x 24490 units)\nWindow area = 1131920000 square units\n```\n:::\n\n```{.r .cell-code}\nsummary(grab_dest_ppp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPlanar point pattern:  28000 points\nAverage intensity 2.493661e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [3637.21, 49870.63] x [25221.3, 49507.79] units\n                    (46230 x 24290 units)\nWindow area = 1122850000 square units\n```\n:::\n:::\n\n\n::: callout-note\n`grab_origin_ppp` and `grab_dest_ppp` objects have no duplicated points, but just to be sure, we check again using the `any(duplicated()` function.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nany(duplicated(grab_origin_ppp)) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\nany(duplicated(grab_dest_ppp)) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n:::\n\n\nThe output is false for both objects so we move on to the next step.\n\n### 2.5.5 Introducing OWIN\n\nWhen analysing spatial point patterns, we’ll confine our analysis within a certain geographical area - such as the Singapore boundary. In spatstat, an object called `owin` is specially designed to represent this polygonal region.\n\n### 2.5.5.1 Creating OWIN Object\n\nTo create a two dimensional observation window using `sg_sf` coastal boundary we created earlier, we use the `as.owin` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsg_owin <- as.owin(sg_sf)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(sg_owin, \"data/rds/sg_owin\")\nsg_owin <- read_rds(\"data/rds/sg_owin\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(sg_owin)\n```\n:::\n\n\n![](images/image 6.png){fig-align=\"center\"}\n\n::: callout-tip\nWe'll save the output in .rds file format to save loading time.\n:::\n\n### 2.5.5.2 Combining Point Events and OWIN Object\n\nNow, we’ll extract the relevant point events that are located within Singapore.\n\n### 2.5.5.2.1 Origin Points in OWIN Object\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab_origin_ppp_sg <- grab_origin_ppp[sg_owin]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(grab_origin_ppp_sg, \"data/rds/grab_origin_ppp_sg.rds\")\ngrab_origin_ppp_sg <- read_rds(\"data/rds/grab_origin_ppp_sg.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mar = c(1,1,1,1))\nplot(grab_origin_ppp_sg, main = '[OWIN] Grab Origin Points' )\n```\n:::\n\n\n![](images/image 7.png){fig-align=\"center\"}\n\n::: callout-tip\nWe'll save the output in .rds file format to save loading time.\n:::\n\n### 2.5.5.2.1 Destination Points in OWIN Object\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab_dest_ppp_sg <- grab_dest_ppp[sg_owin]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(grab_dest_ppp_sg, \"data/rds/grab_dest_ppp_sg.rds\")\ngrab_dest_ppp_sg <- read_rds(\"data/rds/grab_dest_ppp_sg.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mar = c(1,1,1,1))\nplot(grab_dest_ppp_sg, main = '[OWIN] Grab Destination Points' )\n```\n:::\n\n\n![](images/image 8.png){fig-align=\"center\"}\n\n::: callout-tip\nWe'll save the output in .rds file format to save loading time.\n:::\n\n## 3.0 Exploratory Data Analysis\n\nTo better understand the spatial data, we employ a series of exploratory techniques.\n\n### 3.1 Spatial Relationship between Origin and Destination Points\n\nThe map below shows the geographical distribution of origin and destination points. By overlaying both sets of points, we can observe areas where origin and destination locations overlap. These overlapping areas indicate regions with bidirectional travel.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncombined_map <- ggplot() +\n  geom_sf(data = grab_origin, aes(color = \"Origin\"), alpha = 0.7) +\n  geom_sf(data = grab_dest, aes(color = \"Destination\"), alpha = 0.7) +\n  ggtitle(\"Spatial Relationship Between Origin and Destination Locations\") +\n  labs(color = \"Location Type\") +\n  scale_color_manual(values = c(\"Origin\" = \"blue\", \"Destination\" = \"red\"), \n                     name = \"Location Type\", \n                     labels = c(\"Origin\", \"Destination\")) +\n  theme_minimal()\n\nprint(combined_map)\n```\n:::\n\n\n![](images/image 9.png){fig-align=\"center\"}\n\n### 3.2 Spatio-Temporal Visualisations\n\nSpatio-temporal visualisations show us a view of how data evolves over both space and time. These visualisations are particularly useful for analysing patterns, trends, and relationships within datasets.\n\n### 3.2.1 Frequency of Trip by Hour\n\nLet's create interactive plots to provide an insightful representation of the distribution of origin/destination locations and emphasise the specific hours that stand out in terms of pickup/drop-off frequency.\n\n### 3.2.1.1 Origin or Pickup Frequency\n\nFor creating a bar plot with `ggplot`, the pickup hours are first converted to numeric values for analysis. TThe x-axis represents the pickup hours, and the y-axis represents the count of origin locations. To highlight the hours with the highest count with a visual indication, we add a red dashed vertical line on the plot. The **`ggplot`** object is then converted into an interactive plot using **`ggplotly`**, allowing users to hover over bars for detailed information.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab_origin$start_hr <- as.numeric(grab_origin$start_hr)\norg<- ggplot(data = grab_origin, aes(x = start_hr)) +\n  geom_bar() +\n  labs(title = \"Distribution of Origin Locations by Pickup Hour\",\n       x = \"Pickup Hour\",\n       y = \"Count\") +\n  scale_x_continuous(breaks = seq(0, 24, by = 1)) +\n  theme_minimal()\nmax_hour <- which.max(table(grab_origin$start_hr))\norg <- org + geom_vline(xintercept = max_hour, linetype = \"dashed\", color = \"red\")\n\norg <- ggplotly(org)\norg\n```\n:::\n\n\n![](images/image 10.png){fig-align=\"center\"}\n\nThe chart above indicates that most pickups occur at 2-3pm, a potential reason could include:\n\n> **After-School Activities**: this time period may coincide with school release times and after-school activities. Parents might be picking up children or transporting them to various activities.\n\n### 3.2.1.2 Destination or Drop-off Frequency\n\nFor creating a bar plot with `ggplot`, the drop-off hours are first converted to numeric values for analysis. TThe x-axis represents the drop-off hours, and the y-axis represents the count of destination locations. To highlight the hours with the highest count with a visual indication, we add a red dashed vertical line on the plot. The **`ggplot`** object is then converted into an interactive plot using **`ggplotly`**, allowing users to hover over bars for detailed information.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab_dest$end_hr <- as.numeric(grab_dest$end_hr)\ndest<- ggplot(data = grab_dest, aes(x = end_hr)) +\n  geom_bar() +\n  labs(title = \"Distribution of Destinatioon Locations by Drop-off Hour\",\n       x = \"Drop-off Hour\",\n       y = \"Count\") +\n  scale_x_continuous(breaks = seq(0, 24, by = 1)) +\n  theme_minimal()\nmax_hour <- which.max(table(grab_dest$end_hr))\ndest <- dest + geom_vline(xintercept = max_hour, linetype = \"dashed\", color = \"red\")\n\ndest <- ggplotly(dest)\ndest\n```\n:::\n\n\n![](images/image 11.png){fig-align=\"center\"}\n\nThe chart above indicates that most drop-offs occur at 2pm, a potential reason could include:\n\n> **Lunchtime Rush**: 2pm is often around the time people finish their lunch breaks. This could result in increased travel demand as people return to work or resume their activities.\n\n### 3.2.2 Frequency of Trip by Day of Week\n\nLet's create a bar chart to explore the frequency of origins/destinations across different days and identify any noteworthy patterns.\n\n### 3.2.2.1 Origin or Pickup Frequency by Days\n\nThe code uses `ggplot` to create a bar plot, where each bar represents the frequency of pickups on a specific day. This code produces a informative visualisation to explore patterns in pickup frequency throughout the week.\n\n\n::: {.cell}\n\n```{.r .cell-code}\norigin_day <- ggplot(data = grab_origin, aes(x = weekday))  +\n              geom_bar(fill = \"#4C78A8\", color = \"#4C78A8\", alpha = 0.8) +\n              labs(title = \"Frequency of Pickup by Day of Week\",\n                   x = \"Day\",\n                   y = \"Count\") +\n              theme_minimal()\norigin_day <- ggplotly(origin_day)\norigin_day\n```\n:::\n\n\n![](images/image 12.png){fig-align=\"center\"}\n\n> The distribution of trips across days appears generally uniform, with a subtle increase observed on Wednesdays.\n\n### 3.2.2.2 Destination or Drop-off Frequency by Days\n\nThe code uses `ggplot` to create a bar plot, where each bar represents the frequency of drop-offs on a specific day. This code produces a informative visualisation to explore patterns in drop-off frequency throughout the week.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndest_day <- ggplot(data = grab_dest, aes(x = weekday))  +\n              geom_bar(fill = \"#FF0000\", color = \"#FF0000\", alpha = 0.8) +\n              labs(title = \"Frequency of Drop-off by Day of Week\",\n                   x = \"Day\",\n                   y = \"Count\") +\n              theme_minimal()\ndest_day <- ggplotly(dest_day)\ndest_day\n```\n:::\n\n\n![](images/image 13.png){fig-align=\"center\"}\n\n> If we plot by destination, we see the same result. This is expected, considering that each trip's origin corresponds to a destination.\n\n## **4.0 First-Order Spatial Point Patterns Analysis**\n\nFirst-order spatial point pattern analysis focuses on the distribution of individual points in a given spatial domain. It involves examining the basic characteristics and properties of the point pattern itself, without considering the interactions or relationship between points.\n\n### **4.1** Rescale `grab_original_ppp_sg` and `grab_dest_ppp_sg`\n\nFor further analysis, it is necessary to convert our data to kilometers, and we can achieve this by utilising the `rescale` function on `grab_original_ppp_sg` and `grab_dest_ppp_sg` which are in metres.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrab_origin_ppp_sg_km <- rescale(grab_origin_ppp_sg, 1000, 'km')\ngrab_dest_ppp_sg_km <- rescale(grab_dest_ppp_sg, 1000, 'km')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(grab_origin_ppp_sg_km, \"data/rds/grab_origin_ppp_sg_km.rds\")\ngrab_origin_ppp_sg_km <- read_rds(\"data/rds/grab_origin_ppp_sg_km.rds\")\n```\n:::\n\n\n::: callout-tip\nWe'll save the output in .rds file format to save loading time.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(grab_dest_ppp_sg_km, \"data/rds/grab_dest_ppp_sg_km.rds\")\ngrab_dest_ppp_sg_km <- read_rds(\"data/rds/grab_dest_ppp_sg_km.rds\")\n```\n:::\n\n\n::: callout-tip\nWe'll save the output in .rds file format to save loading time.\n:::\n\n> [**Proceed to Take-home Exercise 1b: Analysis**](https://is415-gaa-fathima.netlify.app/take-home_ex/take-home_ex01/take-home_ex01b)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}